{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstructured to extract Info from Scanned pdf\n",
    "- https://unstructured.io/\n",
    "- https://unstructured-io.github.io/unstructured/index.html\n",
    "- https://docs.unstructured.io/api-reference/api-services/python-sdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "import json\n",
    "\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements, elements_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: unstructured\n",
      "Version: 0.15.13\n",
      "Summary: A library that prepares raw documents for downstream ML tasks.\n",
      "Home-page: https://github.com/Unstructured-IO/unstructured\n",
      "Author: Unstructured Technologies\n",
      "Author-email: devops@unstructuredai.io\n",
      "License: Apache-2.0\n",
      "Location: c:\\Ia\\ver2\\IA\\IA-PDF-youtube-stuffs\\.venv\\Lib\\site-packages\n",
      "Requires: backoff, beautifulsoup4, chardet, dataclasses-json, emoji, filetype, langdetect, lxml, nltk, numpy, psutil, python-iso639, python-magic, python-oxmsg, rapidfuzz, requests, tabulate, tqdm, typing-extensions, unstructured-client, wrapt\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package unstructured.partition in unstructured:\n",
      "\n",
      "NAME\n",
      "    unstructured.partition\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    auto\n",
      "    common\n",
      "    csv\n",
      "    doc\n",
      "    docx\n",
      "    email\n",
      "    epub\n",
      "    html (package)\n",
      "    image\n",
      "    json\n",
      "    lang\n",
      "    md\n",
      "    model_init\n",
      "    msg\n",
      "    odt\n",
      "    org\n",
      "    pdf\n",
      "    pdf_image (package)\n",
      "    ppt\n",
      "    pptx\n",
      "    rst\n",
      "    rtf\n",
      "    strategies\n",
      "    text\n",
      "    text_type\n",
      "    tsv\n",
      "    utils (package)\n",
      "    xlsx\n",
      "    xml\n",
      "\n",
      "FILE\n",
      "    c:\\ia\\ver2\\ia\\ia-pdf-youtube-stuffs\\.venv\\lib\\site-packages\\unstructured\\partition\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import unstructured.partition\n",
    "\n",
    "help(unstructured.partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = \"data/gpt4all.pdf\"\n",
    "\n",
    "# Call the partition_pdf function\n",
    "# Returns a List[Element] present in the pages of the parsed pdf document\n",
    "elements = partition_pdf(filename)\n",
    "\n",
    "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Text at 0x308c2ba0>,\n",
       " <unstructured.documents.elements.Title at 0x30aed700>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3e270>,\n",
       " <unstructured.documents.elements.Text at 0x3fc3e2a0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3ce00>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3d580>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3d6a0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3dac0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3e180>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3e720>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3ec30>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3ecc0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3f5c0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc4bd70>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3f440>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc3fe00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc33b90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc487d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc4bf50>,\n",
       " <unstructured.documents.elements.Title at 0x3fc51cd0>,\n",
       " <unstructured.documents.elements.Title at 0x3f42e780>,\n",
       " <unstructured.documents.elements.Text at 0x3fc49d30>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3fd40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc4a5d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc536b0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc49fd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc5d880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc5ce30>,\n",
       " <unstructured.documents.elements.Title at 0x308f09b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x308f16d0>,\n",
       " <unstructured.documents.elements.Title at 0x308f21e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x308f2540>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc4a3f0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc52cf0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x308f3a70>,\n",
       " <unstructured.documents.elements.Title at 0x308f2930>,\n",
       " <unstructured.documents.elements.Title at 0x3098cc20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3098d1f0>,\n",
       " <unstructured.documents.elements.Title at 0x3098e240>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3098e180>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3098e3f0>,\n",
       " <unstructured.documents.elements.Title at 0x309286e0>,\n",
       " <unstructured.documents.elements.Title at 0x30928650>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30928aa0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x308f0920>,\n",
       " <unstructured.documents.elements.Title at 0x30929c40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3092b890>,\n",
       " <unstructured.documents.elements.Text at 0x30aaa6f0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc66f00>,\n",
       " <unstructured.documents.elements.Text at 0x3fc67170>,\n",
       " <unstructured.documents.elements.Text at 0x3fc67410>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd864b0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc67440>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc48c80>,\n",
       " <unstructured.documents.elements.Text at 0x3fc3cf50>,\n",
       " <unstructured.documents.elements.Text at 0x3fc3d7f0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc3e540>,\n",
       " <unstructured.documents.elements.Text at 0x3fc3ef00>,\n",
       " <unstructured.documents.elements.Text at 0x3fc3f650>,\n",
       " <unstructured.documents.elements.Text at 0x3fc48320>,\n",
       " <unstructured.documents.elements.Text at 0x3fc4a720>,\n",
       " <unstructured.documents.elements.Text at 0x3fc4b9b0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc70fb0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc713a0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc71820>,\n",
       " <unstructured.documents.elements.Text at 0x3fc51d60>,\n",
       " <unstructured.documents.elements.Text at 0x3fc3fda0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc48cb0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc70f80>,\n",
       " <unstructured.documents.elements.Text at 0x3fc4bbc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc66f60>,\n",
       " <unstructured.documents.elements.Text at 0x3fc504d0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc50e60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fcae3f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc53800>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd98f80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd995e0>,\n",
       " <unstructured.documents.elements.Title at 0x3fd98bc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd98b00>,\n",
       " <unstructured.documents.elements.Title at 0x3fda5610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fda6600>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd98e90>,\n",
       " <unstructured.documents.elements.Title at 0x3fdac110>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8ccb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8cad0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8d760>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8ea50>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8ee70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8f3b0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8e5d0>,\n",
       " <unstructured.documents.elements.Title at 0x3fd146e0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8c3b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd14c20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd14b00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fda6570>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd17320>,\n",
       " <unstructured.documents.elements.Title at 0x3fd16f60>,\n",
       " <unstructured.documents.elements.Title at 0x3fd17d40>,\n",
       " <unstructured.documents.elements.Title at 0x3fd5f560>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8c080>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd5fd70>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8c560>,\n",
       " <unstructured.documents.elements.Title at 0x3fccc950>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fca4230>,\n",
       " <unstructured.documents.elements.Title at 0x3fca4200>,\n",
       " <unstructured.documents.elements.Text at 0x3fca48f0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3d430>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3ddf0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3d4f0>,\n",
       " <unstructured.documents.elements.Text at 0x3fca62a0>,\n",
       " <unstructured.documents.elements.Title at 0x3fca52e0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3e9c0>,\n",
       " <unstructured.documents.elements.Title at 0x3fcc0170>,\n",
       " <unstructured.documents.elements.Title at 0x3fd17770>,\n",
       " <unstructured.documents.elements.Title at 0x3fd5f2c0>,\n",
       " <unstructured.documents.elements.Title at 0x3fcc0770>,\n",
       " <unstructured.documents.elements.Text at 0x3fcc2720>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3fc20>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3e480>,\n",
       " <unstructured.documents.elements.Title at 0x3fd14050>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc3dee0>,\n",
       " <unstructured.documents.elements.Title at 0x3fd5d070>,\n",
       " <unstructured.documents.elements.Title at 0x3fda5640>,\n",
       " <unstructured.documents.elements.Title at 0x3fc3d490>,\n",
       " <unstructured.documents.elements.Title at 0x3fda4830>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd98170>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd985c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd9a4b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fda4110>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fda4860>,\n",
       " <unstructured.documents.elements.Title at 0x3fda5f40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fda4bf0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc3f380>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3f2f2a80>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b0c5cfcf93a217591e27d5c97845f59b\",\n",
      "    \"text\": \"3 2 0 2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            263.81000000000006\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            303.81000000000006\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            303.81000000000006\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            263.81000000000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d71e9973e25dde0d96dc422b5a8fd429\",\n",
      "    \"text\": \"v o N 6\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            308.81000000000006\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            358.25\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            358.25\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            308.81000000000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"da9a4b336f710784f847aa01becae2d8\",\n",
      "    \"text\": \"] L C . s c [\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            368.24999999999994\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            428.78999999999996\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            428.78999999999996\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            368.24999999999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"cf466a5a422c76d228e6f9c56a8428ce\",\n",
      "    \"text\": \"1 v 1 3 9 4 0 . 1 1 3 2 : v i X r a\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            438.78999999999996\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            604.89\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            604.89\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            438.78999999999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"da9a4b336f710784f847aa01becae2d8\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"741c25a4fb94e81aa7239a1c0534a9e8\",\n",
      "    \"text\": \"GPT4All: An Ecosystem of Open Source Compressed Language Models\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            77.497,\n",
      "            78.40315579999992\n",
      "          ],\n",
      "          [\n",
      "            77.497,\n",
      "            92.74935579999999\n",
      "          ],\n",
      "          [\n",
      "            517.7818779999999,\n",
      "            92.74935579999999\n",
      "          ],\n",
      "          [\n",
      "            517.7818779999999,\n",
      "            78.40315579999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3f394fcdfd3c020fa260d031c7aa3551\",\n",
      "    \"text\": \"Yuvanesh Anand Nomic AI yuvanesh@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            69.06,\n",
      "            110.08451589999993\n",
      "          ],\n",
      "          [\n",
      "            69.06,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            170.67834999999997,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            170.67834999999997,\n",
      "            110.08451589999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c9f10a02ba1baf5861871dea2427ea13\",\n",
      "    \"text\": \"Zach Nussbaum Nomic AI zach@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.531,\n",
      "            110.08451589999993\n",
      "          ],\n",
      "          [\n",
      "            196.531,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            279.2363818,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            279.2363818,\n",
      "            110.08451589999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"1fb7ac4ca22ad79ab5acc099895231b9\",\n",
      "    \"text\": \"Adam Treat Nomic AI adam@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            318.538,\n",
      "            110.08451589999993\n",
      "          ],\n",
      "          [\n",
      "            318.538,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            396.24615,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            396.24615,\n",
      "            110.08451589999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c3528c06b42170925c8845cd0516afaf\",\n",
      "    \"text\": \"Aaron Miller Nomic AI aaron@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            435.058,\n",
      "            110.08451589999993\n",
      "          ],\n",
      "          [\n",
      "            435.058,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            518.7436999999999,\n",
      "            150.07418739999991\n",
      "          ],\n",
      "          [\n",
      "            518.7436999999999,\n",
      "            110.08451589999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"87aa6b53bb4ad01ca3786c2082164fa2\",\n",
      "    \"text\": \"Richard Guo Nomic AI richard@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            100.43099999999997,\n",
      "            173.28351589999988\n",
      "          ],\n",
      "          [\n",
      "            100.43099999999997,\n",
      "            213.27318739999987\n",
      "          ],\n",
      "          [\n",
      "            196.07179999999994,\n",
      "            213.27318739999987\n",
      "          ],\n",
      "          [\n",
      "            196.07179999999994,\n",
      "            173.28351589999988\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0f9ab7485cd89cf606234ade290a822f\",\n",
      "    \"text\": \"Ben Schmidt Nomic AI ben@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            261.77199999999993,\n",
      "            173.28351589999988\n",
      "          ],\n",
      "          [\n",
      "            261.77199999999993,\n",
      "            213.27318739999987\n",
      "          ],\n",
      "          [\n",
      "            333.5026,\n",
      "            213.27318739999987\n",
      "          ],\n",
      "          [\n",
      "            333.5026,\n",
      "            173.28351589999988\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9eace5e83f6c7f55784da14b30801a6e\",\n",
      "    \"text\": \"GPT4All Community Planet Earth\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            392.05999999999995,\n",
      "            173.28351589999988\n",
      "          ],\n",
      "          [\n",
      "            392.05999999999995,\n",
      "            199.54930159999992\n",
      "          ],\n",
      "          [\n",
      "            501.98714449999994,\n",
      "            199.54930159999992\n",
      "          ],\n",
      "          [\n",
      "            501.98714449999994,\n",
      "            173.28351589999988\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"adefd49403515997446e8633e38d94f7\",\n",
      "    \"text\": \"Brandon Duderstadt\\u2217 Nomic AI brandon@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            145.07499999999993,\n",
      "            235.17709939999986\n",
      "          ],\n",
      "          [\n",
      "            145.07499999999993,\n",
      "            276.4731873999999\n",
      "          ],\n",
      "          [\n",
      "            255.25451412999993,\n",
      "            276.4731873999999\n",
      "          ],\n",
      "          [\n",
      "            255.25451412999993,\n",
      "            235.17709939999986\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"Hfootnote.1\",\n",
      "          \"start_index\": 42\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"aa800040abcb3a68245ea9e047eb25a1\",\n",
      "    \"text\": \"Andriy Mulyar\\u2217 Nomic AI andriy@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            352.39699999999993,\n",
      "            235.17709939999997\n",
      "          ],\n",
      "          [\n",
      "            352.39699999999993,\n",
      "            276.47318740000003\n",
      "          ],\n",
      "          [\n",
      "            442.06024999999994,\n",
      "            276.47318740000003\n",
      "          ],\n",
      "          [\n",
      "            442.06024999999994,\n",
      "            235.17709939999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "    \"text\": \"Abstract\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            157.75799999999992,\n",
      "            304.80951590000006\n",
      "          ],\n",
      "          [\n",
      "            157.75799999999992,\n",
      "            316.7646159000001\n",
      "          ],\n",
      "          [\n",
      "            202.24292709999992,\n",
      "            316.7646159000001\n",
      "          ],\n",
      "          [\n",
      "            202.24292709999992,\n",
      "            304.80951590000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a90d3e5cedb83aa21ccdb130e575542b\",\n",
      "    \"text\": \"Large language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs re- quire costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            87.625,\n",
      "            331.47432159999994\n",
      "          ],\n",
      "          [\n",
      "            87.625,\n",
      "            437.07792159999997\n",
      "          ],\n",
      "          [\n",
      "            273.7749204880001,\n",
      "            437.07792159999997\n",
      "          ],\n",
      "          [\n",
      "            273.7749204880001,\n",
      "            331.47432159999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3f27ae624f926eb91c661791f642f9e3\",\n",
      "    \"text\": \"In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4All model family, as well as the evolution of the GPT4All project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            87.874,\n",
      "            444.3423216\n",
      "          ],\n",
      "          [\n",
      "            87.874,\n",
      "            573.8569216\n",
      "          ],\n",
      "          [\n",
      "            272.1287004640001,\n",
      "            573.8569216\n",
      "          ],\n",
      "          [\n",
      "            272.1287004640001,\n",
      "            444.3423216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"185bfce5f50e0f150589bc1d066df5a9\",\n",
      "    \"text\": \"variety of queries, responding only with the now infa- mous \\\"As an AI Language Model, I cannot...\\\" prefix (Vincent, 2023). These transparency and accessibility concerns spurred several developers to begin creating open source large language model (LLM) alternatives. Several grassroots efforts focused on fine tuning Meta\\u2019s open code LLaMA model (Touvron et al., 2023; McMil- lan, 2023), whose weights were leaked on BitTorrent less than a week prior to the release of GPT-4 (Verge, 2023). GPT4All started as one of these variants.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.813,\n",
      "            306.45532159999993\n",
      "          ],\n",
      "          [\n",
      "            305.813,\n",
      "            424.01392159999995\n",
      "          ],\n",
      "          [\n",
      "            526.1474706388001,\n",
      "            424.01392159999995\n",
      "          ],\n",
      "          [\n",
      "            526.1474706388001,\n",
      "            306.45532159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Vincent\",\n",
      "          \"url\": \"cite.verge2023ai\",\n",
      "          \"start_index\": 106\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.verge2023ai\",\n",
      "          \"start_index\": 115\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Touvronetal .,\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 345\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 361\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"McMil\",\n",
      "          \"url\": \"cite.wsj_llama\",\n",
      "          \"start_index\": 367\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"lan\",\n",
      "          \"url\": \"cite.wsj_llama\",\n",
      "          \"start_index\": 374\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.wsj_llama\",\n",
      "          \"start_index\": 379\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Verge\",\n",
      "          \"url\": \"cite.verge-meta-ai-leak-2023\",\n",
      "          \"start_index\": 474\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.verge-meta-ai-leak-2023\",\n",
      "          \"start_index\": 481\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c4a4c71ac956e6c69d6d761d32e81e0f\",\n",
      "    \"text\": \"In this paper, we tell the story of GPT4All. We com- ment on the technical details of the original GPT4All model (Anand et al., 2023), as well as the evolution of GPT4All from a single model to an ecosystem of several models. We remark on the impact that the project has had on the open source community, and discuss future directions. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.783,\n",
      "            426.5143216\n",
      "          ],\n",
      "          [\n",
      "            305.783,\n",
      "            544.0729216\n",
      "          ],\n",
      "          [\n",
      "            526.0674912600001,\n",
      "            544.0729216\n",
      "          ],\n",
      "          [\n",
      "            526.0674912600001,\n",
      "            426.5143216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Anandetal .,\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 114\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 128\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"4c756886e4dbf688c1568c8e65bda77d\",\n",
      "    \"text\": \"2 The Original GPT4All Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            557.3085159\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            569.2636159\n",
      "          ],\n",
      "          [\n",
      "            474.5295835,\n",
      "            569.2636159\n",
      "          ],\n",
      "          [\n",
      "            474.5295835,\n",
      "            557.3085159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"49fcd165ead3de8d30afc73d0ac33943\",\n",
      "    \"text\": \"2.1 Data Collection and Curation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            578.7575833999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            588.7201834\n",
      "          ],\n",
      "          [\n",
      "            454.4751514,\n",
      "            588.7201834\n",
      "          ],\n",
      "          [\n",
      "            454.4751514,\n",
      "            578.7575833999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b06f3763a242682a426d25678eee97da\",\n",
      "    \"text\": \"1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            589.5385159\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            601.4936159\n",
      "          ],\n",
      "          [\n",
      "            76.84355,\n",
      "            601.4936159\n",
      "          ],\n",
      "          [\n",
      "            76.84355,\n",
      "            589.5385159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"49fcd165ead3de8d30afc73d0ac33943\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
      "    \"text\": \"Introduction\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            88.79865,\n",
      "            589.5385159\n",
      "          ],\n",
      "          [\n",
      "            88.79865,\n",
      "            601.4936159\n",
      "          ],\n",
      "          [\n",
      "            153.6789777,\n",
      "            601.4936159\n",
      "          ],\n",
      "          [\n",
      "            153.6789777,\n",
      "            589.5385159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3abe933a09cfef67aa4b1b9a3a889472\",\n",
      "    \"text\": \"On March 14 2023, OpenAI released GPT-4, a large language model capable of achieving human level per- formance on a variety of professional and academic benchmarks. Despite the popularity of the release, the GPT-4 technical report (OpenAI, 2023) contained virtually no details regarding the architecture, hard- ware, training compute, dataset construction, or training method used to create the model. Moreover, users could only access the model through the internet interface at chat.openai.com, which was severely rate limited and unavailable in several locales (e.g. Italy) (BBC News, 2023). Additionally, GPT-4 refused to answer a wide\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.507,\n",
      "            611.3753216\n",
      "          ],\n",
      "          [\n",
      "            70.507,\n",
      "            752.8449216\n",
      "          ],\n",
      "          [\n",
      "            290.7879641256002,\n",
      "            752.8449216\n",
      "          ],\n",
      "          [\n",
      "            290.7879641256002,\n",
      "            611.3753216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"OpenAI\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 232\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 240\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"BBCNews\",\n",
      "          \"url\": \"cite.bbc2023chatgpt\",\n",
      "          \"start_index\": 578\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b11f30bd83a1069848654cfbd663d188\",\n",
      "    \"text\": \"To train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3.5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023. In particular, we gathered GPT- 3.5-Turbo responses to prompts of three publicly avail- able datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3 (Sanh et al., 2021). Fol- lowing the approach in Stanford Alpaca (Taori et al., 2023), an open source LLaMA variant that came just be- fore GPT4All, we focused substantial effort on dataset curation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.833,\n",
      "            595.3333216\n",
      "          ],\n",
      "          [\n",
      "            305.833,\n",
      "            736.8029216\n",
      "          ],\n",
      "          [\n",
      "            526.0666639902,\n",
      "            736.8029216\n",
      "          ],\n",
      "          [\n",
      "            526.0666639902,\n",
      "            595.3333216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Sanhetal .,\",\n",
      "          \"url\": \"cite.sanh2021multitask\",\n",
      "          \"start_index\": 395\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.sanh2021multitask\",\n",
      "          \"start_index\": 408\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Taorietal\",\n",
      "          \"url\": \"cite.alpaca\",\n",
      "          \"start_index\": 460\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.alpaca\",\n",
      "          \"start_index\": 474\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
      "    \"text\": \"\\u2217 Shared Senior Authorship\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81,\n",
      "            763.3930544\n",
      "          ],\n",
      "          [\n",
      "            85.81,\n",
      "            772.8172968\n",
      "          ],\n",
      "          [\n",
      "            177.0362924,\n",
      "            772.8172968\n",
      "          ],\n",
      "          [\n",
      "            177.0362924,\n",
      "            763.3930544\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4ab72a88d0df5f2cb17bd34cb4904132\",\n",
      "    \"text\": \"The collected dataset was loaded into Atlas (AI, 2023)\\u2014a visual interface for exploring and tagging mas- sive unstructured datasets \\u2014for data curation. Using At-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            739.3033216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            526.0614137000001,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            526.0614137000001,\n",
      "            739.3033216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"AI\",\n",
      "          \"url\": \"cite.atlas-nomic-ai\",\n",
      "          \"start_index\": 45\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.atlas-nomic-ai\",\n",
      "          \"start_index\": 49\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3a30a05cb24cdd567f6da500d522c05f\",\n",
      "    \"text\": \"las, we identified and removed subsets of the data where GPT-3.5-Turbo refused to respond, had malformed out- put, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure 1a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            74.0143215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            167.6629216\n",
      "          ],\n",
      "          [\n",
      "            290.7879242752001,\n",
      "            167.6629216\n",
      "          ],\n",
      "          [\n",
      "            290.7879242752001,\n",
      "            74.0143215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"605prompt - responsepairs , inFigure1a\",\n",
      "          \"url\": \"figure.caption.1\",\n",
      "          \"start_index\": 337\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b7e78c182dbf1ff32cc960ed1022019c\",\n",
      "    \"text\": \"2.2 Model Training\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            178.24758339999994\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            188.2101833999999\n",
      "          ],\n",
      "          [\n",
      "            159.80213020000002,\n",
      "            188.2101833999999\n",
      "          ],\n",
      "          [\n",
      "            159.80213020000002,\n",
      "            178.24758339999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1e9fb4a4895681f2277acac805311c72\",\n",
      "    \"text\": \"The original GPT4All model was a fine tuned variant of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine tuning process. Detailed model hyper-parameters and training code can be found in our associated code repository1.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.557,\n",
      "            194.20532159999993\n",
      "          ],\n",
      "          [\n",
      "            70.557,\n",
      "            275.8989216\n",
      "          ],\n",
      "          [\n",
      "            289.13843652000014,\n",
      "            275.8989216\n",
      "          ],\n",
      "          [\n",
      "            289.13843652000014,\n",
      "            194.20532159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Huetal .,\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 176\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 187\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"repository1\",\n",
      "          \"url\": \"Hfootnote.2\",\n",
      "          \"start_index\": 318\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"b7e78c182dbf1ff32cc960ed1022019c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
      "    \"text\": \"2.3 Model Access\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.86600000000001,\n",
      "            286.48358339999993\n",
      "          ],\n",
      "          [\n",
      "            70.86600000000001,\n",
      "            296.4461833999999\n",
      "          ],\n",
      "          [\n",
      "            151.10478040000004,\n",
      "            296.4461833999999\n",
      "          ],\n",
      "          [\n",
      "            151.10478040000004,\n",
      "            286.48358339999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2fd8d8cedd78e9080e5e641d58d85f58\",\n",
      "    \"text\": \"We publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hard- ware without transferring data to a 3rd party service.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.398,\n",
      "            302.4413215999999\n",
      "          ],\n",
      "          [\n",
      "            70.398,\n",
      "            360.2239216\n",
      "          ],\n",
      "          [\n",
      "            290.7888009840001,\n",
      "            360.2239216\n",
      "          ],\n",
      "          [\n",
      "            290.7888009840001,\n",
      "            302.4413215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8dfde8cadfe9b32242bf92a46677da95\",\n",
      "    \"text\": \"Our research and development costs were dominated by \\u223c$800 in GPU spend (rented from Lambda Labs and Paperspace) and \\u223c$500 in OpenAI API spend. Our final GPT4All model could be trained in about eight hours on a Lambda Labs DGX A100 8x 80GB for a total cost of \\u223c$100.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            362.3993216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            432.1369216\n",
      "          ],\n",
      "          [\n",
      "            289.1357349720001,\n",
      "            432.1369216\n",
      "          ],\n",
      "          [\n",
      "            289.1357349720001,\n",
      "            362.3993216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d6d4ad115eb010fa18f8db60b6e16130\",\n",
      "    \"text\": \"2.4 Model Evaluation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.86600000000001,\n",
      "            442.72158340000004\n",
      "          ],\n",
      "          [\n",
      "            70.86600000000001,\n",
      "            452.68418340000005\n",
      "          ],\n",
      "          [\n",
      "            169.29648800000004,\n",
      "            452.68418340000005\n",
      "          ],\n",
      "          [\n",
      "            169.29648800000004,\n",
      "            442.72158340000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f62efce43d06b955f6a5dcddf65af02c\",\n",
      "    \"text\": \"We performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowl- edge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace. Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100. We found that GPT4All produces stochastically lower ground truth perplexities than alpaca-lora (Anand et al., 2023).\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.398,\n",
      "            458.6793216\n",
      "          ],\n",
      "          [\n",
      "            70.398,\n",
      "            588.1939216\n",
      "          ],\n",
      "          [\n",
      "            290.78419826280003,\n",
      "            588.1939216\n",
      "          ],\n",
      "          [\n",
      "            290.78419826280003,\n",
      "            458.6793216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Wangetal .,\",\n",
      "          \"url\": \"cite.wang2023selfinstruct\",\n",
      "          \"start_index\": 113\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.wang2023selfinstruct\",\n",
      "          \"start_index\": 126\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"(\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 542\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"etal .,\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 549\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.gpt4all\",\n",
      "          \"start_index\": 557\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"d6d4ad115eb010fa18f8db60b6e16130\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"12c1dd0555bedb5ccc2a4d6366af96c7\",\n",
      "    \"text\": \"3 From a Model to an Ecosystem\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            600.3705159\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            612.3256159\n",
      "          ],\n",
      "          [\n",
      "            246.96462300000002,\n",
      "            612.3256159\n",
      "          ],\n",
      "          [\n",
      "            246.96462300000002,\n",
      "            600.3705159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0dffdafdd5dd329002b2c54c4cb1110b\",\n",
      "    \"text\": \"3.1 GPT4All-J: Repository Growth and the implications of the LLaMA License\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            621.0545834\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            642.9721834\n",
      "          ],\n",
      "          [\n",
      "            261.8091916,\n",
      "            642.9721834\n",
      "          ],\n",
      "          [\n",
      "            261.8091916,\n",
      "            621.0545834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"eefe269a0febf2b64874bf58517dfd42\",\n",
      "    \"text\": \"The GPT4All repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants. As the Nomic discord, the home of online discussion about GPT4All, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.557,\n",
      "            648.9673216\n",
      "          ],\n",
      "          [\n",
      "            70.557,\n",
      "            754.5709216\n",
      "          ],\n",
      "          [\n",
      "            290.3781824640001,\n",
      "            754.5709216\n",
      "          ],\n",
      "          [\n",
      "            290.3781824640001,\n",
      "            648.9673216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"figure.caption.3\",\n",
      "          \"start_index\": 125\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0dffdafdd5dd329002b2c54c4cb1110b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
      "    \"text\": \"1https://github.com/nomic-ai/gpt4all\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            82.406,\n",
      "            763.6547055999999\n",
      "          ],\n",
      "          [\n",
      "            82.406,\n",
      "            772.8172968\n",
      "          ],\n",
      "          [\n",
      "            203.33735880000003,\n",
      "            772.8172968\n",
      "          ],\n",
      "          [\n",
      "            203.33735880000003,\n",
      "            763.6547055999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0d8886d9a22209bc8437feee3638a5ca\",\n",
      "    \"text\": \"The LLaMA model that GPT4All was based on was licensed for research only, which severely limited the set of domains that GPT4All could be applied in. As a response to this, the Nomic team repeated the model training procedure of the original GPT4All model, but based on the already open source and commercially li- censed GPT-J model (Wang and Komatsuzaki, 2021). GPT4All-J also had an augmented training set, which contained multi-turn QA examples and creative writing such as poetry, rap, and short stories. The creative writ- ing prompts were generated by filling in schemas such as \\\"Write a [CREATIVE STORY TYPE] about [NOUN] in the style of [PERSON].\\\" We again employed Atlas to curate the prompt-response pairs in this data set.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            74.0143215999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            239.3939216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            239.3939216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            74.0143215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"WangandKomatsuzaki\",\n",
      "          \"url\": \"cite.gpt-j\",\n",
      "          \"start_index\": 335\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.gpt-j\",\n",
      "          \"start_index\": 357\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"92e00ff1cb81d6b459be0fe6dc472d52\",\n",
      "    \"text\": \"Our evaluation methodology also evolved as the project grew. In particular, we began evaluating GPT4All models using a suite of seven reasoning tasks that were used for evaluation of the Databricks Dolly (Conover et al., 2023b) model, which was re- leased on April 12, 2023. Unfortunately, GPT4All-J did not outperform other prominent open source models on this evaluation. As a result, we endeavoured to create a model that did.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            242.06532159999995\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            347.6689216\n",
      "          ],\n",
      "          [\n",
      "            526.064800984,\n",
      "            347.6689216\n",
      "          ],\n",
      "          [\n",
      "            526.064800984,\n",
      "            242.06532159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Conoveretal .,\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
      "          \"start_index\": 205\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
      "          \"start_index\": 221\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"73c58b69befd3e9f585d675406001042\",\n",
      "    \"text\": \"3.2 GPT4All-Snoozy: the Emergence of the\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            359.8695834\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            369.8321834\n",
      "          ],\n",
      "          [\n",
      "            496.7365006000001,\n",
      "            369.8321834\n",
      "          ],\n",
      "          [\n",
      "            496.7365006000001,\n",
      "            359.8695834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
      "    \"text\": \"GPT4All Ecosystem\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            328.558,\n",
      "            371.8245834\n",
      "          ],\n",
      "          [\n",
      "            328.558,\n",
      "            381.7871834\n",
      "          ],\n",
      "          [\n",
      "            414.0669958,\n",
      "            381.7871834\n",
      "          ],\n",
      "          [\n",
      "            414.0669958,\n",
      "            371.8245834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"024462343235bc2daac9cce9bb6c634e\",\n",
      "    \"text\": \"GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4All models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base model due to its superior base metrics when compared to GPT-J. Next, GPT4All-Snoozy incor- porated the Dolly\\u2019s training data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4All-Snoozy. As shown in Figure 1, GPT4All-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.395,\n",
      "            388.7263216\n",
      "          ],\n",
      "          [\n",
      "            305.395,\n",
      "            542.1499216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            542.1499216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            388.7263216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"59eced6045d5b1cdba3ade16138ac760\",\n",
      "    \"text\": \"Concurrently with the development of GPT4All, sev- eral organizations such as LMSys, Stability AI, BAIR, and Databricks built and deployed open source language models. We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more resources were developing source language models, we decided to pivot our effort away from training increas- ingly capable models and towards providing easy access to the plethora of models being produced by the open source community. Practically, this meant spending our time compressing open source models for use on com- modity hardware, providing stable and simple high level model APIs, and supporting a GUI for no code model experimentation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            544.8223216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            722.1569216\n",
      "          ],\n",
      "          [\n",
      "            526.0674912600001,\n",
      "            722.1569216\n",
      "          ],\n",
      "          [\n",
      "            526.0674912600001,\n",
      "            544.8223216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "    \"text\": \"3.3 The Current State of GPT4All\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            734.3565834\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            744.3191833999999\n",
      "          ],\n",
      "          [\n",
      "            457.8823606,\n",
      "            744.3191833999999\n",
      "          ],\n",
      "          [\n",
      "            457.8823606,\n",
      "            734.3565834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cb61f57fcce8e8a2646dc76a8c093748\",\n",
      "    \"text\": \"Today, GPT4All is focused on improving the accessi- bility of open source language models. The repository\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            305.833,\n",
      "            751.2583216\n",
      "          ],\n",
      "          [\n",
      "            305.833,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            526.0606565440002,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            526.0606565440002,\n",
      "            751.2583216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"41e0446a073aef5a69d9255c3c4e97d3\",\n",
      "    \"text\": \"(a)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            120.238,\n",
      "            182.17665599999998\n",
      "          ],\n",
      "          [\n",
      "            120.238,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            130.32900999999998,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            130.32900999999998,\n",
      "            182.17665599999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"58733fcd98d72185ade05bca0dfb629e\",\n",
      "    \"text\": \"(b)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            226.15,\n",
      "            182.17665599999998\n",
      "          ],\n",
      "          [\n",
      "            226.15,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            236.750106,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            236.750106,\n",
      "            182.17665599999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c46d4a1f11826347b7e9e26d86ba9cf0\",\n",
      "    \"text\": \"(c)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            338.03,\n",
      "            182.17665599999998\n",
      "          ],\n",
      "          [\n",
      "            338.03,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            348.12101,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            348.12101,\n",
      "            182.17665599999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9698a5149dc8973c56d946c401011e29\",\n",
      "    \"text\": \"(d)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            454.856,\n",
      "            182.17665599999998\n",
      "          ],\n",
      "          [\n",
      "            454.856,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            465.45610600000003,\n",
      "            191.267656\n",
      "          ],\n",
      "          [\n",
      "            465.45610600000003,\n",
      "            182.17665599999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2e03616f70996bcde479197f45b4857c\",\n",
      "    \"text\": \"Figure 1: TSNE visualizations showing the progression of the GPT4All train set. Panel (a) shows the original uncurated data. The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4All data after curation. This panel, as well as panels (c) and (d) are 10 colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appearl. Panel (c) shows the GPT4All-J dataset. The \\\"starburst\\\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.507,\n",
      "            203.06932159999997\n",
      "          ],\n",
      "          [\n",
      "            70.507,\n",
      "            296.71892160000004\n",
      "          ],\n",
      "          [\n",
      "            525.6591306453995,\n",
      "            296.71892160000004\n",
      "          ],\n",
      "          [\n",
      "            525.6591306453995,\n",
      "            203.06932159999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            76.844,\n",
      "            313.32293119999997\n",
      "          ],\n",
      "          [\n",
      "            76.844,\n",
      "            321.7911312\n",
      "          ],\n",
      "          [\n",
      "            98.9544702,\n",
      "            321.7911312\n",
      "          ],\n",
      "          [\n",
      "            98.9544702,\n",
      "            313.32293119999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"887a46a4686a15ffec4a85995e852a77\",\n",
      "    \"text\": \"BoolQ PIQA HellaSwag WinoG. ARC-e ARC-c OBQA Avg.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            245.318839,\n",
      "            313.32293119999997\n",
      "          ],\n",
      "          [\n",
      "            245.318839,\n",
      "            321.7911312\n",
      "          ],\n",
      "          [\n",
      "            523.1689492000004,\n",
      "            321.7911312\n",
      "          ],\n",
      "          [\n",
      "            523.1689492000004,\n",
      "            313.32293119999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"52cfb840240d199decfe24db5e27ce5d\",\n",
      "    \"text\": \"GPT4All-J 6B v1.0* GPT4All-J v1.1-breezy* GPT4All-J v1.2-jazzy* GPT4All-J v1.3-groovy* GPT4All-J Lora 6B* GPT4All LLaMa Lora 7B* GPT4All 13B snoozy* GPT4All Falcon Nous-Hermes (Nous-Research, 2023b) Nous-Hermes2 (Nous-Research, 2023c) Nous-Puffin (Nous-Research, 2023d) Dolly 6B* (Conover et al., 2023a) Dolly 12B* (Conover et al., 2023b) Alpaca 7B* (Taori et al., 2023) Alpaca Lora 7B* (Wang, 2023) GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama 7B* (Touvron et al., 2023) LLama 13B* (Touvron et al., 2023) Pythia 6.7B* (Biderman et al., 2023) Pythia 12B* (Biderman et al., 2023) Fastchat T5* (Zheng et al., 2023) Fastchat Vicu\\u00f1a* 7B (Zheng et al., 2023) Fastchat Vicu\\u00f1a 13B* (Zheng et al., 2023) StableVicu\\u00f1a RLHF* (Stability-AI, 2023) StableLM Tuned* (Stability-AI, 2023) StableLM Base* (Stability-AI, 2023) Koala 13B* (Geng et al., 2023) Open Assistant Pythia 12B* Mosaic MPT7B (MosaicML-Team, 2023) Mosaic mpt-instruct (MosaicML-Team, 2023) Mosaic mpt-chat (MosaicML-Team, 2023) Wizard 7B (Xu et al., 2023) Wizard 7B Uncensored (Xu et al., 2023) Wizard 13B Uncensored (Xu et al., 2023) GPT4-x-Vicuna-13b (Nous-Research, 2023a) Falcon 7b (Almazrouei et al., 2023) Falcon 7b instruct (Almazrouei et al., 2023)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            76.84399999999994,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            76.84399999999994,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            233.36174060000002,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            233.36174060000002,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Nous - Research\",\n",
      "          \"url\": \"cite.nousresearch2023noushermes\",\n",
      "          \"start_index\": 177\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.nousresearch2023noushermes\",\n",
      "          \"start_index\": 192\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nous - Research\",\n",
      "          \"url\": \"cite.nousresearch2023noushermesllama\",\n",
      "          \"start_index\": 213\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023c\",\n",
      "          \"url\": \"cite.nousresearch2023noushermesllama\",\n",
      "          \"start_index\": 228\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nous - Research\",\n",
      "          \"url\": \"cite.nousresearch2023redmondpuffin\",\n",
      "          \"start_index\": 247\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023d\",\n",
      "          \"url\": \"cite.nousresearch2023redmondpuffin\",\n",
      "          \"start_index\": 262\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Conoveretal .,\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV1\",\n",
      "          \"start_index\": 280\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023a\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV1\",\n",
      "          \"start_index\": 296\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Conoveretal .,\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
      "          \"start_index\": 315\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
      "          \"start_index\": 331\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Taorietal .,\",\n",
      "          \"url\": \"cite.alpaca\",\n",
      "          \"start_index\": 350\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.alpaca\",\n",
      "          \"start_index\": 364\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Wang\",\n",
      "          \"url\": \"cite.alpaca-lora\",\n",
      "          \"start_index\": 387\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.alpaca-lora\",\n",
      "          \"start_index\": 393\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"WangandKomatsuzaki\",\n",
      "          \"url\": \"cite.gpt-j\",\n",
      "          \"start_index\": 412\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.gpt-j\",\n",
      "          \"start_index\": 434\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Touvronetal .,\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 451\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 467\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Touvronetal .,\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 485\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 501\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Bidermanetal .,\",\n",
      "          \"url\": \"cite.biderman2023pythia\",\n",
      "          \"start_index\": 521\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.biderman2023pythia\",\n",
      "          \"start_index\": 538\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Bidermanetal .,\",\n",
      "          \"url\": \"cite.biderman2023pythia\",\n",
      "          \"start_index\": 557\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.biderman2023pythia\",\n",
      "          \"start_index\": 574\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhengetal .,\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 594\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 608\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhengetal .,\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 635\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 649\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhengetal .,\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 677\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zheng2023judging\",\n",
      "          \"start_index\": 691\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Stability - AI\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 717\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 731\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Stability - AI\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 754\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 768\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Stability - AI\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 790\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.stabilityai2023stablelm\",\n",
      "          \"start_index\": 804\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Gengetal .,\",\n",
      "          \"url\": \"cite.koala_blogpost_2023\",\n",
      "          \"start_index\": 822\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koala_blogpost_2023\",\n",
      "          \"start_index\": 835\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"MosaicML - Team\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 882\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 897\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"MosaicML - Team\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 924\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 939\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"MosaicML - Team\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 962\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.MosaicML2023Introducing\",\n",
      "          \"start_index\": 977\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Xuetal .,\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 994\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1005\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Xuetal .,\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1033\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1044\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Xuetal .,\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1073\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.xu2023wizardlm\",\n",
      "          \"start_index\": 1084\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nous - Research\",\n",
      "          \"url\": \"cite.nousresearch2023gpt4xvicuna\",\n",
      "          \"start_index\": 1109\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023a\",\n",
      "          \"url\": \"cite.nousresearch2023gpt4xvicuna\",\n",
      "          \"start_index\": 1124\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Almazroueietal .,\",\n",
      "          \"url\": \"cite.falcon40b\",\n",
      "          \"start_index\": 1142\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.falcon40b\",\n",
      "          \"start_index\": 1161\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"863cef5b45ff3c135f3d6ac488541345\",\n",
      "    \"text\": \"73.4 74 74.8 73.6 68.6 73.1 83.3 77.6 79.5 83.9 81.5 68.8 56.7 73.9 74.3 65.4 73.1 68.5 63.5 67.7 81.5 76.6 81.5 82.3 62.5 60.1 76.5 67.9 74.8 74.3 77.1 78.4 77.7 78.4 81.3 73.6 70.9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            249.19727459999996,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            249.19727459999996,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            264.01735,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            264.01735,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9292384de68d6f41f3b383a7321eceeb\",\n",
      "    \"text\": \"74.8 75.1 74.9 74.3 75.8 77.6 79.2 79.8 78.9 80.7 80.7 77.3 75.4 77.2 79.3 76.2 77.4 79.1 76.3 76.6 64.6 77.2 76.8 78.6 71.2 67.4 77.9 78 79.3 80.4 78.2 77.2 74.2 75.5 75 80.7 78.6\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            282.32399999999996,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            282.32399999999996,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            297.14494840000003,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            297.14494840000003,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2e76b593bee43831923f1d8063243e50\",\n",
      "    \"text\": \"63.4 63.2 63.6 63.8 66.2 72.1 75 74.9 80 80.1 80.4 67.6 71 73.9 74 66.2 73 76.2 64 67.3 46.3 70.7 73.3 74.1 53.6 41.2 72.6 68.1 76.3 77.2 74.5 69.9 68 72.1 75.2 76.3 69.8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.6919094,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            322.6919094,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            337.51335,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            337.51335,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"e4cc6d4975ff77e2c54a0df8341aff4c\",\n",
      "    \"text\": \"64.7 63.6 63.8 63.5 63.5 67.8 71.3 70.1 71.9 71.3 72.5 63.9 62.2 66.1 68.8 64.1 66.9 70.1 61.1 63.8 61.8 67.3 66.7 70.9 54.8 50.1 68.8 65 68.6 67.8 67.5 66.5 65.2 69.5 65 67.3 66.7\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            366.54024899999996,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            366.54024899999996,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            381.36168960000003,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            381.36168960000003,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"61bf0aa152722b826ff22a41233dc20c\",\n",
      "    \"text\": \"54.9 55.4 56.6 57.7 56.4 51.1 60.9 67.9 74.2 75.7 77.6 62.9 64.6 59.8 56.6 62.2 52.5 60 61.3 63.9 49.3 53.5 57.4 61 52.4 44.9 54.3 64.2 70 72.2 69.4 56.8 53.5 57.5 58.7 71 67.9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            403.84267,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            403.84267,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            418.6641106,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            418.6641106,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3ba922161513605086db41d4457e0843\",\n",
      "    \"text\": \"36 34.9 35.3 35 35.7 40.4 44.2 43.4 50.9 52.1 50.7 38.7 38.5 43.3 43.9 36.6 41.4 44.6 35.2 34.8 33.3 41.2 42.7 43.5 31.1 27 41 40.4 42.2 44.6 43.3 40.5 38.7 40.4 43.9 43.3 42.7\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            439.78999999999996,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            439.78999999999996,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            454.6116196,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            454.6116196,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"06b88051ebb9bf06a22ceb08cda91320\",\n",
      "    \"text\": \"40.2 38.4 41 38.8 40.2 40.2 43.4 42.6 46.4 46.2 45.6 41.2 40.4 43.4 42.6 38.2 42.4 42.2 37.2 38 39.4 40.8 43.6 44.4 33.4 32 42.8 43.2 42.6 43 44.2 42.6 41.6 44 43.6 44.4 41.2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            475.736,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            475.736,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            490.5591286,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            490.5591286,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "    \"text\": \"text-davinci-003\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            76.844,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            76.844,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            132.522415,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            132.522415,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f205dfd163738d0912bd2e3793e41a8e\",\n",
      "    \"text\": \"88.1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            249.1972746,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            249.1972746,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            264.0166246,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            264.0166246,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9f70060bfc2e03397be9c3ca01669dbb\",\n",
      "    \"text\": \"83.8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            282.324873,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            282.324873,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            297.14422300000007,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            297.14422300000007,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"efa84942a23a7f4f32030613b47e5d14\",\n",
      "    \"text\": \"83.4\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.69278240000006,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            322.69278240000006,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            337.5121324000001,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            337.5121324000001,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3e22defdcd8953213ed2b41bc15e9400\",\n",
      "    \"text\": \"75.8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            366.5411220000001,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            366.5411220000001,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            381.36047200000013,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            381.36047200000013,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"dd3373b1f28a16333af2e3b8484ac102\",\n",
      "    \"text\": \"83.9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            403.8435430000001,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            403.8435430000001,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            418.66289300000017,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            418.66289300000017,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c73cb5d9dc355215c7df2c742d6c06c0\",\n",
      "    \"text\": \"63.9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            439.79105200000015,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            439.79105200000015,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            454.6104020000002,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            454.6104020000002,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"349d5830083c52f2e022ef9572f77a8c\",\n",
      "    \"text\": \"51.0\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            475.7385610000002,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            475.7385610000002,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            490.5579110000002,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            490.5579110000002,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e4cfa78e74e08ab87de711c67c176fb4\",\n",
      "    \"text\": \"Table 1: Evaluations of all language models in the GPT4All ecosystem as of August 1, 2023. Code models are not included. OpenAI\\u2019s text-davinci-003 is included as a point of comparison. The best overall performing model in the GPT4All ecosystem, Nous-Hermes2, achieves over 92% of the average performance of text-davinci-003. Models marked with an asterisk were available in the ecosystem as of the release of GPT4All-Snoozy. Note that at release, GPT4All-Snoozy had the best average performance of any model in the ecosystem. Bolded numbers indicate the best performing model as of August 1, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.557,\n",
      "            668.5213216\n",
      "          ],\n",
      "          [\n",
      "            70.557,\n",
      "            738.2599216\n",
      "          ],\n",
      "          [\n",
      "            525.6547547729999,\n",
      "            738.2599216\n",
      "          ],\n",
      "          [\n",
      "            525.6547547729999,\n",
      "            668.5213216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c0c82e3e53fb3495e4493442d86113aa\",\n",
      "    \"text\": \"58.2 57.8 58.6 58.1 58.1 60.3 65.3 65.2 68.8 70.0 69.9 60.1 58.4 62.5 62.8 58.4 61.0 63.0 56.9 58.9 53.7 61.0 63.1 65.0 51.3 46.1 62.0 61.0 64.8 65.6 64.9 61.7 59.8 62.5 63.2 65.2 62.5\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            507.7219004,\n",
      "            327.2679312\n",
      "          ],\n",
      "          [\n",
      "            507.7219004,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            522.5435200000001,\n",
      "            640.5931312000002\n",
      "          ],\n",
      "          [\n",
      "            522.5435200000001,\n",
      "            327.2679312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"0955591427ee44e2be8e6cd3b9d8d95b\",\n",
      "    \"text\": \"75.7\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            507.7229524000002,\n",
      "            646.0699311999999\n",
      "          ],\n",
      "          [\n",
      "            507.7229524000002,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            522.5423024000003,\n",
      "            654.5381312\n",
      "          ],\n",
      "          [\n",
      "            522.5423024000003,\n",
      "            646.0699311999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5b851cfc3a92040f34538dabb304f77b\",\n",
      "    \"text\": \"Figure 2: Comparison of the github start growth of GPT4All, Meta\\u2019s LLaMA, and Stanford\\u2019s Alpaca. We conjecture that GPT4All achieved and maintains faster ecosystem growth due to the focus on access, which allows more users to meaningfully participate.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            285.4943215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            319.36792160000005\n",
      "          ],\n",
      "          [\n",
      "            524.4125679919997,\n",
      "            319.36792160000005\n",
      "          ],\n",
      "          [\n",
      "            524.4125679919997,\n",
      "            285.4943215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d19fcb87b6dfe6f1efe8ff69aedf0a8a\",\n",
      "    \"text\": \"provides compressed versions of open source models for use on commodity hardware, stable and simple high level model APIs, and a GUI for no code model ex- perimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            343.8763216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            413.61492159999995\n",
      "          ],\n",
      "          [\n",
      "            290.7888009840001,\n",
      "            413.61492159999995\n",
      "          ],\n",
      "          [\n",
      "            290.7888009840001,\n",
      "            343.8763216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6fdeb55e51d9b4b32895af473bd3970f\",\n",
      "    \"text\": \"\\u201cjust work\\\" on any machine, whether it comes equipped with Apple Metal silicon, NVIDIA, AMD, or other edge- accelerated hardware. Overall, we envision a world where anyone, anywhere, with any machine, can access and contribute to the cutting edge of AI.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            304.817,\n",
      "            343.8763216\n",
      "          ],\n",
      "          [\n",
      "            304.817,\n",
      "            401.65992159999996\n",
      "          ],\n",
      "          [\n",
      "            526.0636575760001,\n",
      "            401.65992159999996\n",
      "          ],\n",
      "          [\n",
      "            526.0636575760001,\n",
      "            343.8763216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b19cd88bad15dbd896f39128b97e30bc\",\n",
      "    \"text\": \"GPT4All currently provides native support and benchmark data for over 35 models (see Figure 1), and includes several models co-developed with industry part- ners such as Replit and Hugging Face. GPT4All also provides high level model APIs in languages includ- ing Python, Typescript, Go, C#, and Java, among oth- ers. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4All user data is collected on an opt in basis.) GPT4All has be- come the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others. GPT4All is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            416.6453216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            641.8009216\n",
      "          ],\n",
      "          [\n",
      "            290.78880098400003,\n",
      "            641.8009216\n",
      "          ],\n",
      "          [\n",
      "            290.78880098400003,\n",
      "            416.6453216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"),\",\n",
      "          \"url\": \"table.caption.2\",\n",
      "          \"start_index\": 93\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Chase\",\n",
      "          \"url\": \"cite.langchain\",\n",
      "          \"start_index\": 679\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.langchain\",\n",
      "          \"start_index\": 686\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"imartinez\",\n",
      "          \"url\": \"cite.privategpt\",\n",
      "          \"start_index\": 758\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.privategpt\",\n",
      "          \"start_index\": 769\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"StanGi\",\n",
      "          \"url\": \"cite.stangirard2023quivr\",\n",
      "          \"start_index\": 784\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"rard\",\n",
      "          \"url\": \"cite.stangirard2023quivr\",\n",
      "          \"start_index\": 792\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.stangirard2023quivr\",\n",
      "          \"start_index\": 798\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"MindsDB\",\n",
      "          \"url\": \"cite.mindsdb\",\n",
      "          \"start_index\": 818\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.mindsdb\",\n",
      "          \"start_index\": 827\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Leo\",\n",
      "          \"url\": \"cite.leo_github_fastest\",\n",
      "          \"start_index\": 914\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.leo_github_fastest\",\n",
      "          \"start_index\": 919\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5dc00f8cd1386b82aa9564922875f55b\",\n",
      "    \"text\": \"4 The Future of GPT4All\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            656.7605159\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            668.7156159\n",
      "          ],\n",
      "          [\n",
      "            208.469201,\n",
      "            668.7156159\n",
      "          ],\n",
      "          [\n",
      "            208.469201,\n",
      "            656.7605159\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8715e02bb2e5b4d7758a80a9775e8168\",\n",
      "    \"text\": \"In the future, we will continue to grow GPT4All, sup- porting it as the de facto solution for LLM accessibil- ity. Concretely, this means continuing to compress and distribute important open-source language models de- veloped by the community, as well as compressing and distributing increasingly multimodal AI models. Fur- thermore, we will expand the set of hardware devices that GPT4All models run on, so that GPT4All models\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.617,\n",
      "            679.5273216\n",
      "          ],\n",
      "          [\n",
      "            70.617,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            290.78880098400015,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            290.78880098400015,\n",
      "            679.5273216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"5dc00f8cd1386b82aa9564922875f55b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
      "    \"text\": \"Limitations\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            416.61951589999995\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            428.57461589999997\n",
      "          ],\n",
      "          [\n",
      "            365.2599695,\n",
      "            428.57461589999997\n",
      "          ],\n",
      "          [\n",
      "            365.2599695,\n",
      "            416.61951589999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f07b7060b90e509a5831047a04041324\",\n",
      "    \"text\": \"By enabling access to large language models, the GPT4All project also inherits many of the ethical con- cerns associated with generative models. Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., in- structions on building bioweapons). While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of in- creasingly secretive research groups. We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            439.3863216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            604.7649216\n",
      "          ],\n",
      "          [\n",
      "            526.064800984,\n",
      "            604.7649216\n",
      "          ],\n",
      "          [\n",
      "            526.064800984,\n",
      "            439.3863216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"037ae7c81d992d8bc0727fa73e581faf\",\n",
      "    \"text\": \"Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly includ- ing the GPT4All open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4All effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standard- ized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit as- signment, and hope to be able to support some of this research ourselves in the future.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            607.7963216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            761.2209216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520002,\n",
      "            761.2209216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520002,\n",
      "            607.7963216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d3f115969fa159c8ae83287b2de7a62e\",\n",
      "    \"text\": \"References\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            72.36851589999992\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            84.32361589999994\n",
      "          ],\n",
      "          [\n",
      "            126.4093946,\n",
      "            84.32361589999994\n",
      "          ],\n",
      "          [\n",
      "            126.4093946,\n",
      "            72.36851589999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
      "    \"text\": \"Nomic AI. 2023. Atlas. https://atlas.nomic.ai/.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            92.14289239999994\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            102.5239216\n",
      "          ],\n",
      "          [\n",
      "            286.13765,\n",
      "            102.5239216\n",
      "          ],\n",
      "          [\n",
      "            286.13765,\n",
      "            92.14289239999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Atlas\",\n",
      "          \"url\": \"https://atlas.nomic.ai/\",\n",
      "          \"start_index\": 16\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"https :// atlas . nomic . ai\",\n",
      "          \"url\": \"https://atlas.nomic.ai/\",\n",
      "          \"start_index\": 23\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c786e482f15da16d5c8387f40291180e\",\n",
      "    \"text\": \"Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al- shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hes- low, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            112.95932159999995\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            188.67592160000004\n",
      "          ],\n",
      "          [\n",
      "            290.8761733600001,\n",
      "            188.67592160000004\n",
      "          ],\n",
      "          [\n",
      "            290.8761733600001,\n",
      "            112.95932159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ff41e3dc2250ba1bdf97a74f6b347927\",\n",
      "    \"text\": \"Yuvanesh Anand, Zach Nussbaum, Brandon Duder- stadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo. https://github.com/nomic-ai/gpt4all.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            199.1103215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            252.90892159999999\n",
      "          ],\n",
      "          [\n",
      "            290.88095540800003,\n",
      "            252.90892159999999\n",
      "          ],\n",
      "          [\n",
      "            290.88095540800003,\n",
      "            199.1103215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com / nomic - ai / gpt4all\",\n",
      "          \"url\": \"https://github.com/nomic-ai/gpt4all\",\n",
      "          \"start_index\": 196\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6b1e1363d133a804d6a87d3d9ea1bc5e\",\n",
      "    \"text\": \"BBC News. 2023. Chatgpt banned in italy over privacy\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            263.34432159999994\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            273.3069216\n",
      "          ],\n",
      "          [\n",
      "            289.4846169432001,\n",
      "            273.3069216\n",
      "          ],\n",
      "          [\n",
      "            289.4846169432001,\n",
      "            263.34432159999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"https://www.bbc.com/news/technology-65139406\",\n",
      "          \"start_index\": 14\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8f4f477e26112f0d2d24d57229527002\",\n",
      "    \"text\": \"concerns. BBC News.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81,\n",
      "            274.0741818\n",
      "          ],\n",
      "          [\n",
      "            85.81,\n",
      "            284.26592160000007\n",
      "          ],\n",
      "          [\n",
      "            172.53465,\n",
      "            284.26592160000007\n",
      "          ],\n",
      "          [\n",
      "            172.53465,\n",
      "            274.0741818\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"concerns\",\n",
      "          \"url\": \"https://www.bbc.com/news/technology-65139406\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9ecc6cb3f818c8971fbbebf3ada09d7b\",\n",
      "    \"text\": \"Stella Biderman, Hailey Schoelkopf, Quentin An- thony, Herbie Bradley, Kyle O\\u2019Brien, Eric Hal- lahan, Mohammad Aflah Khan, Shivanshu Puro- hit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pythia: A suite for analyzing large language models across training and scaling.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            294.7013215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            370.41692159999997\n",
      "          ],\n",
      "          [\n",
      "            290.8793613920001,\n",
      "            370.41692159999997\n",
      "          ],\n",
      "          [\n",
      "            290.8793613920001,\n",
      "            294.7013215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Pythia\",\n",
      "          \"url\": \"http://arxiv.org/abs/2304.01373\",\n",
      "          \"start_index\": 239\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"modelsacrosstrainingandscaling\",\n",
      "          \"url\": \"http://arxiv.org/abs/2304.01373\",\n",
      "          \"start_index\": 284\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"8f4f477e26112f0d2d24d57229527002\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"16f9306e183f011f9a89e80c8b1d4f1c\",\n",
      "    \"text\": \"Harrison Chase. 2022.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            380.8523216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            390.8149216\n",
      "          ],\n",
      "          [\n",
      "            163.318529496,\n",
      "            390.8149216\n",
      "          ],\n",
      "          [\n",
      "            163.318529496,\n",
      "            380.8523216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"27d06343168776257e5cdc6d77525580\",\n",
      "    \"text\": \"langchain. https://github.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            169.58839218000003,\n",
      "            380.4338924\n",
      "          ],\n",
      "          [\n",
      "            169.58839218000003,\n",
      "            390.8149216\n",
      "          ],\n",
      "          [\n",
      "            292.6205,\n",
      "            390.8149216\n",
      "          ],\n",
      "          [\n",
      "            292.6205,\n",
      "            380.4338924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github\",\n",
      "          \"url\": \"https://github.com/langchain-ai/langchain\",\n",
      "          \"start_index\": 11\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "    \"text\": \"com/langchain-ai/langchain.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81,\n",
      "            391.3928924\n",
      "          ],\n",
      "          [\n",
      "            85.81,\n",
      "            401.7739216\n",
      "          ],\n",
      "          [\n",
      "            218.31365,\n",
      "            401.7739216\n",
      "          ],\n",
      "          [\n",
      "            218.31365,\n",
      "            391.3928924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"com / langchain - ai / langchain\",\n",
      "          \"url\": \"https://github.com/langchain-ai/langchain\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3a06407710f1e1db5c1e2561578c6241\",\n",
      "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing the magic of chatgpt with open mod- els.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            412.20932159999995\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            466.00692159999994\n",
      "          ],\n",
      "          [\n",
      "            290.79149126000016,\n",
      "            466.00692159999994\n",
      "          ],\n",
      "          [\n",
      "            290.79149126000016,\n",
      "            412.20932159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Hellodolly\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
      "          \"start_index\": 132\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Democratizingthemagicofchatgptwithopenmod\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
      "          \"start_index\": 145\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"els\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
      "          \"start_index\": 195\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e4992de073d64de58bd155d44d670bad\",\n",
      "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing the world\\u2019s first truly open instruction- tuned llm.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            476.4423216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            530.2409216\n",
      "          ],\n",
      "          [\n",
      "            290.78760584600013,\n",
      "            530.2409216\n",
      "          ],\n",
      "          [\n",
      "            290.78760584600013,\n",
      "            476.4423216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Freedolly\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
      "          \"start_index\": 140\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Introducingtheworld \\u2019 sfirsttrulyopeninstruction\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
      "          \"start_index\": 152\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"tunedllm\",\n",
      "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
      "          \"start_index\": 205\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"056cbfffc020bf8a655a5197701034c3\",\n",
      "    \"text\": \"Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal- lace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic re- search. Blog post.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            540.6763215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            583.5149216\n",
      "          ],\n",
      "          [\n",
      "            290.8736030092001,\n",
      "            583.5149216\n",
      "          ],\n",
      "          [\n",
      "            290.8736030092001,\n",
      "            540.6763215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Koala : Adialoguemodelforacademicre\",\n",
      "          \"url\": \"https://bair.berkeley.edu/blog/2023/04/03/koala/\",\n",
      "          \"start_index\": 107\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"search\",\n",
      "          \"url\": \"https://bair.berkeley.edu/blog/2023/04/03/koala/\",\n",
      "          \"start_index\": 148\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e21f882269851b2f6a4a5411c7f2e8fc\",\n",
      "    \"text\": \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            593.9503216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            636.7899216\n",
      "          ],\n",
      "          [\n",
      "            289.13354754680006,\n",
      "            636.7899216\n",
      "          ],\n",
      "          [\n",
      "            289.13354754680006,\n",
      "            593.9503216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Lora\",\n",
      "          \"url\": \"http://arxiv.org/abs/2106.09685\",\n",
      "          \"start_index\": 117\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"largelanguagemodels\",\n",
      "          \"url\": \"http://arxiv.org/abs/2106.09685\",\n",
      "          \"start_index\": 146\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3ea6c2ee4f5b756e77b23cdcbaf6d74c\",\n",
      "    \"text\": \"imartinez. 2023. privategpt. https://github.com/\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            646.8068923999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            657.1879216\n",
      "          ],\n",
      "          [\n",
      "            290.1297,\n",
      "            657.1879216\n",
      "          ],\n",
      "          [\n",
      "            290.1297,\n",
      "            646.8068923999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com\",\n",
      "          \"url\": \"https://github.com/imartinez/privateGPT\",\n",
      "          \"start_index\": 29\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0d84c182bf003f976d44d475b40751e3\",\n",
      "    \"text\": \"imartinez/privateGPT.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81000000000002,\n",
      "            657.7658924\n",
      "          ],\n",
      "          [\n",
      "            85.81000000000002,\n",
      "            668.1469216\n",
      "          ],\n",
      "          [\n",
      "            187.92665000000002,\n",
      "            668.1469216\n",
      "          ],\n",
      "          [\n",
      "            187.92665000000002,\n",
      "            657.7658924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"imartinez / privateGPT\",\n",
      "          \"url\": \"https://github.com/imartinez/privateGPT\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"113ed8473136e587a63ff658d9685446\",\n",
      "    \"text\": \"Oscar Leo. 2023. GitHub: The Fastest Growing Repos-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            678.5823216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            688.5449216\n",
      "          ],\n",
      "          [\n",
      "            290.7856627650001,\n",
      "            688.5449216\n",
      "          ],\n",
      "          [\n",
      "            290.7856627650001,\n",
      "            678.5823216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"GitHub : TheFastestGrowingRepos\",\n",
      "          \"url\": \"https://levelup.gitconnected.com/github-the-fastest-growing-repositories-of-all-time-f9884eb79e9\",\n",
      "          \"start_index\": 17\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"bfac0e2a1a1b97d79ec43a400d81572e\",\n",
      "    \"text\": \"itories of All Time.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81,\n",
      "            689.5403216\n",
      "          ],\n",
      "          [\n",
      "            85.81,\n",
      "            699.5029216\n",
      "          ],\n",
      "          [\n",
      "            162.39250619999999,\n",
      "            699.5029216\n",
      "          ],\n",
      "          [\n",
      "            162.39250619999999,\n",
      "            689.5403216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"itoriesofAllTime\",\n",
      "          \"url\": \"https://levelup.gitconnected.com/github-the-fastest-growing-repositories-of-all-time-f9884eb79e9\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"23ac2d2fe4e15d8b26e950649c9ae26c\",\n",
      "    \"text\": \"Robert McMillan. 2023. A meta platforms leak put powerful ai in the hands of everyone. The Wall Street Journal.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            709.9383216\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            741.8189216\n",
      "          ],\n",
      "          [\n",
      "            289.138158692,\n",
      "            741.8189216\n",
      "          ],\n",
      "          [\n",
      "            289.138158692,\n",
      "            709.9383216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \". powerfulaiinthehandsofeveryone .\",\n",
      "          \"url\": \"https://www.wsj.com/articles/a-meta-platforms-leak-put-powerful-ai-in-the-hands-of-everyone-8b9f875a\",\n",
      "          \"start_index\": 21\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"powerfulaiinthehandsofeveryone\",\n",
      "          \"url\": \"https://www.wsj.com/articles/a-meta-platforms-leak-put-powerful-ai-in-the-hands-of-everyone-8b9f875a\",\n",
      "          \"start_index\": 49\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"bfac0e2a1a1b97d79ec43a400d81572e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"afc0a061d59bc2dd31c7c5ce76ee55e4\",\n",
      "    \"text\": \"MindsDB. 2023. Mindsdb. https://github.com/\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            751.8358923999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            762.2169216\n",
      "          ],\n",
      "          [\n",
      "            290.1297,\n",
      "            762.2169216\n",
      "          ],\n",
      "          [\n",
      "            290.1297,\n",
      "            751.8358923999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com\",\n",
      "          \"url\": \"https://github.com/mindsdb/mindsdb\",\n",
      "          \"start_index\": 24\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"eb547b2c0d2a1977932d2e99c28c07ea\",\n",
      "    \"text\": \"mindsdb/mindsdb. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            85.81000000000002,\n",
      "            762.7948924\n",
      "          ],\n",
      "          [\n",
      "            85.81000000000002,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            241.22706000000002,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            241.22706000000002,\n",
      "            762.7948924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ec3f3280237ca8fe7a71d94be4c52569\",\n",
      "    \"text\": \"MosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable llms. Accessed: 2023-08-07.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            74.0143215999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            105.89492159999998\n",
      "          ],\n",
      "          [\n",
      "            526.1496030092002,\n",
      "            105.89492159999998\n",
      "          ],\n",
      "          [\n",
      "            526.1496030092002,\n",
      "            74.0143215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Introducingmpt - 7b : standardforopen - source , commerciallyusablellms\",\n",
      "          \"url\": null,\n",
      "          \"start_index\": 21\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"standardforopen - source , commerciallyusablellms\",\n",
      "          \"url\": null,\n",
      "          \"start_index\": 47\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"eb547b2c0d2a1977932d2e99c28c07ea\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"691d7fdf7080b720f8a8071e195b16ae\",\n",
      "    \"text\": \"Nous-Research.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            116.8363215999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            116.8363215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f827e63fb077c922bdb201badf9538dc\",\n",
      "    \"text\": \"2023a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            383.768387428,\n",
      "            116.8363215999999\n",
      "          ],\n",
      "          [\n",
      "            383.768387428,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            411.144416716,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            411.144416716,\n",
      "            116.8363215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"691d7fdf7080b720f8a8071e195b16ae\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"836334aabadbdf6ca8aceb81f73d1164\",\n",
      "    \"text\": \"gpt4-x-vicuna-13b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            448.37744244400005,\n",
      "            116.8363215999999\n",
      "          ],\n",
      "          [\n",
      "            448.37744244400005,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            126.79892159999997\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            116.8363215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"7d1236630fbec2f7f81c116ade9d829d\",\n",
      "    \"text\": \"https://huggingface.co/NousResearch/ gpt4-x-vicuna-13b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            127.37689239999997\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            148.7159216\n",
      "          ],\n",
      "          [\n",
      "            512.8067844000001,\n",
      "            148.7159216\n",
      "          ],\n",
      "          [\n",
      "            512.8067844000001,\n",
      "            127.37689239999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// huggingface . co / NousResearch gpt4 - x - vicuna - 13b . ModelonHuggingFace\",\n",
      "          \"url\": \"https://huggingface.co/NousResearch/gpt4-x-vicuna-13b\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ad50d6c212c9ead7c7d08664b1f0a368\",\n",
      "    \"text\": \"Nous-Research.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            159.65732159999993\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            159.65732159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"8f1a2b95024fc5a8a5b3a5142706fb6f\",\n",
      "    \"text\": \"2023b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            384.306965584,\n",
      "            159.65732159999993\n",
      "          ],\n",
      "          [\n",
      "            384.306965584,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            412.252058584,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            412.252058584,\n",
      "            159.65732159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"ad50d6c212c9ead7c7d08664b1f0a368\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9bb17e6c8fda36fc71499b4fe0441a98\",\n",
      "    \"text\": \"Nous-hermes-13b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            451.20243730000004,\n",
      "            159.65732159999993\n",
      "          ],\n",
      "          [\n",
      "            451.20243730000004,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            169.6199216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            159.65732159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fe871a36f9b133dd10e75d7e9343bd26\",\n",
      "    \"text\": \"https://huggingface.co/NousResearch/ Nous-Hermes-13b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            170.1978924\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            191.5379216\n",
      "          ],\n",
      "          [\n",
      "            502.34578440000007,\n",
      "            191.5379216\n",
      "          ],\n",
      "          [\n",
      "            502.34578440000007,\n",
      "            170.1978924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2c04966d0258539a0b71703eea37b41f\",\n",
      "    \"text\": \"Nous-Research. 2023c.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            202.47832159999996\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            212.44092160000002\n",
      "          ],\n",
      "          [\n",
      "            404.823744772,\n",
      "            212.44092160000002\n",
      "          ],\n",
      "          [\n",
      "            404.823744772,\n",
      "            202.47832159999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8328bea0ed9a308f513b89b4809d19f0\",\n",
      "    \"text\": \"Nous-hermes-llama-2-7b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            421.855008724,\n",
      "            202.47832159999996\n",
      "          ],\n",
      "          [\n",
      "            421.855008724,\n",
      "            212.44092160000002\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            212.44092160000002\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            202.47832159999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"81055478269ce81b5561884c98424677\",\n",
      "    \"text\": \"https://huggingface.co/NousResearch/ Nous-Hermes-llama-2-7b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            213.0188923999999\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            245.31792159999998\n",
      "          ],\n",
      "          [\n",
      "            524.408199856,\n",
      "            245.31792159999998\n",
      "          ],\n",
      "          [\n",
      "            524.408199856,\n",
      "            213.0188923999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// huggingface . co / NousResearch\",\n",
      "          \"url\": \"https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b\",\n",
      "          \"start_index\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nous - Hermes - llama - 2 - 7b\",\n",
      "          \"url\": \"https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b\",\n",
      "          \"start_index\": 37\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"95738f8b6f648f2d97a991304ccb420e\",\n",
      "    \"text\": \"Nous-Research.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            256.2593215999999\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            370.76121686799996,\n",
      "            256.2593215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2484431e07b97b4f98a6ac8d59303d97\",\n",
      "    \"text\": \"2023d.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            381.268571836,\n",
      "            256.2593215999999\n",
      "          ],\n",
      "          [\n",
      "            381.268571836,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            409.213664836,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            409.213664836,\n",
      "            256.2593215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"95738f8b6f648f2d97a991304ccb420e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0d0a73807f488d425d129e474ce8114a\",\n",
      "    \"text\": \"Redmond-puffin-13b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            438.459474892,\n",
      "            256.2593215999999\n",
      "          ],\n",
      "          [\n",
      "            438.459474892,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            266.2219216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            256.2593215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c3c419152e30de95467de68011b36673\",\n",
      "    \"text\": \"https://huggingface.co/NousResearch/ Redmond-Puffin-13B. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            266.7988924\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            288.1389216\n",
      "          ],\n",
      "          [\n",
      "            517.2897843999999,\n",
      "            288.1389216\n",
      "          ],\n",
      "          [\n",
      "            517.2897843999999,\n",
      "            266.7988924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// huggingface . co / NousResearch Redmond - Puffin - 13B . ModelonHuggingFace\",\n",
      "          \"url\": \"https://huggingface.co/NousResearch/Redmond-Puffin-13B\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f4154c37f41040e7f7b5dd83d6bb9f7d\",\n",
      "    \"text\": \"OpenAI. 2023. Gpt-4 technical report.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            299.08032159999993\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            309.0429216\n",
      "          ],\n",
      "          [\n",
      "            459.6855912000001,\n",
      "            309.0429216\n",
      "          ],\n",
      "          [\n",
      "            459.6855912000001,\n",
      "            299.08032159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Gpt - 4technicalreport\",\n",
      "          \"url\": \"http://arxiv.org/abs/2303.08774\",\n",
      "          \"start_index\": 14\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0a537655c8ca57a623a7fa87b3193a18\",\n",
      "    \"text\": \"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Ab- heesht Sharma, Andrea Santilli, Thibault Fevry, Ja- son Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            319.98332159999995\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            483.3709216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            483.3709216\n",
      "          ],\n",
      "          [\n",
      "            526.1562576520001,\n",
      "            319.98332159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"http://arxiv.org/abs/2110.08207\",\n",
      "          \"start_index\": 629\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"zero - shottaskgeneralization\",\n",
      "          \"url\": \"http://arxiv.org/abs/2110.08207\",\n",
      "          \"start_index\": 667\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"f4154c37f41040e7f7b5dd83d6bb9f7d\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"886a7f467ba741ee5d07336e15bca148\",\n",
      "    \"text\": \"Stability-AI. 2023. Stablelm. https://github.com/ Stability-AI/StableLM. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            493.89389239999997\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            515.2339216\n",
      "          ],\n",
      "          [\n",
      "            525.4057,\n",
      "            515.2339216\n",
      "          ],\n",
      "          [\n",
      "            525.4057,\n",
      "            493.89389239999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com\",\n",
      "          \"url\": \"https://github.com/Stability-AI/StableLM\",\n",
      "          \"start_index\": 30\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Stability - AI / StableLM\",\n",
      "          \"url\": \"https://github.com/Stability-AI/StableLM\",\n",
      "          \"start_index\": 50\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6161d90c7111121c9df590576b63d8d2\",\n",
      "    \"text\": \"https://github.com/\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            430.761,\n",
      "            525.7558924\n",
      "          ],\n",
      "          [\n",
      "            430.761,\n",
      "            535.7184924000001\n",
      "          ],\n",
      "          [\n",
      "            525.4057,\n",
      "            535.7184924000001\n",
      "          ],\n",
      "          [\n",
      "            525.4057,\n",
      "            525.7558924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"14880807bec39d9525429193f10ca671\",\n",
      "    \"text\": \"StanGirard. 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            526.1743216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            536.1369216\n",
      "          ],\n",
      "          [\n",
      "            381.563265544,\n",
      "            536.1369216\n",
      "          ],\n",
      "          [\n",
      "            381.563265544,\n",
      "            526.1743216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "    \"text\": \"quivr. StanGirard/quivr. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.086,\n",
      "            526.1743216\n",
      "          ],\n",
      "          [\n",
      "            321.086,\n",
      "            547.0959216\n",
      "          ],\n",
      "          [\n",
      "            481.48406000000006,\n",
      "            547.0959216\n",
      "          ],\n",
      "          [\n",
      "            481.48406000000006,\n",
      "            526.1743216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f9127289b648f97d5468d9c534385556\",\n",
      "    \"text\": \"Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https:// github.com/tatsu-lab/stanford_alpaca.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            558.0373216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            611.8349216\n",
      "          ],\n",
      "          [\n",
      "            525.7912084368,\n",
      "            611.8349216\n",
      "          ],\n",
      "          [\n",
      "            525.7912084368,\n",
      "            558.0373216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https\",\n",
      "          \"url\": \"https://github.com/tatsu-lab/stanford_alpaca\",\n",
      "          \"start_index\": 189\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"github . com / tatsu - lab / stanford _ alpaca\",\n",
      "          \"url\": \"https://github.com/tatsu-lab/stanford_alpaca\",\n",
      "          \"start_index\": 198\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1e03777b59eb46b371e2c0ec4e04c04c\",\n",
      "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            622.7763216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            698.4919216\n",
      "          ],\n",
      "          [\n",
      "            526.1521733600001,\n",
      "            698.4919216\n",
      "          ],\n",
      "          [\n",
      "            526.1521733600001,\n",
      "            622.7763216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Llama\",\n",
      "          \"url\": \"http://arxiv.org/abs/2302.13971\",\n",
      "          \"start_index\": 238\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"models\",\n",
      "          \"url\": \"http://arxiv.org/abs/2302.13971\",\n",
      "          \"start_index\": 283\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cb3d4cb151a83b755fbb5d192919a87a\",\n",
      "    \"text\": \"The Verge. 2023. Meta\\u2019s powerful ai language model has leaked online \\u2014 what happens now? The Verge.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            709.4333216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            730.3549216\n",
      "          ],\n",
      "          [\n",
      "            526.15332765,\n",
      "            730.3549216\n",
      "          ],\n",
      "          [\n",
      "            526.15332765,\n",
      "            709.4333216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Meta \\u2019 hasleakedonline \\u2014 whathappensnow ? TheVerge\",\n",
      "          \"url\": \"https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse\",\n",
      "          \"start_index\": 17\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"hasleakedonline \\u2014 whathappensnow ?\",\n",
      "          \"url\": \"https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse\",\n",
      "          \"start_index\": 51\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e3c968af341f5c57d0f600fc18d74a87\",\n",
      "    \"text\": \"James Vincent. 2023. As an ai generated language model: The phrase that shows how ai is polluting the web. The Verge.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.142,\n",
      "            741.2953216\n",
      "          ],\n",
      "          [\n",
      "            306.142,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            524.4084191080001,\n",
      "            773.1759216\n",
      "          ],\n",
      "          [\n",
      "            524.4084191080001,\n",
      "            741.2953216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \". model : theweb . TheVerge\",\n",
      "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
      "          \"start_index\": 19\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"model : theweb . TheVerge\",\n",
      "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
      "          \"start_index\": 49\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"theweb\",\n",
      "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
      "          \"start_index\": 98\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"056688ab6012c536a7138e0807ad0938\",\n",
      "    \"text\": \"Ben Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A 6 Billion Parameter Autoregressive Language https://github.com/kingoflolz/ Model. mesh-transformer-jax.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            74.0143215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            116.85392159999992\n",
      "          ],\n",
      "          [\n",
      "            290.5144309800001,\n",
      "            116.85392159999992\n",
      "          ],\n",
      "          [\n",
      "            290.5144309800001,\n",
      "            74.0143215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github . com / kingoflolz\",\n",
      "          \"url\": \"https://github.com/kingoflolz/mesh-transformer-jax\",\n",
      "          \"start_index\": 93\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"mesh - transformer - jax\",\n",
      "          \"url\": \"https://github.com/kingoflolz/mesh-transformer-jax\",\n",
      "          \"start_index\": 131\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
      "    \"text\": \"Eric J. Wang. 2023. alpaca-lora. https://github. com/tloen/alpaca-lora. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            125.40089239999998\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            146.74092159999998\n",
      "          ],\n",
      "          [\n",
      "            292.6205,\n",
      "            146.74092159999998\n",
      "          ],\n",
      "          [\n",
      "            292.6205,\n",
      "            125.40089239999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// github\",\n",
      "          \"url\": \"https://github.com/tloen/alpaca-lora\",\n",
      "          \"start_index\": 33\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"com / tloen / alpaca - lora\",\n",
      "          \"url\": \"https://github.com/tloen/alpaca-lora\",\n",
      "          \"start_index\": 49\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9e1872a7627d65000001f6a1a6cdd620\",\n",
      "    \"text\": \"Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han- naneh Hajishirzi. 2023. Self-instruct: Aligning lan- guage models with self-generated instructions.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            155.7063215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            198.54592160000004\n",
      "          ],\n",
      "          [\n",
      "            290.784716692,\n",
      "            198.54592160000004\n",
      "          ],\n",
      "          [\n",
      "            290.784716692,\n",
      "            155.7063215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Self - instruct : Aligninglan\",\n",
      "          \"url\": \"http://arxiv.org/abs/2212.10560\",\n",
      "          \"start_index\": 121\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"guagemodelswithself - generatedinstructions\",\n",
      "          \"url\": \"http://arxiv.org/abs/2212.10560\",\n",
      "          \"start_index\": 150\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1d4f3165609e78d1d6fb3065ae898420\",\n",
      "    \"text\": \"Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            207.51132159999997\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            250.3509216\n",
      "          ],\n",
      "          [\n",
      "            290.3823269040001,\n",
      "            250.3509216\n",
      "          ],\n",
      "          [\n",
      "            290.3823269040001,\n",
      "            207.51132159999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Wizardlm\",\n",
      "          \"url\": \"http://arxiv.org/abs/2304.12244\",\n",
      "          \"start_index\": 106\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"modelstofollowcomplexinstructions\",\n",
      "          \"url\": \"http://arxiv.org/abs/2304.12244\",\n",
      "          \"start_index\": 142\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7ef5091817209ce37c6cfb895b7c8acd\",\n",
      "    \"text\": \"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            70.866,\n",
      "            259.3163215999999\n",
      "          ],\n",
      "          [\n",
      "            70.866,\n",
      "            313.1139216\n",
      "          ],\n",
      "          [\n",
      "            290.37824261200007,\n",
      "            313.1139216\n",
      "          ],\n",
      "          [\n",
      "            290.37824261200007,\n",
      "            259.3163215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 595.276,\n",
      "        \"layout_height\": 841.89\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"gpt4all.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"http://arxiv.org/abs/2306.05685\",\n",
      "          \"start_index\": 184\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"llm - as - a - judgewithmt - benchandchatbotarena\",\n",
      "          \"url\": \"http://arxiv.org/abs/2306.05685\",\n",
      "          \"start_index\": 194\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "element_dict = [el.to_dict() for el in elements]\n",
    "output = json.dumps(element_dict, indent=2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UncategorizedText', 'Title', 'NarrativeText'}\n"
     ]
    }
   ],
   "source": [
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = \"data/scanned_gpt4all.pdf\"\n",
    "\n",
    "# Call the partition_pdf function\n",
    "# Returns a List[Element] present in the pages of the parsed pdf document\n",
    "elements = partition_pdf(filename)\n",
    "\n",
    "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Text at 0x3fc8cb90>,\n",
       " <unstructured.documents.elements.Title at 0x30828fb0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8cc20>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8c5f0>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8de80>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8e810>,\n",
       " <unstructured.documents.elements.Title at 0x30aeda30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8d370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8ff80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8f1d0>,\n",
       " <unstructured.documents.elements.Title at 0x3fca74d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fca5fa0>,\n",
       " <unstructured.documents.elements.ListItem at 0x3fd14320>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd15490>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd174d0>,\n",
       " <unstructured.documents.elements.Title at 0x3fca7b90>,\n",
       " <unstructured.documents.elements.Title at 0x3fd5f710>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd5f5f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd5f860>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd5ec00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30a5ce60>,\n",
       " <unstructured.documents.elements.Title at 0x30a5fd40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30a5eb10>,\n",
       " <unstructured.documents.elements.Title at 0x3fd154f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x38e03b00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fca5490>,\n",
       " <unstructured.documents.elements.Title at 0x3fd16060>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fca5400>,\n",
       " <unstructured.documents.elements.Title at 0x3fca7590>,\n",
       " <unstructured.documents.elements.Title at 0x3fca6b70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc84b00>,\n",
       " <unstructured.documents.elements.Title at 0x3fdace30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fdacd40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc3d9d0>,\n",
       " <unstructured.documents.elements.Title at 0x3fcc1f10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fcc3320>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30a5fef0>,\n",
       " <unstructured.documents.elements.Title at 0x3fd5d8b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30895b80>,\n",
       " <unstructured.documents.elements.Text at 0x3fd5c9b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd17830>,\n",
       " <unstructured.documents.elements.Text at 0x30895760>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fcef620>,\n",
       " <unstructured.documents.elements.Title at 0x30a256d0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc84470>,\n",
       " <unstructured.documents.elements.Text at 0x3fc8cfb0>,\n",
       " <unstructured.documents.elements.Text at 0x3fc8ef60>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8cec0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc84fe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fca4ef0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8dcd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fca5850>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8e8a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fca44d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8f380>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8f8f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8fa40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc8fe30>,\n",
       " <unstructured.documents.elements.Title at 0x3fc8fd40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x31a9d9d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd161b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc87920>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30a5c650>,\n",
       " <unstructured.documents.elements.Title at 0x3fd5f530>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd14d10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30a5df10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30a5ca10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd50080>,\n",
       " <unstructured.documents.elements.Title at 0x39320b60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30e9bef0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd153a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd5d1c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fc872c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30ebb920>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30ebb6b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3d6e7d70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x31a9ef30>,\n",
       " <unstructured.documents.elements.Title at 0x3d4c2120>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3d745250>,\n",
       " <unstructured.documents.elements.Title at 0x3fd16450>,\n",
       " <unstructured.documents.elements.Title at 0x30896de0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30896e40>,\n",
       " <unstructured.documents.elements.Text at 0x30897c80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x308951c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x2ef138f0>,\n",
       " <unstructured.documents.elements.Title at 0x3fdaf830>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd5fa70>,\n",
       " <unstructured.documents.elements.Title at 0x3fd84a10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fd85910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3fdac4d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x30a25490>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "    \"text\": \"2311.04931v1 [cs.CL] 6 Nov 2023\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            187.0,\n",
      "            718.0\n",
      "          ],\n",
      "          [\n",
      "            187.0,\n",
      "            1404.0\n",
      "          ],\n",
      "          [\n",
      "            230.0,\n",
      "            1404.0\n",
      "          ],\n",
      "          [\n",
      "            230.0,\n",
      "            718.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e4fe3bbb0809b51d59fa5c6d32240053\",\n",
      "    \"text\": \"arXiv\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            187.0,\n",
      "            1422.0\n",
      "          ],\n",
      "          [\n",
      "            187.0,\n",
      "            1526.0\n",
      "          ],\n",
      "          [\n",
      "            220.0,\n",
      "            1526.0\n",
      "          ],\n",
      "          [\n",
      "            220.0,\n",
      "            1422.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "    \"text\": \"GPT4AII: An Ecosystem of Open Source Compressed Language Models\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            330.0,\n",
      "            275.0\n",
      "          ],\n",
      "          [\n",
      "            330.0,\n",
      "            313.0\n",
      "          ],\n",
      "          [\n",
      "            1368.0,\n",
      "            313.0\n",
      "          ],\n",
      "          [\n",
      "            1368.0,\n",
      "            275.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3b6229680e5b76a64d828388fc9558af\",\n",
      "    \"text\": \"Yuvanesh Anand Nomic AI yuvanesh@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            310.0,\n",
      "            351.0\n",
      "          ],\n",
      "          [\n",
      "            310.0,\n",
      "            444.0\n",
      "          ],\n",
      "          [\n",
      "            548.0,\n",
      "            444.0\n",
      "          ],\n",
      "          [\n",
      "            548.0,\n",
      "            351.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2b31179eb0e5f5f7d85c9fb0cb5b961e\",\n",
      "    \"text\": \"Zach Nussbaum Nomic AI zach@nomic. ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            613.0,\n",
      "            355.0\n",
      "          ],\n",
      "          [\n",
      "            613.0,\n",
      "            445.0\n",
      "          ],\n",
      "          [\n",
      "            806.0,\n",
      "            445.0\n",
      "          ],\n",
      "          [\n",
      "            806.0,\n",
      "            355.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e99ec24d75fca645414a8eeba5922394\",\n",
      "    \"text\": \"Aaron Miller Nomic AI aaron@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1174.0,\n",
      "            357.0\n",
      "          ],\n",
      "          [\n",
      "            1174.0,\n",
      "            446.0\n",
      "          ],\n",
      "          [\n",
      "            1367.0,\n",
      "            446.0\n",
      "          ],\n",
      "          [\n",
      "            1367.0,\n",
      "            357.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
      "    \"text\": \"Adam Treat Nomic AI adam@nomic. ai\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            900.0,\n",
      "            357.0\n",
      "          ],\n",
      "          [\n",
      "            900.0,\n",
      "            446.0\n",
      "          ],\n",
      "          [\n",
      "            1079.0,\n",
      "            446.0\n",
      "          ],\n",
      "          [\n",
      "            1079.0,\n",
      "            357.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f49db26031127120e27a8fb9be080262\",\n",
      "    \"text\": \"Richard Guo Ben Schmidt GPT4AIl Community Nomic AI Nomic AI Planet Earth richard@nomic. ai ben@nomic. ai Brandon Duderstadt* Andriy Mulyar* Nomic AI Nomic AI brandon@nomic. ai andriy@nomic.ai Abstract variety of queries, responding only with the now infa-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            387.0,\n",
      "            503.0\n",
      "          ],\n",
      "          [\n",
      "            387.0,\n",
      "            847.0\n",
      "          ],\n",
      "          [\n",
      "            1384.0,\n",
      "            847.0\n",
      "          ],\n",
      "          [\n",
      "            1384.0,\n",
      "            503.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7ca0f2ae4307b5e65fbbf275bd57f0d8\",\n",
      "    \"text\": \"Large language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs re- quire costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            356.0,\n",
      "            879.0\n",
      "          ],\n",
      "          [\n",
      "            356.0,\n",
      "            1127.0\n",
      "          ],\n",
      "          [\n",
      "            793.0,\n",
      "            1127.0\n",
      "          ],\n",
      "          [\n",
      "            793.0,\n",
      "            879.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1078dd84576df5d9cd18dc21562c4667\",\n",
      "    \"text\": \"In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4AII mode] family, as well as the evolution of the GPT4Al] project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4Al models as well as a case study on the subsequent growth of the GPT4AI] open source ecosystem.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            354.0,\n",
      "            1147.0\n",
      "          ],\n",
      "          [\n",
      "            354.0,\n",
      "            1454.0\n",
      "          ],\n",
      "          [\n",
      "            792.0,\n",
      "            1454.0\n",
      "          ],\n",
      "          [\n",
      "            792.0,\n",
      "            1147.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
      "    \"text\": \"1 Introduction\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            314.0,\n",
      "            1493.0\n",
      "          ],\n",
      "          [\n",
      "            314.0,\n",
      "            1515.0\n",
      "          ],\n",
      "          [\n",
      "            509.0,\n",
      "            1515.0\n",
      "          ],\n",
      "          [\n",
      "            509.0,\n",
      "            1493.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cc800a372051047b2ffd4c3251d06344\",\n",
      "    \"text\": \"On March 14 2023, OpenAI released GPT-4, a large language model capable of achieving human level per- formance on a yariety of professional and academic benchmarks. Despite the popularity of the release, the GPT-4 technical report (OpenAl, 2023) contained virtually no details regarding the architecture, hard- ware, training compute, dataset construction, or training method used to create the model, Moreover, users could only access the model through the internet interface at chat.openai.com, which was severely rate limited and unavailable in several locales (e.g. Italy) (BBC News, 2023). Additionally, GPT-4 refused to answer a wide\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            310.0,\n",
      "            1542.0\n",
      "          ],\n",
      "          [\n",
      "            310.0,\n",
      "            1884.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            1884.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            1542.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"2dbce9fa5c8141f6497bfb64323e1a9a\",\n",
      "    \"text\": \"Shared Senior Authorship\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            347.0,\n",
      "            1915.0\n",
      "          ],\n",
      "          [\n",
      "            347.0,\n",
      "            1933.0\n",
      "          ],\n",
      "          [\n",
      "            562.0,\n",
      "            1933.0\n",
      "          ],\n",
      "          [\n",
      "            562.0,\n",
      "            1915.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"83802e9c42af8178ba8f1fdca43809eb\",\n",
      "    \"text\": \"mous \\\"As an AI Language Model, I cannot...\\\" prefix (Vincent, 2023). These transparency and accessibility concerns spurred several developers to begin creating open source large language model (LLM) alternatives. Several grassroots efforts focused on fine tuning Meta\\u2019s open code LLaMA model (Touvron et al., 2023; McMil- lan, 2023), whose weights were leaked on BitTorrent less than_a week prior to the release of GPT-4 (Verge, 2023). GIJT4All started as one of these variants.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            870.0,\n",
      "            850.0\n",
      "          ],\n",
      "          [\n",
      "            870.0,\n",
      "            1095.0\n",
      "          ],\n",
      "          [\n",
      "            1384.0,\n",
      "            1095.0\n",
      "          ],\n",
      "          [\n",
      "            1384.0,\n",
      "            850.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1972dc3f152ccb70dd394560f1398964\",\n",
      "    \"text\": \"In thiAXaper, we tell the story of GPT4AlI. We com- ment on the technical details of the original GPT4Al model (Anand et al., 2023), as well as the evolution of GPT4AIl from a single model to an ecosystem of several models. We remark on the impact that the project has had on the open source community, and discuss future directions. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            871.0,\n",
      "            1104.0\n",
      "          ],\n",
      "          [\n",
      "            871.0,\n",
      "            1380.0\n",
      "          ],\n",
      "          [\n",
      "            1385.0,\n",
      "            1380.0\n",
      "          ],\n",
      "          [\n",
      "            1385.0,\n",
      "            1104.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"733695a3173f6e088d89321305d070f1\",\n",
      "    \"text\": \"2 The Original GPT4AII Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            871.0,\n",
      "            1413.0\n",
      "          ],\n",
      "          [\n",
      "            871.0,\n",
      "            1440.0\n",
      "          ],\n",
      "          [\n",
      "            1266.0,\n",
      "            1440.0\n",
      "          ],\n",
      "          [\n",
      "            1266.0,\n",
      "            1413.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
      "    \"text\": \"2.1 Data Collection and Curation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            871.0,\n",
      "            1465.0\n",
      "          ],\n",
      "          [\n",
      "            871.0,\n",
      "            1482.0\n",
      "          ],\n",
      "          [\n",
      "            1219.0,\n",
      "            1482.0\n",
      "          ],\n",
      "          [\n",
      "            1219.0,\n",
      "            1465.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6ec13ad59960463ba50e9b6bc7fcec29\",\n",
      "    \"text\": \"To train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3,5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023, In particular, we gathered GPT- 3.5-Turbo responses to prompts of three publicly avail- able datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3 (Sanh et al., 2021). Fol- lowing the approach in Stanford Alpaca (Taori et al., 2023), an open source LLaMA variant that came just be- fore GPT4AIl, we focused substantial effort on dataset curation,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            869.0,\n",
      "            1503.0\n",
      "          ],\n",
      "          [\n",
      "            869.0,\n",
      "            1838.0\n",
      "          ],\n",
      "          [\n",
      "            1389.0,\n",
      "            1838.0\n",
      "          ],\n",
      "          [\n",
      "            1389.0,\n",
      "            1503.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c9462cb1f13d8c4b319e4228c23948b8\",\n",
      "    \"text\": \"The collected dataset was loaded into Atlas (Al, 2023)\\u2014a visual interface for exploring and tagging mas\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            872.0,\n",
      "            1851.0\n",
      "          ],\n",
      "          [\n",
      "            872.0,\n",
      "            1902.0\n",
      "          ],\n",
      "          [\n",
      "            1389.0,\n",
      "            1902.0\n",
      "          ],\n",
      "          [\n",
      "            1389.0,\n",
      "            1851.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4864442e74fdf0e16c3fe0e80d73e48b\",\n",
      "    \"text\": \"sive unstructured datasets \\u2014for data curation, Using At\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            872.0,\n",
      "            1905.0\n",
      "          ],\n",
      "          [\n",
      "            872.0,\n",
      "            1935.0\n",
      "          ],\n",
      "          [\n",
      "            1382.0,\n",
      "            1935.0\n",
      "          ],\n",
      "          [\n",
      "            1382.0,\n",
      "            1905.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e846da42683be8472aad51fa00976543\",\n",
      "    \"text\": \"las, we identified and removed subsets of the data where GPT-3.5-Turbo refused to respond, had malformed out- put, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure la.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.0,\n",
      "            259.0\n",
      "          ],\n",
      "          [\n",
      "            322.0,\n",
      "            484.0\n",
      "          ],\n",
      "          [\n",
      "            838.0,\n",
      "            484.0\n",
      "          ],\n",
      "          [\n",
      "            838.0,\n",
      "            259.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9d7097ade60591eb70584599d4462684\",\n",
      "    \"text\": \"2.2. Model Training\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            324.0,\n",
      "            510.0\n",
      "          ],\n",
      "          [\n",
      "            324.0,\n",
      "            535.0\n",
      "          ],\n",
      "          [\n",
      "            532.0,\n",
      "            535.0\n",
      "          ],\n",
      "          [\n",
      "            532.0,\n",
      "            510.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7d5b27a26c06285c662b93db7b659140\",\n",
      "    \"text\": \"The original GPT4AII model was a fine tuned variant of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine tuning process. Detailed model hyper-parameters and training code can be found in our associated code repository\\u2019.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            323.0,\n",
      "            549.0\n",
      "          ],\n",
      "          [\n",
      "            323.0,\n",
      "            742.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            742.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            549.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"9d7097ade60591eb70584599d4462684\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"563b4046bd6e1d3c94d65c78a25a35fc\",\n",
      "    \"text\": \"2.3 Model Access\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            325.0,\n",
      "            768.0\n",
      "          ],\n",
      "          [\n",
      "            325.0,\n",
      "            787.0\n",
      "          ],\n",
      "          [\n",
      "            512.0,\n",
      "            787.0\n",
      "          ],\n",
      "          [\n",
      "            512.0,\n",
      "            768.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a0aa7d4d319c6bc0314ea8ef359c88cf\",\n",
      "    \"text\": \"We publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hard- ware without transferring data to a 3rd party service.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            323.0,\n",
      "            806.0\n",
      "          ],\n",
      "          [\n",
      "            323.0,\n",
      "            945.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            945.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            806.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"563b4046bd6e1d3c94d65c78a25a35fc\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9bcea687b18e61c18e3d1e774e3afee1\",\n",
      "    \"text\": \"Our research and development costs were dominated by ~$800 in GPU spend (rented from Lambda Labs and Paperspace) and ~$500 in OpenAl API spend. Our final GPT4AII model could be trained in about eight hours ona Lambda Labs DGX A100 8x 80GB for a total cost of ~$100.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            325.0,\n",
      "            948.0\n",
      "          ],\n",
      "          [\n",
      "            325.0,\n",
      "            1107.0\n",
      "          ],\n",
      "          [\n",
      "            832.0,\n",
      "            1107.0\n",
      "          ],\n",
      "          [\n",
      "            832.0,\n",
      "            948.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"563b4046bd6e1d3c94d65c78a25a35fc\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cbfb9aa9127dfca004d2dd75155a629c\",\n",
      "    \"text\": \"2.4 Model Evaluation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            324.0,\n",
      "            1137.0\n",
      "          ],\n",
      "          [\n",
      "            324.0,\n",
      "            1155.0\n",
      "          ],\n",
      "          [\n",
      "            553.0,\n",
      "            1155.0\n",
      "          ],\n",
      "          [\n",
      "            553.0,\n",
      "            1137.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"db62f503c16b1df3b8e9551a1dc5533f\",\n",
      "    \"text\": \"We performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowl- edge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace. Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100. We found that GPT4All produces stochastically lower ground truth perplexitics than alpaca-lora (Anand et al., 2023).\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.0,\n",
      "            1175.0\n",
      "          ],\n",
      "          [\n",
      "            322.0,\n",
      "            1477.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            1477.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            1175.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cbfb9aa9127dfca004d2dd75155a629c\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0f2ac1ad48e313fde439d850f90442c6\",\n",
      "    \"text\": \"3 From a Model to an Ecosystem\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.0,\n",
      "            1508.0\n",
      "          ],\n",
      "          [\n",
      "            322.0,\n",
      "            1536.0\n",
      "          ],\n",
      "          [\n",
      "            731.0,\n",
      "            1536.0\n",
      "          ],\n",
      "          [\n",
      "            731.0,\n",
      "            1508.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f4f0c6e1d309c744fc08d0eafe010419\",\n",
      "    \"text\": \"3.1 GPT4AII-J: Repository Growth and the implications of the LLaMA License\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.0,\n",
      "            1557.0\n",
      "          ],\n",
      "          [\n",
      "            322.0,\n",
      "            1606.0\n",
      "          ],\n",
      "          [\n",
      "            765.0,\n",
      "            1606.0\n",
      "          ],\n",
      "          [\n",
      "            765.0,\n",
      "            1557.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"884fd329debd5992e62f88a7aec7a056\",\n",
      "    \"text\": \"The GPT4AIl repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants. As the Nomic discord, the home of online discussion about GPT4AII, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.0,\n",
      "            1623.0\n",
      "          ],\n",
      "          [\n",
      "            319.0,\n",
      "            1874.0\n",
      "          ],\n",
      "          [\n",
      "            830.0,\n",
      "            1874.0\n",
      "          ],\n",
      "          [\n",
      "            830.0,\n",
      "            1623.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"f4f0c6e1d309c744fc08d0eafe010419\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
      "    \"text\": \"hups://github.com/nomic-ai/gpttall\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            353.0,\n",
      "            1898.0\n",
      "          ],\n",
      "          [\n",
      "            353.0,\n",
      "            1916.0\n",
      "          ],\n",
      "          [\n",
      "            625.0,\n",
      "            1916.0\n",
      "          ],\n",
      "          [\n",
      "            625.0,\n",
      "            1898.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8628305dbb5c0c282971a35a1895f6d2\",\n",
      "    \"text\": \"The LLaMA model that GPT4AII was based on was licensed for research only, which severely limited the set of domains that GPT4AII could be applied in. As a response to this, the Nomic team repeated the model training procedure of the original GPT4AII model, but based on the already open source and commercially li- censed GPT-J model (Wang and Komatsuzaki, 2021). GPT4AII-J also had an augmented training set, which contained multi-turm QA examples and creative writing such as poetry, rap, and short stories. The creative writ- ing prompts were generated by filling in schemas such as \\\"Write a [CREATIVE STORY TYPE] about [NOUN] in the style of [PERSON].\\\" We again employed Atlas to curate the prompt-response pairs in this data set.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            874.0,\n",
      "            265.0\n",
      "          ],\n",
      "          [\n",
      "            874.0,\n",
      "            662.0\n",
      "          ],\n",
      "          [\n",
      "            1390.0,\n",
      "            662.0\n",
      "          ],\n",
      "          [\n",
      "            1390.0,\n",
      "            265.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2c3d8b98ff7a64d7349e31a728a61e4c\",\n",
      "    \"text\": \"Our evaluation methodology also evolved as the project grew. In particular, we began evaluating GPT4All models using a suite of seven reasoning tasks that were used for evaluation of the Databricks Dolly (Conover et al., 2023b) model, which was re- leased on April 12, 2023. Unfortunately, GPT4AII-J did not outperform other prominent open source models on this evaluation. As a result, we endeavoured to create a model that did,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.0,\n",
      "            668.0\n",
      "          ],\n",
      "          [\n",
      "            873.0,\n",
      "            913.0\n",
      "          ],\n",
      "          [\n",
      "            1385.0,\n",
      "            913.0\n",
      "          ],\n",
      "          [\n",
      "            1385.0,\n",
      "            668.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
      "    \"text\": \"3.2. GPT4All-Snoozy: the Emergence of the GPT4All Ecosystem\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.0,\n",
      "            946.0\n",
      "          ],\n",
      "          [\n",
      "            873.0,\n",
      "            998.0\n",
      "          ],\n",
      "          [\n",
      "            1315.0,\n",
      "            998.0\n",
      "          ],\n",
      "          [\n",
      "            1315.0,\n",
      "            946.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"01954c5a8dd94aae91c5a396fc98d0ab\",\n",
      "    \"text\": \"GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4All models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base mcs\\u00a5# due to its superior base metrics when compared to orp Next, GPT4All-Snoozy incor- porated the Dolly\\u2019s trating data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4AII-Snoozy. As shown in Figure 1, GPT4AIl-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            869.0,\n",
      "            1015.0\n",
      "          ],\n",
      "          [\n",
      "            869.0,\n",
      "            1370.0\n",
      "          ],\n",
      "          [\n",
      "            1382.0,\n",
      "            1370.0\n",
      "          ],\n",
      "          [\n",
      "            1382.0,\n",
      "            1015.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"72c3b96bf66b56ffe45832ddfda45a2e\",\n",
      "    \"text\": \"Concurrently with the development of GPT4AlI, sev- eral organizations such as LMSys, Stability Al, BAIR, and Databricks built and deployed open source language models, We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more Tesources were developing source language models, we decided to pivot our effort away from training increas: ingly capable models and towards providing easy access to the plethora of models being produced by the open source community. Practically, this meant spending our time compressing open source models for use on com- modity hardware, providing stable and simple high level model APIs, and supporting a GUI for no code model experimentation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.0,\n",
      "            1381.0\n",
      "          ],\n",
      "          [\n",
      "            867.0,\n",
      "            1799.0\n",
      "          ],\n",
      "          [\n",
      "            1380.0,\n",
      "            1799.0\n",
      "          ],\n",
      "          [\n",
      "            1380.0,\n",
      "            1381.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8a14f721bb69583c86530d42b9a254e1\",\n",
      "    \"text\": \"33 The Current State of GPT4AlL\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.0,\n",
      "            1829.0\n",
      "          ],\n",
      "          [\n",
      "            867.0,\n",
      "            1851.0\n",
      "          ],\n",
      "          [\n",
      "            1219.0,\n",
      "            1851.0\n",
      "          ],\n",
      "          [\n",
      "            1219.0,\n",
      "            1829.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3824d3746129eff2f0cbc8ead93c8ea5\",\n",
      "    \"text\": \"Today, GPT4AII is focused on improving the accessi bility of open source language models. The repository\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.0,\n",
      "            1870.0\n",
      "          ],\n",
      "          [\n",
      "            867.0,\n",
      "            1926.0\n",
      "          ],\n",
      "          [\n",
      "            1372.0,\n",
      "            1926.0\n",
      "          ],\n",
      "          [\n",
      "            1372.0,\n",
      "            1870.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"8a14f721bb69583c86530d42b9a254e1\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"583893028def4f6b9b760a521a2d550d\",\n",
      "    \"text\": \"@) (b) (\\u00a9) (d)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            435.0,\n",
      "            520.0\n",
      "          ],\n",
      "          [\n",
      "            435.0,\n",
      "            553.0\n",
      "          ],\n",
      "          [\n",
      "            1245.0,\n",
      "            553.0\n",
      "          ],\n",
      "          [\n",
      "            1245.0,\n",
      "            520.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"8a14f721bb69583c86530d42b9a254e1\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f0884a56bfed4a6941eceb540d5d46a1\",\n",
      "    \"text\": \"Figure 1: TSNE visualizations showing the progression of the GPT4AII train set. Panel (a) shows the original uncurated data, The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4All data after curation. This panel, as well as panels (c) and (d) are 10 colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appearl. Panel (c) shows the GPT4AII-J dataset. The \\\"starburst\\\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            316.0,\n",
      "            572.0\n",
      "          ],\n",
      "          [\n",
      "            316.0,\n",
      "            796.0\n",
      "          ],\n",
      "          [\n",
      "            1385.0,\n",
      "            796.0\n",
      "          ],\n",
      "          [\n",
      "            1385.0,\n",
      "            572.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"8a14f721bb69583c86530d42b9a254e1\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"e23b9c1bfe87745da68648565d5b8085\",\n",
      "    \"text\": \"Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 63.4 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 \\u00a9 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4AIl LLaMa Lora 7B* 73.1 77.6 721 67.8 SIL 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 15 71.3 60.9 442 43.4 65.3 GPT4AIl Falcon 71.6 79.8 74.9 70.1 67.9 Ba 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 ng 74.2 50.9 64 68.8 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023b) 56.7 75.4 at 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT, 73.9 66.1 59.8 43.3 4B4 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 42.6 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 ue) 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 71.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned\\u2019 (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 78 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 48 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 49 Wizard 7B xu et al., 2023) 4 712 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 41.6 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 el 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 48 4 OS text-davinci-003 88.1 83.8 83.4 715.8 83.9 63.9 SLO Ba\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.0,\n",
      "            833.0\n",
      "          ],\n",
      "          [\n",
      "            321.0,\n",
      "            1652.0\n",
      "          ],\n",
      "          [\n",
      "            1376.0,\n",
      "            1652.0\n",
      "          ],\n",
      "          [\n",
      "            1376.0,\n",
      "            833.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"8a14f721bb69583c86530d42b9a254e1\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0298caeafb9fe2344eef79e4f3a16628\",\n",
      "    \"text\": \"Table 1: Evaluations of all language models in the GPT4AIl ecosystem as of August 1, 2023, Code models are not included. OpenAI\\u2019s text-davinci-003 is included as a point of comparison. The best overall performing model in the GPT4AIl ecosystem, Nous-Hermes?, achieves over 92% of the average performance of text-davinci-003, Models marked with an asterisk were available in the ecosystem as of the release of GPT4All-Snoozy, Note that at release, GPT4AII-Snoozy had the best average performance of any model in the ecosystem. Bolded numbers indicate the best performing model as of August 1, 2023\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            308.0,\n",
      "            1677.0\n",
      "          ],\n",
      "          [\n",
      "            308.0,\n",
      "            1850.0\n",
      "          ],\n",
      "          [\n",
      "            1378.0,\n",
      "            1850.0\n",
      "          ],\n",
      "          [\n",
      "            1378.0,\n",
      "            1677.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"8a14f721bb69583c86530d42b9a254e1\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fae05d8e02ce0c387969c227af5f183a\",\n",
      "    \"text\": \"Github Repo Growth\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            776.0,\n",
      "            294.0\n",
      "          ],\n",
      "          [\n",
      "            776.0,\n",
      "            313.0\n",
      "          ],\n",
      "          [\n",
      "            942.0,\n",
      "            313.0\n",
      "          ],\n",
      "          [\n",
      "            942.0,\n",
      "            294.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"78d7c4d499039c1e0c224f2dfa0fc11c\",\n",
      "    \"text\": \"50000 | \\u2014\\u2014 GPTAAIL \\u2014 UaMA \\u2014 Alpaca 40000 g 30000 a 2 3 r=] & 20000 4 10000 \\u00b0\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            538.0,\n",
      "            320.0\n",
      "          ],\n",
      "          [\n",
      "            538.0,\n",
      "            680.0\n",
      "          ],\n",
      "          [\n",
      "            715.0,\n",
      "            680.0\n",
      "          ],\n",
      "          [\n",
      "            715.0,\n",
      "            320.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"fae05d8e02ce0c387969c227af5f183a\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9e8303190b5c2c8d15df54dfef4873c3\",\n",
      "    \"text\": \"0 20 40 60\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            633.0,\n",
      "            694.0\n",
      "          ],\n",
      "          [\n",
      "            633.0,\n",
      "            722.0\n",
      "          ],\n",
      "          [\n",
      "            832.0,\n",
      "            722.0\n",
      "          ],\n",
      "          [\n",
      "            832.0,\n",
      "            694.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"fae05d8e02ce0c387969c227af5f183a\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"083e35edc20211ce5254d8e2294c0d26\",\n",
      "    \"text\": \"80 100 \\u00ab120s 140\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            877.0,\n",
      "            702.0\n",
      "          ],\n",
      "          [\n",
      "            877.0,\n",
      "            713.0\n",
      "          ],\n",
      "          [\n",
      "            1084.0,\n",
      "            713.0\n",
      "          ],\n",
      "          [\n",
      "            1084.0,\n",
      "            702.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"fae05d8e02ce0c387969c227af5f183a\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"24465d3d1cdb40f3ef70df159f83997e\",\n",
      "    \"text\": \"Days Since Launch\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            796.0,\n",
      "            721.0\n",
      "          ],\n",
      "          [\n",
      "            796.0,\n",
      "            735.0\n",
      "          ],\n",
      "          [\n",
      "            924.0,\n",
      "            735.0\n",
      "          ],\n",
      "          [\n",
      "            924.0,\n",
      "            721.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ad937a483ab5c1fc8ab9ba6b62f063fb\",\n",
      "    \"text\": \"Figure 2: Comparison of the github start growth of GPT4All, Meta\\u2019s LLaMA, and Stanford\\u2019s Alpaca. We conjecture that GPT4AIl achieved and maintains faster ecosystem growth due to the focus on access, which allows more users\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.0,\n",
      "            769.0\n",
      "          ],\n",
      "          [\n",
      "            319.0,\n",
      "            822.0\n",
      "          ],\n",
      "          [\n",
      "            1383.0,\n",
      "            822.0\n",
      "          ],\n",
      "          [\n",
      "            1383.0,\n",
      "            769.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"24465d3d1cdb40f3ef70df159f83997e\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"02623e0caa56000a521f4f25a3f4658d\",\n",
      "    \"text\": \"to meaningfully participate.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.0,\n",
      "            826.0\n",
      "          ],\n",
      "          [\n",
      "            319.0,\n",
      "            849.0\n",
      "          ],\n",
      "          [\n",
      "            579.0,\n",
      "            849.0\n",
      "          ],\n",
      "          [\n",
      "            579.0,\n",
      "            826.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"24465d3d1cdb40f3ef70df159f83997e\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cbdae924621d9535a0dd698c1b5d4c73\",\n",
      "    \"text\": \"provides compressed versions of open source models for use on commodity hardware, stable and simple high level model APIs, and a GUI for no code model ex- perimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.0,\n",
      "            907.0\n",
      "          ],\n",
      "          [\n",
      "            319.0,\n",
      "            1067.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1067.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            907.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"24465d3d1cdb40f3ef70df159f83997e\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0216c5b98b9aed284fcbe0dad1849324\",\n",
      "    \"text\": \"GPT4All currently provides native support and benchmark data for over 35 models (see Figure 1), and includes several models co-developed with industry part- ners such as Replit and Hugging Face. GPT4AII also provides high level model APIs in languages includ- ing Python, Typescript, Go, C#, and Java, among oth- ers. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4AII user data is collected on an opt in basis.) GPT4AIl has be- come the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others, GPT4AII is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            317.0,\n",
      "            1081.0\n",
      "          ],\n",
      "          [\n",
      "            317.0,\n",
      "            1616.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1616.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1081.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"24465d3d1cdb40f3ef70df159f83997e\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0bc8c617a21a6dc13b8f7f58ff30d9cf\",\n",
      "    \"text\": \"4 The Future of GPT4AIl\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            316.0,\n",
      "            1652.0\n",
      "          ],\n",
      "          [\n",
      "            316.0,\n",
      "            1674.0\n",
      "          ],\n",
      "          [\n",
      "            642.0,\n",
      "            1674.0\n",
      "          ],\n",
      "          [\n",
      "            642.0,\n",
      "            1652.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a838b099edaf32d0fe75a4fb3b6ed7cb\",\n",
      "    \"text\": \"In the future, we will continue to grow GPT4AI, sup- porting it as the de facto solution for LLM accessibil- ity. Concretely, this means continuing to compress and distribute important open-source language models de- veloped by the community, as well as compressing and distributing increasingly multimodal AI models, Fur- thermore, we will expand the set of hardware devices that GPT4AII models run on, so that GPT4AIl models\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            316.0,\n",
      "            1706.0\n",
      "          ],\n",
      "          [\n",
      "            316.0,\n",
      "            1929.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1929.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1706.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"0bc8c617a21a6dc13b8f7f58ff30d9cf\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1f5894bc80ac11427824b2c632168961\",\n",
      "    \"text\": \"\\u201cjust work\\\" on any machine, whether it comes equipped with Apple Metal silicon, NVIDIA, AMD, or other edge- accelerated hardware, Overall, we envision a world where anyone, anywhere, with any machine, can access and contribute to the cutting edge of AI.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            870.0,\n",
      "            909.0\n",
      "          ],\n",
      "          [\n",
      "            870.0,\n",
      "            1045.0\n",
      "          ],\n",
      "          [\n",
      "            1386.0,\n",
      "            1045.0\n",
      "          ],\n",
      "          [\n",
      "            1386.0,\n",
      "            909.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"0bc8c617a21a6dc13b8f7f58ff30d9cf\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b11387b7bac0f6b50f03ff010c8a4b41\",\n",
      "    \"text\": \"Limitations\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.0,\n",
      "            1081.0\n",
      "          ],\n",
      "          [\n",
      "            873.0,\n",
      "            1103.0\n",
      "          ],\n",
      "          [\n",
      "            1010.0,\n",
      "            1103.0\n",
      "          ],\n",
      "          [\n",
      "            1010.0,\n",
      "            1081.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"716d5585a6919f6af6c3249d7169e1f2\",\n",
      "    \"text\": \"By enabling uk large language models, the GPT4AII project also inherits many of the ethical con- cems associated with generative models. Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., in- structions on building bioweapons), While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of in- creasingly secretive research groups, We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.0,\n",
      "            1099.0\n",
      "          ],\n",
      "          [\n",
      "            873.0,\n",
      "            1526.0\n",
      "          ],\n",
      "          [\n",
      "            1388.0,\n",
      "            1526.0\n",
      "          ],\n",
      "          [\n",
      "            1388.0,\n",
      "            1099.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"b11387b7bac0f6b50f03ff010c8a4b41\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fb479ef670472b8c32387e621ec1214f\",\n",
      "    \"text\": \"Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly includ- ing the GPT4AII open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4AII effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standard- ized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit as: signment, and hope to be able to support some of this research ourselves in the future\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            875.0,\n",
      "            1534.0\n",
      "          ],\n",
      "          [\n",
      "            875.0,\n",
      "            1899.0\n",
      "          ],\n",
      "          [\n",
      "            1391.0,\n",
      "            1899.0\n",
      "          ],\n",
      "          [\n",
      "            1391.0,\n",
      "            1534.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"b11387b7bac0f6b50f03ff010c8a4b41\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
      "    \"text\": \"References Nomic AT. 2023. Atlas. https://atlas.nomic.ai/.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            325.0,\n",
      "            260.0\n",
      "          ],\n",
      "          [\n",
      "            325.0,\n",
      "            329.0\n",
      "          ],\n",
      "          [\n",
      "            830.0,\n",
      "            329.0\n",
      "          ],\n",
      "          [\n",
      "            830.0,\n",
      "            260.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ff447f96b6bf72627398a07e3eaad24a\",\n",
      "    \"text\": \"Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al- shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hes- low, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            325.0,\n",
      "            356.0\n",
      "          ],\n",
      "          [\n",
      "            325.0,\n",
      "            536.0\n",
      "          ],\n",
      "          [\n",
      "            841.0,\n",
      "            536.0\n",
      "          ],\n",
      "          [\n",
      "            841.0,\n",
      "            356.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7c3f0c3564467fdaab3a993349e794bc\",\n",
      "    \"text\": \"Yuvanesh Anand, Zach Nussbaum, Brandon Duder- stadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo, https: //github.com/nomic-ai/gpt4all.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            326.0,\n",
      "            562.0\n",
      "          ],\n",
      "          [\n",
      "            326.0,\n",
      "            687.0\n",
      "          ],\n",
      "          [\n",
      "            841.0,\n",
      "            687.0\n",
      "          ],\n",
      "          [\n",
      "            841.0,\n",
      "            562.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"96b99fb92c077a36f47b747d61206825\",\n",
      "    \"text\": \"BBC News. 2023. Chatgpt banned in italy over privacy concerns. BBC News.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            326.0,\n",
      "            714.0\n",
      "          ],\n",
      "          [\n",
      "            326.0,\n",
      "            766.0\n",
      "          ],\n",
      "          [\n",
      "            837.0,\n",
      "            766.0\n",
      "          ],\n",
      "          [\n",
      "            837.0,\n",
      "            714.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9d2b6c54458ad97d68464d08a873abd9\",\n",
      "    \"text\": \"Stella Biderman, Hailey Schoelkopf, Quentin An- thony, Herbie Bradley, Kyle O\\u2019Brien, Eric Hal- lahan, Mohammad Aflah Khan, Shivanshu Puro- hit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pythia: A suite for analyzing large language models across training and scaling.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            325.0,\n",
      "            788.0\n",
      "          ],\n",
      "          [\n",
      "            325.0,\n",
      "            964.0\n",
      "          ],\n",
      "          [\n",
      "            841.0,\n",
      "            964.0\n",
      "          ],\n",
      "          [\n",
      "            841.0,\n",
      "            788.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"28822eaa42869bc6296dca0488854eb4\",\n",
      "    \"text\": \"Harrison Chase, 2022. langchain. https://github. com/langchain-ai/langchain.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            325.0,\n",
      "            990.0\n",
      "          ],\n",
      "          [\n",
      "            325.0,\n",
      "            1038.0\n",
      "          ],\n",
      "          [\n",
      "            840.0,\n",
      "            1038.0\n",
      "          ],\n",
      "          [\n",
      "            840.0,\n",
      "            990.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2829deeb1aef68b7dd984491582b736d\",\n",
      "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing the magic of chatgpt with open mod- els.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            324.0,\n",
      "            1063.0\n",
      "          ],\n",
      "          [\n",
      "            324.0,\n",
      "            1185.0\n",
      "          ],\n",
      "          [\n",
      "            839.0,\n",
      "            1185.0\n",
      "          ],\n",
      "          [\n",
      "            839.0,\n",
      "            1063.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"28822eaa42869bc6296dca0488854eb4\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e815f282e0d35e8bb03aa8bba15b9157\",\n",
      "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing the world\\u2019s first truly open instruction- tuned Im.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            323.0,\n",
      "            1214.0\n",
      "          ],\n",
      "          [\n",
      "            323.0,\n",
      "            1338.0\n",
      "          ],\n",
      "          [\n",
      "            839.0,\n",
      "            1338.0\n",
      "          ],\n",
      "          [\n",
      "            839.0,\n",
      "            1214.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"28822eaa42869bc6296dca0488854eb4\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ecbe83b2f160b4993aa56eaf343dff0a\",\n",
      "    \"text\": \"Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal- Jace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic re- search. Blog post.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.0,\n",
      "            1366.0\n",
      "          ],\n",
      "          [\n",
      "            322.0,\n",
      "            1469.0\n",
      "          ],\n",
      "          [\n",
      "            839.0,\n",
      "            1469.0\n",
      "          ],\n",
      "          [\n",
      "            839.0,\n",
      "            1366.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"28822eaa42869bc6296dca0488854eb4\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4e1128513585d8d278a7322894635447\",\n",
      "    \"text\": \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen, 2021. Lora: Low-rank adaptation of large language models,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            320.0,\n",
      "            1493.0\n",
      "          ],\n",
      "          [\n",
      "            320.0,\n",
      "            1598.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1598.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1493.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"28822eaa42869bc6296dca0488854eb4\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "    \"text\": \"imartinez. 2023. privategpt, https://github.com/ imartinez/privateGPT.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.0,\n",
      "            1621.0\n",
      "          ],\n",
      "          [\n",
      "            319.0,\n",
      "            1672.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1672.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            1621.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a7349787d70d9c2093d459fe3ca5c693\",\n",
      "    \"text\": \"Oscar Leo, 2023. GitHub: The Fastest Growing Repos- itories of AJ] Time.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            318.0,\n",
      "            1696.0\n",
      "          ],\n",
      "          [\n",
      "            318.0,\n",
      "            1743.0\n",
      "          ],\n",
      "          [\n",
      "            837.0,\n",
      "            1743.0\n",
      "          ],\n",
      "          [\n",
      "            837.0,\n",
      "            1696.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"65931a58c527e7b109596a20f87f1355\",\n",
      "    \"text\": \"Robert McMillan, 2023. A meta platforms leak put powerful ai in the hands of everyone. The Wall Street Journal\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            318.0,\n",
      "            1772.0\n",
      "          ],\n",
      "          [\n",
      "            318.0,\n",
      "            1845.0\n",
      "          ],\n",
      "          [\n",
      "            833.0,\n",
      "            1845.0\n",
      "          ],\n",
      "          [\n",
      "            833.0,\n",
      "            1772.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4f034182069da34ff9a3a3f11f943cab\",\n",
      "    \"text\": \"MindsDB, 2023, Mindsdb. https://github.com/ mindsdb/mindsdb, GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            318.0,\n",
      "            1876.0\n",
      "          ],\n",
      "          [\n",
      "            318.0,\n",
      "            1925.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            1925.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            1876.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7b04324f6e6e6d43bcbc6a47c8d77d6e\",\n",
      "    \"text\": \"MosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable Ilms. Accessed: 2023-08-07.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            879.0,\n",
      "            265.0\n",
      "          ],\n",
      "          [\n",
      "            879.0,\n",
      "            335.0\n",
      "          ],\n",
      "          [\n",
      "            1390.0,\n",
      "            335.0\n",
      "          ],\n",
      "          [\n",
      "            1390.0,\n",
      "            265.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d3246b135b36ddd7688886a776431694\",\n",
      "    \"text\": \"Nous-Research. 2023a. gpt4-x-vicuna-13b. https: //huggingface.co/NousResearch/ gpt4-x-vicuna-13b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            879.0,\n",
      "            366.0\n",
      "          ],\n",
      "          [\n",
      "            879.0,\n",
      "            441.0\n",
      "          ],\n",
      "          [\n",
      "            1390.0,\n",
      "            441.0\n",
      "          ],\n",
      "          [\n",
      "            1390.0,\n",
      "            366.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b215473fa719e0470c5dc3b8b2d6c273\",\n",
      "    \"text\": \"Nous-Research. 2023b. Nous-hermes-13b. https: //huggingface.co/NousResearch/ Nous-Hermes~13b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            879.0,\n",
      "            468.0\n",
      "          ],\n",
      "          [\n",
      "            879.0,\n",
      "            542.0\n",
      "          ],\n",
      "          [\n",
      "            1389.0,\n",
      "            542.0\n",
      "          ],\n",
      "          [\n",
      "            1389.0,\n",
      "            468.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"375e366de6040fb4cb6eb069941c9bbf\",\n",
      "    \"text\": \"Nous-Research. 2023c. | Nous-hermes-Ilama-2-7b. https: //huggingface.co/NousResearch/ Nous-Hermes-llama-2-7b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            879.0,\n",
      "            565.0\n",
      "          ],\n",
      "          [\n",
      "            879.0,\n",
      "            665.0\n",
      "          ],\n",
      "          [\n",
      "            1389.0,\n",
      "            665.0\n",
      "          ],\n",
      "          [\n",
      "            1389.0,\n",
      "            565.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5fa14f83af115bdda91a6ea497ee24f5\",\n",
      "    \"text\": \"Nous-Research. 2023d. Redmond-puffin-13b. https: //huggingface.co/NousResearch/ Redmond-Puf fin-13B. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            878.0,\n",
      "            696.0\n",
      "          ],\n",
      "          [\n",
      "            878.0,\n",
      "            770.0\n",
      "          ],\n",
      "          [\n",
      "            1388.0,\n",
      "            770.0\n",
      "          ],\n",
      "          [\n",
      "            1388.0,\n",
      "            696.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ad8404b5ba525ba55c88db3507afea61\",\n",
      "    \"text\": \"OpenAI. 2023. Gpt-4 technical report.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            878.0,\n",
      "            797.0\n",
      "          ],\n",
      "          [\n",
      "            878.0,\n",
      "            819.0\n",
      "          ],\n",
      "          [\n",
      "            1232.0,\n",
      "            819.0\n",
      "          ],\n",
      "          [\n",
      "            1232.0,\n",
      "            797.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d0f9c14256bd5d6d644a9fba0c2a4048\",\n",
      "    \"text\": \"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Teshala Neeraj, Jos Rozen, Ab- heesht Sharma, Ar}irea Santilli, Thibault Fevry, Ja- son Alan Fries, RxAn Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            878.0,\n",
      "            845.0\n",
      "          ],\n",
      "          [\n",
      "            878.0,\n",
      "            1228.0\n",
      "          ],\n",
      "          [\n",
      "            1387.0,\n",
      "            1228.0\n",
      "          ],\n",
      "          [\n",
      "            1387.0,\n",
      "            845.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"ad8404b5ba525ba55c88db3507afea61\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6d81f7374a1170f44fc2017eb686e42e\",\n",
      "    \"text\": \"Stability-AL 2023. Stablelm. https: //github.com/ Stability-AI/StableLM. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            877.0,\n",
      "            1255.0\n",
      "          ],\n",
      "          [\n",
      "            877.0,\n",
      "            1303.0\n",
      "          ],\n",
      "          [\n",
      "            1386.0,\n",
      "            1303.0\n",
      "          ],\n",
      "          [\n",
      "            1386.0,\n",
      "            1255.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
      "    \"text\": \"StanGirard. 2023. quivr. https://github.com/ StanGirard/quivr, GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            876.0,\n",
      "            1331.0\n",
      "          ],\n",
      "          [\n",
      "            876.0,\n",
      "            1379.0\n",
      "          ],\n",
      "          [\n",
      "            1386.0,\n",
      "            1379.0\n",
      "          ],\n",
      "          [\n",
      "            1386.0,\n",
      "            1331.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5d1bc696851ef79af9375f55b5b41cf3\",\n",
      "    \"text\": \"Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B, Hashimoto. 2023. Stanford alpaca: An instruction-following llama model, https: // github. com/tatsu-lab/stanford_alpaca.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            877.0,\n",
      "            1405.0\n",
      "          ],\n",
      "          [\n",
      "            877.0,\n",
      "            1532.0\n",
      "          ],\n",
      "          [\n",
      "            1391.0,\n",
      "            1532.0\n",
      "          ],\n",
      "          [\n",
      "            1391.0,\n",
      "            1405.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"171ccc2dc868ac8356c784d33399c9e7\",\n",
      "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e9re, Naman Goyal, Bric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample, 2023, Llama: Open and efficient foundation language models,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            876.0,\n",
      "            1561.0\n",
      "          ],\n",
      "          [\n",
      "            876.0,\n",
      "            1736.0\n",
      "          ],\n",
      "          [\n",
      "            1390.0,\n",
      "            1736.0\n",
      "          ],\n",
      "          [\n",
      "            1390.0,\n",
      "            1561.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"96193587a3ec137f8f1402f5ba65703e\",\n",
      "    \"text\": \"The Verge. 2023, Meta\\u2019s powerful ai language model has leaked online \\u2014 what happens now? The Verge\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            874.0,\n",
      "            1769.0\n",
      "          ],\n",
      "          [\n",
      "            874.0,\n",
      "            1818.0\n",
      "          ],\n",
      "          [\n",
      "            1388.0,\n",
      "            1818.0\n",
      "          ],\n",
      "          [\n",
      "            1388.0,\n",
      "            1769.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fc824dd6182933738198e6c1d09a9799\",\n",
      "    \"text\": \"James Vincent. 2023. As an ai generated language model; The phrase that shows how ai is polluting the web. The Verge.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            875.0,\n",
      "            1847.0\n",
      "          ],\n",
      "          [\n",
      "            875.0,\n",
      "            1921.0\n",
      "          ],\n",
      "          [\n",
      "            1387.0,\n",
      "            1921.0\n",
      "          ],\n",
      "          [\n",
      "            1387.0,\n",
      "            1847.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e38c3965189305a5b0d9425724b2281d\",\n",
      "    \"text\": \"| free\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            147.0,\n",
      "            2063.0\n",
      "          ],\n",
      "          [\n",
      "            147.0,\n",
      "            2112.0\n",
      "          ],\n",
      "          [\n",
      "            1556.0,\n",
      "            2112.0\n",
      "          ],\n",
      "          [\n",
      "            1556.0,\n",
      "            2063.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"04c3ff73bf077e14ea3e3fe8d73d17ef\",\n",
      "    \"text\": \"Ben Wang and Aran Komatsuzaki. 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https: //github.com/kingoflolz/ mesh-transformer-jax.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.0,\n",
      "            273.0\n",
      "          ],\n",
      "          [\n",
      "            319.0,\n",
      "            376.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            376.0\n",
      "          ],\n",
      "          [\n",
      "            834.0,\n",
      "            273.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"e38c3965189305a5b0d9425724b2281d\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"52aa2311e47b83680da125d4df87a738\",\n",
      "    \"text\": \"Eric J. Wang. 2023. alpaca-lora. https: //github. com/tloen/alpaca-lora. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            320.0,\n",
      "            397.0\n",
      "          ],\n",
      "          [\n",
      "            320.0,\n",
      "            450.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            450.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            397.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"55b51cf7becc1a40a4f665cb04af4e0d\",\n",
      "    \"text\": \"Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han- nanch Hajishirzi. 2023. Self-instruct: Aligning lan- guage models with self-generated instructions.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.0,\n",
      "            468.0\n",
      "          ],\n",
      "          [\n",
      "            321.0,\n",
      "            571.0\n",
      "          ],\n",
      "          [\n",
      "            837.0,\n",
      "            571.0\n",
      "          ],\n",
      "          [\n",
      "            837.0,\n",
      "            468.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"52aa2311e47b83680da125d4df87a738\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b7ef3aaaa4297d57b181319cc7d5bd15\",\n",
      "    \"text\": \"Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.0,\n",
      "            591.0\n",
      "          ],\n",
      "          [\n",
      "            322.0,\n",
      "            693.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            693.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            591.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"52aa2311e47b83680da125d4df87a738\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"571342fd70ea71de51f9f7281fad43c0\",\n",
      "    \"text\": \"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging Ilm-as-a-judge with mt-bench and chatbot arena.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            323.0,\n",
      "            714.0\n",
      "          ],\n",
      "          [\n",
      "            323.0,\n",
      "            841.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            841.0\n",
      "          ],\n",
      "          [\n",
      "            836.0,\n",
      "            714.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"52aa2311e47b83680da125d4df87a738\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "element_dict = [el.to_dict() for el in elements]\n",
    "output = json.dumps(element_dict, indent=2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, scanned pdf extraction works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We don't see `Table`, table information is not extracted as we expected, lets use different strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table extraction from PDF\n",
    "- Now let’s say that your PDF has tables and let’s say you want to preserve the structure of the tables. \n",
    "- You will have to specify the [strategy](https://unstructured-io.github.io/unstructured/best_practices/strategies.html) parameter as `hi_res`. This will use a combination of computer vision and Optical Character Recognition (OCR) to extract the tables and maintain the structure. \n",
    "It will return both the text and the html of the table. This is super useful for rendering the tables or passing to a LLM.\n",
    "\n",
    "> Note: For even better table extraction Unstructured offers an API that improves upon the existing open source models.\n",
    "\n",
    "> Depending upon machine, you might face different module / library issues, these links might help\n",
    "- https://stackoverflow.com/questions/59690698/modulenotfounderror-no-module-named-lzma-when-building-python-using-pyenv-on\n",
    "- https://unstructured-io.github.io/unstructured/installation/full_installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "elements = partition_pdf(filename=filename,\n",
    "                         infer_table_structure=True,\n",
    "                         strategy='hi_res',\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"Header\",\n",
      "    \"element_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "    \"text\": \"2311.04931v1 [cs.CL] 6 Nov 2023\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.4232136607170105,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            184.92478942871094,\n",
      "            742.0810546875\n",
      "          ],\n",
      "          [\n",
      "            184.92478942871094,\n",
      "            1471.5084228515625\n",
      "          ],\n",
      "          [\n",
      "            232.85177612304688,\n",
      "            1471.5084228515625\n",
      "          ],\n",
      "          [\n",
      "            232.85177612304688,\n",
      "            742.0810546875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e4fe3bbb0809b51d59fa5c6d32240053\",\n",
      "    \"text\": \"arXiv\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            187.0,\n",
      "            1422.0\n",
      "          ],\n",
      "          [\n",
      "            187.0,\n",
      "            1526.0\n",
      "          ],\n",
      "          [\n",
      "            220.0,\n",
      "            1526.0\n",
      "          ],\n",
      "          [\n",
      "            220.0,\n",
      "            1422.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "    \"text\": \"GPT4AII: An Ecosystem of Open Source Compressed Language Models\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.4024125039577484,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            330.05194091796875,\n",
      "            281.6643371582031\n",
      "          ],\n",
      "          [\n",
      "            330.05194091796875,\n",
      "            311.5008544921875\n",
      "          ],\n",
      "          [\n",
      "            1365.037353515625,\n",
      "            311.5008544921875\n",
      "          ],\n",
      "          [\n",
      "            1365.037353515625,\n",
      "            281.6643371582031\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3b6229680e5b76a64d828388fc9558af\",\n",
      "    \"text\": \"Yuvanesh Anand Nomic AI yuvanesh@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.4871161878108978,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            311.674072265625,\n",
      "            351.6892395019531\n",
      "          ],\n",
      "          [\n",
      "            311.674072265625,\n",
      "            446.8622131347656\n",
      "          ],\n",
      "          [\n",
      "            552.4762573242188,\n",
      "            446.8622131347656\n",
      "          ],\n",
      "          [\n",
      "            552.4762573242188,\n",
      "            351.6892395019531\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2b31179eb0e5f5f7d85c9fb0cb5b961e\",\n",
      "    \"text\": \"Zach Nussbaum Nomic AI zach@nomic. ai\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.46962931752204895,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            618.5408935546875,\n",
      "            356.0069580078125\n",
      "          ],\n",
      "          [\n",
      "            618.5408935546875,\n",
      "            448.8507995605469\n",
      "          ],\n",
      "          [\n",
      "            798.0371704101562,\n",
      "            448.8507995605469\n",
      "          ],\n",
      "          [\n",
      "            798.0371704101562,\n",
      "            356.0069580078125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7a7d1c29b06a89db7c7ee29e70877278\",\n",
      "    \"text\": \"Adam Treat Nomic AI adam@nomic. ai\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.4653831720352173,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            904.9122314453125,\n",
      "            356.7784423828125\n",
      "          ],\n",
      "          [\n",
      "            904.9122314453125,\n",
      "            450.34698486328125\n",
      "          ],\n",
      "          [\n",
      "            1080.4359130859375,\n",
      "            450.34698486328125\n",
      "          ],\n",
      "          [\n",
      "            1080.4359130859375,\n",
      "            356.7784423828125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7db0b87ebaf95200e60899e7b95899a4\",\n",
      "    \"text\": \"Aaron Miller Nomic AI aaron@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.528191328048706,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1178.643310546875,\n",
      "            357.61138916015625\n",
      "          ],\n",
      "          [\n",
      "            1178.643310546875,\n",
      "            449.8150939941406\n",
      "          ],\n",
      "          [\n",
      "            1368.121826171875,\n",
      "            449.8150939941406\n",
      "          ],\n",
      "          [\n",
      "            1368.121826171875,\n",
      "            357.61138916015625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"03b1afbbb44842034b8293706639f7cd\",\n",
      "    \"text\": \"Richard Guo Nomic AI richard@nomic. ai\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5810608863830566,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            386.0675048828125,\n",
      "            504.15655517578125\n",
      "          ],\n",
      "          [\n",
      "            386.0675048828125,\n",
      "            597.4337768554688\n",
      "          ],\n",
      "          [\n",
      "            605.2667846679688,\n",
      "            597.4337768554688\n",
      "          ],\n",
      "          [\n",
      "            605.2667846679688,\n",
      "            504.15655517578125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"982987ea2abb7d1d9ec3c815deec5dd1\",\n",
      "    \"text\": \"Ben Schmidt Nomic AI ben@nomic. ai\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6449709534645081,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            764.7431640625,\n",
      "            508.09454345703125\n",
      "          ],\n",
      "          [\n",
      "            764.7431640625,\n",
      "            600.0762329101562\n",
      "          ],\n",
      "          [\n",
      "            935.64404296875,\n",
      "            600.0762329101562\n",
      "          ],\n",
      "          [\n",
      "            935.64404296875,\n",
      "            508.09454345703125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"941dd02cd64fc418c67f37ecd7447eaf\",\n",
      "    \"text\": \"GPT4AIl Community Planet Earth\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5254923105239868,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1093.162353515625,\n",
      "            508.01739501953125\n",
      "          ],\n",
      "          [\n",
      "            1093.162353515625,\n",
      "            567.9408569335938\n",
      "          ],\n",
      "          [\n",
      "            1310.8515625,\n",
      "            567.9408569335938\n",
      "          ],\n",
      "          [\n",
      "            1310.8515625,\n",
      "            508.01739501953125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6ec733c3e3a00bcc21fa6f20cab5d532\",\n",
      "    \"text\": \"Brandon Duderstadt* Nomic AI brandon@nomic. ai\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.44019490480422974,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            495.36895751953125,\n",
      "            655.016845703125\n",
      "          ],\n",
      "          [\n",
      "            495.36895751953125,\n",
      "            748.2459106445312\n",
      "          ],\n",
      "          [\n",
      "            741.5177612304688,\n",
      "            748.2459106445312\n",
      "          ],\n",
      "          [\n",
      "            741.5177612304688,\n",
      "            655.016845703125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e73b527ae3de7105c066be325e6e3457\",\n",
      "    \"text\": \"Andriy Mulyar* Nomic AI andriy@nomic.ai\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6033191084861755,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            977.3466796875,\n",
      "            657.3770141601562\n",
      "          ],\n",
      "          [\n",
      "            977.3466796875,\n",
      "            748.8932495117188\n",
      "          ],\n",
      "          [\n",
      "            1193.7236328125,\n",
      "            748.8932495117188\n",
      "          ],\n",
      "          [\n",
      "            1193.7236328125,\n",
      "            657.3770141601562\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"cb64b467c88027496b27bdf8788314d2\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
      "    \"text\": \"Abstract\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            522.0,\n",
      "            813.0\n",
      "          ],\n",
      "          [\n",
      "            522.0,\n",
      "            847.0\n",
      "          ],\n",
      "          [\n",
      "            627.0,\n",
      "            847.0\n",
      "          ],\n",
      "          [\n",
      "            627.0,\n",
      "            813.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"db9aa1d8179cc3192d44f5a90f3b1826\",\n",
      "    \"text\": \"Large language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs re- quire costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9393344521522522,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            356.5931701660156,\n",
      "            878.8330078125\n",
      "          ],\n",
      "          [\n",
      "            356.5931701660156,\n",
      "            1126.6077880859375\n",
      "          ],\n",
      "          [\n",
      "            795.5686645507812,\n",
      "            1126.6077880859375\n",
      "          ],\n",
      "          [\n",
      "            795.5686645507812,\n",
      "            878.8330078125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"36ed8f41aa2fe1874422c75d79b033a8\",\n",
      "    \"text\": \"variety of queries, responding only with the now infa- mous \\\"As an AI Language Model, I cannot...\\\" prefix (Vincent, 2023). These transparency and accessibility concerns spurred several developers to begin creating open source large language model (LLM) alternatives. Several grassroots efforts focused on fine tuning Meta\\u2019s open code LLaMA model (Touvron et al., 2023; McMil- lan, 2023), whose weights were leaked on BitTorrent less than_a week prior to the release of GPT-4 (Verge, 2023). GIJT4All started as one of these variants.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9476661086082458,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            870.2737426757812,\n",
      "            822.4456176757812\n",
      "          ],\n",
      "          [\n",
      "            870.2737426757812,\n",
      "            1094.8389892578125\n",
      "          ],\n",
      "          [\n",
      "            1389.4317626953125,\n",
      "            1094.8389892578125\n",
      "          ],\n",
      "          [\n",
      "            1389.4317626953125,\n",
      "            822.4456176757812\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3a41b9635b90a4dfd4b38b911c6a9da8\",\n",
      "    \"text\": \"In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4AII mode] family, as well as the evolution of the GPT4Al] project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4Al models as well as a case study on the subsequent growth of the GPT4AI] open source ecosystem.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9432600736618042,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            353.97564697265625,\n",
      "            1145.4993896484375\n",
      "          ],\n",
      "          [\n",
      "            353.97564697265625,\n",
      "            1450.2889404296875\n",
      "          ],\n",
      "          [\n",
      "            797.5936279296875,\n",
      "            1450.2889404296875\n",
      "          ],\n",
      "          [\n",
      "            797.5936279296875,\n",
      "            1145.4993896484375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"25fea872954de1b032ffa137dd0b4924\",\n",
      "    \"text\": \"In thiAXaper, we tell the story of GPT4AlI. We com- ment on the technical details of the original GPT4Al model (Anand et al., 2023), as well as the evolution of GPT4AIl from a single model to an ecosystem of several models. We remark on the impact that the project has had on the open source community, and discuss future directions. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9492385387420654,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            869.222900390625,\n",
      "            1103.2613525390625\n",
      "          ],\n",
      "          [\n",
      "            869.222900390625,\n",
      "            1378.0030517578125\n",
      "          ],\n",
      "          [\n",
      "            1391.3668212890625,\n",
      "            1378.0030517578125\n",
      "          ],\n",
      "          [\n",
      "            1391.3668212890625,\n",
      "            1103.2613525390625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"af5ffcc37642b9d2d0e99532ecb0c4ac\",\n",
      "    \"text\": \"2 The Original GPT4AII Model\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8576385378837585,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            869.8643798828125,\n",
      "            1414.04638671875\n",
      "          ],\n",
      "          [\n",
      "            869.8643798828125,\n",
      "            1437.1588134765625\n",
      "          ],\n",
      "          [\n",
      "            1267.4658203125,\n",
      "            1437.1588134765625\n",
      "          ],\n",
      "          [\n",
      "            1267.4658203125,\n",
      "            1414.04638671875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b86fb3cfbb2562fe20ae819e41db4f63\",\n",
      "    \"text\": \"2.1 Data Collection and Curation\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8208932280540466,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            869.8379516601562,\n",
      "            1464.2177734375\n",
      "          ],\n",
      "          [\n",
      "            869.8379516601562,\n",
      "            1484.450439453125\n",
      "          ],\n",
      "          [\n",
      "            1219.3873291015625,\n",
      "            1484.450439453125\n",
      "          ],\n",
      "          [\n",
      "            1219.3873291015625,\n",
      "            1464.2177734375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"1a2527f9f828de968622402594415f33\",\n",
      "    \"text\": \"1 Introduction\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.835685133934021,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            313.1302185058594,\n",
      "            1491.400146484375\n",
      "          ],\n",
      "          [\n",
      "            313.1302185058594,\n",
      "            1519.2489013671875\n",
      "          ],\n",
      "          [\n",
      "            507.8752136230469,\n",
      "            1519.2489013671875\n",
      "          ],\n",
      "          [\n",
      "            507.8752136230469,\n",
      "            1491.400146484375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"103d30241b8f4f33440cde2f8c062ed1\",\n",
      "    \"text\": \"On March 14 2023, OpenAI released GPT-4, a large language model capable of achieving human level per- formance on a yariety of professional and academic benchmarks. Despite the popularity of the release, the GPT-4 technical report (OpenAl, 2023) contained virtually no details regarding the architecture, hard- ware, training compute, dataset construction, or training method used to create the model, Moreover, users could only access the model through the internet interface at chat.openai.com, which was severely rate limited and unavailable in several locales (e.g. Italy) (BBC News, 2023). Additionally, GPT-4 refused to answer a wide\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9468173980712891,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            308.257568359375,\n",
      "            1541.1007080078125\n",
      "          ],\n",
      "          [\n",
      "            308.257568359375,\n",
      "            1883.820068359375\n",
      "          ],\n",
      "          [\n",
      "            837.3360595703125,\n",
      "            1883.820068359375\n",
      "          ],\n",
      "          [\n",
      "            837.3360595703125,\n",
      "            1541.1007080078125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8d8277c86b679fcbadd288f1bacdf824\",\n",
      "    \"text\": \"To train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3,5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023, In particular, we gathered GPT- 3.5-Turbo responses to prompts of three publicly avail- able datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3 (Sanh et al., 2021). Fol- lowing the approach in Stanford Alpaca (Taori et al., 2023), an open source LLaMA variant that came just be- fore GPT4AIl, we focused substantial effort on dataset curation,\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9404544234275818,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            869.7801513671875,\n",
      "            1503.2587890625\n",
      "          ],\n",
      "          [\n",
      "            869.7801513671875,\n",
      "            1841.6685791015625\n",
      "          ],\n",
      "          [\n",
      "            1397.6998291015625,\n",
      "            1841.6685791015625\n",
      "          ],\n",
      "          [\n",
      "            1397.6998291015625,\n",
      "            1503.2587890625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"655e1b7d92cbf6324e65f613100aa570\",\n",
      "    \"text\": \"* Shared Senior Authorship\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6288467645645142,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            336.6943359375,\n",
      "            1913.42529296875\n",
      "          ],\n",
      "          [\n",
      "            336.6943359375,\n",
      "            1933.592529296875\n",
      "          ],\n",
      "          [\n",
      "            565.4310913085938,\n",
      "            1933.592529296875\n",
      "          ],\n",
      "          [\n",
      "            565.4310913085938,\n",
      "            1913.42529296875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"acb228dd280ec3e448618148ec7de215\",\n",
      "    \"text\": \"The collected dataset was loaded into Atlas (Al, 2023)\\u2014a visual interface for exploring and tagging mas sive unstructured datasets \\u2014for data curation, Using At\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9268862009048462,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            871.0282592773438,\n",
      "            1849.0352783203125\n",
      "          ],\n",
      "          [\n",
      "            871.0282592773438,\n",
      "            1929.71435546875\n",
      "          ],\n",
      "          [\n",
      "            1394.6534423828125,\n",
      "            1929.71435546875\n",
      "          ],\n",
      "          [\n",
      "            1394.6534423828125,\n",
      "            1849.0352783203125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e846da42683be8472aad51fa00976543\",\n",
      "    \"text\": \"las, we identified and removed subsets of the data where GPT-3.5-Turbo refused to respond, had malformed out- put, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure la.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9441848397254944,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            320.89459228515625,\n",
      "            259.8636779785156\n",
      "          ],\n",
      "          [\n",
      "            320.89459228515625,\n",
      "            484.8104553222656\n",
      "          ],\n",
      "          [\n",
      "            838.01318359375,\n",
      "            484.8104553222656\n",
      "          ],\n",
      "          [\n",
      "            838.01318359375,\n",
      "            259.8636779785156\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9d7097ade60591eb70584599d4462684\",\n",
      "    \"text\": \"2.2. Model Training\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8165755867958069,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.9754638671875,\n",
      "            508.0442199707031\n",
      "          ],\n",
      "          [\n",
      "            321.9754638671875,\n",
      "            534.4871215820312\n",
      "          ],\n",
      "          [\n",
      "            534.75830078125,\n",
      "            534.4871215820312\n",
      "          ],\n",
      "          [\n",
      "            534.75830078125,\n",
      "            508.0442199707031\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b719bf54e1020507d0537c2c8d742c8c\",\n",
      "    \"text\": \"The original GPT4AII model was a fine tuned variant\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5734759569168091,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.71484375,\n",
      "            550.2962036132812\n",
      "          ],\n",
      "          [\n",
      "            319.71484375,\n",
      "            573.5416259765625\n",
      "          ],\n",
      "          [\n",
      "            833.6873779296875,\n",
      "            573.5416259765625\n",
      "          ],\n",
      "          [\n",
      "            833.6873779296875,\n",
      "            550.2962036132812\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"9d7097ade60591eb70584599d4462684\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"56a086f1f788c38f50b1466182cb5b0a\",\n",
      "    \"text\": \"of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine tuning process. Detailed model hyper-parameters and training code can be found in our associated code repository\\u2019.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8686403632164001,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            290.8384094238281,\n",
      "            579.4190063476562\n",
      "          ],\n",
      "          [\n",
      "            290.8384094238281,\n",
      "            742.6205444335938\n",
      "          ],\n",
      "          [\n",
      "            855.4992065429688,\n",
      "            742.6205444335938\n",
      "          ],\n",
      "          [\n",
      "            855.4992065429688,\n",
      "            579.4190063476562\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"9d7097ade60591eb70584599d4462684\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b8d7d3d0d64393e2971d1088b368cfed\",\n",
      "    \"text\": \"2.3 Model Access\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8413587808609009,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            323.1849670410156,\n",
      "            764.8734130859375\n",
      "          ],\n",
      "          [\n",
      "            323.1849670410156,\n",
      "            791.444580078125\n",
      "          ],\n",
      "          [\n",
      "            513.9146118164062,\n",
      "            791.444580078125\n",
      "          ],\n",
      "          [\n",
      "            513.9146118164062,\n",
      "            764.8734130859375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"838e5a807702b27e299c0c3343d2cce4\",\n",
      "    \"text\": \"We publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hard- ware without transferring data to a 3rd party service.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9317830204963684,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.9345397949219,\n",
      "            807.614990234375\n",
      "          ],\n",
      "          [\n",
      "            319.9345397949219,\n",
      "            941.8294677734375\n",
      "          ],\n",
      "          [\n",
      "            845.7493286132812,\n",
      "            941.8294677734375\n",
      "          ],\n",
      "          [\n",
      "            845.7493286132812,\n",
      "            807.614990234375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"b8d7d3d0d64393e2971d1088b368cfed\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9bfdc2ba1ef989b79da304187cb93eef\",\n",
      "    \"text\": \"Our research and development costs were dominated by ~$800 in GPU spend (rented from Lambda Labs and Paperspace) and ~$500 in OpenAl API spend. Our final GPT4AII model could be trained in about eight hours ona Lambda Labs DGX A100 8x 80GB for a total cost of ~$100.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9430202841758728,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.70880126953125,\n",
      "            948.4578857421875\n",
      "          ],\n",
      "          [\n",
      "            322.70880126953125,\n",
      "            1109.8153076171875\n",
      "          ],\n",
      "          [\n",
      "            835.965576171875,\n",
      "            1109.8153076171875\n",
      "          ],\n",
      "          [\n",
      "            835.965576171875,\n",
      "            948.4578857421875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"b8d7d3d0d64393e2971d1088b368cfed\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
      "    \"text\": \"2.4 Model Evaluation\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8239712715148926,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            323.6431884765625,\n",
      "            1135.2135009765625\n",
      "          ],\n",
      "          [\n",
      "            323.6431884765625,\n",
      "            1159.323486328125\n",
      "          ],\n",
      "          [\n",
      "            556.37451171875,\n",
      "            1159.323486328125\n",
      "          ],\n",
      "          [\n",
      "            556.37451171875,\n",
      "            1135.2135009765625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5e768b03fb279be64b77679e2d1990f8\",\n",
      "    \"text\": \"We performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowl- edge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace. Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100. We found that GPT4All produces stochastically lower ground truth perplexitics than alpaca-lora (Anand et al., 2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9474015235900879,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.9371643066406,\n",
      "            1175.1939697265625\n",
      "          ],\n",
      "          [\n",
      "            321.9371643066406,\n",
      "            1475.82763671875\n",
      "          ],\n",
      "          [\n",
      "            837.9116821289062,\n",
      "            1475.82763671875\n",
      "          ],\n",
      "          [\n",
      "            837.9116821289062,\n",
      "            1175.1939697265625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"6f4f90867d8d04875180aca00689cedf\",\n",
      "    \"text\": \"3 From a Model to an Ecosystem\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7870762348175049,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            317.7433776855469,\n",
      "            1504.808837890625\n",
      "          ],\n",
      "          [\n",
      "            317.7433776855469,\n",
      "            1534.271728515625\n",
      "          ],\n",
      "          [\n",
      "            736.4494018554688,\n",
      "            1534.271728515625\n",
      "          ],\n",
      "          [\n",
      "            736.4494018554688,\n",
      "            1504.808837890625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"fdba4511020a50b8ae796b8cbf3e3b09\",\n",
      "    \"text\": \"3.1 GPT4AII-J: Repository Growth and the implications of the LLaMA License\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7292911410331726,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            317.25811767578125,\n",
      "            1554.0673828125\n",
      "          ],\n",
      "          [\n",
      "            317.25811767578125,\n",
      "            1605.45361328125\n",
      "          ],\n",
      "          [\n",
      "            770.439453125,\n",
      "            1605.45361328125\n",
      "          ],\n",
      "          [\n",
      "            770.439453125,\n",
      "            1554.0673828125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2e9b34c0bd81d8dabf0183aff7e477be\",\n",
      "    \"text\": \"The GPT4AIl repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants. As the Nomic discord, the home of online discussion about GPT4AII, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9447707533836365,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            317.32763671875,\n",
      "            1620.1363525390625\n",
      "          ],\n",
      "          [\n",
      "            317.32763671875,\n",
      "            1871.9107666015625\n",
      "          ],\n",
      "          [\n",
      "            835.9295043945312,\n",
      "            1871.9107666015625\n",
      "          ],\n",
      "          [\n",
      "            835.9295043945312,\n",
      "            1620.1363525390625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3d76b9feebb0c6f79568254ff74ab2f0\",\n",
      "    \"text\": \"hups://github.com/nomic-ai/gpttall\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7074752449989319,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            344.36578369140625,\n",
      "            1894.2257080078125\n",
      "          ],\n",
      "          [\n",
      "            344.36578369140625,\n",
      "            1915.5667724609375\n",
      "          ],\n",
      "          [\n",
      "            627.6140747070312,\n",
      "            1915.5667724609375\n",
      "          ],\n",
      "          [\n",
      "            627.6140747070312,\n",
      "            1894.2257080078125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6dd5f993c5162771e861f254da69f5a7\",\n",
      "    \"text\": \"The LLaMA model that GPT4AII was based on was licensed for research only, which severely limited the set of domains that GPT4AII could be applied in. As a response to this, the Nomic team repeated the model training procedure of the original GPT4AII model, but based on the already open source and commercially li- censed GPT-J model (Wang and Komatsuzaki, 2021). GPT4AII-J also had an augmented training set, which contained multi-turm QA examples and creative writing such as poetry, rap, and short stories. The creative writ- ing prompts were generated by filling in schemas such as \\\"Write a [CREATIVE STORY TYPE] about [NOUN] in the style of [PERSON].\\\" We again employed Atlas to curate the prompt-response pairs in this data set.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9396345019340515,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            872.7468872070312,\n",
      "            267.03472900390625\n",
      "          ],\n",
      "          [\n",
      "            872.7468872070312,\n",
      "            662.8563842773438\n",
      "          ],\n",
      "          [\n",
      "            1393.45947265625,\n",
      "            662.8563842773438\n",
      "          ],\n",
      "          [\n",
      "            1393.45947265625,\n",
      "            267.03472900390625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5e45065b9e6ca1ea3c7ab2299aeda506\",\n",
      "    \"text\": \"Our evaluation methodology also evolved as the project grew. In particular, we began evaluating GPT4All models using a suite of seven reasoning tasks that were used for evaluation of the Databricks Dolly (Conover et al., 2023b) model, which was re- leased on April 12, 2023. Unfortunately, GPT4AII-J did not outperform other prominent open source models on this evaluation. As a result, we endeavoured to create a model that did,\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9483440518379211,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            872.5713500976562,\n",
      "            670.2465209960938\n",
      "          ],\n",
      "          [\n",
      "            872.5713500976562,\n",
      "            915.9075317382812\n",
      "          ],\n",
      "          [\n",
      "            1389.849609375,\n",
      "            915.9075317382812\n",
      "          ],\n",
      "          [\n",
      "            1389.849609375,\n",
      "            670.2465209960938\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cecbb16941932a87be2fe18464a7a384\",\n",
      "    \"text\": \"3.2. GPT4All-Snoozy: the Emergence of the GPT4All Ecosystem\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8794782161712646,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            874.1194458007812,\n",
      "            949.46826171875\n",
      "          ],\n",
      "          [\n",
      "            874.1194458007812,\n",
      "            995.743896484375\n",
      "          ],\n",
      "          [\n",
      "            1322.0965576171875,\n",
      "            995.743896484375\n",
      "          ],\n",
      "          [\n",
      "            1322.0965576171875,\n",
      "            949.46826171875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"745937c14cb925f1b293984ae8bbc8be\",\n",
      "    \"text\": \"GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4All models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base mcs\\u00a5# due to its superior base metrics when compared to orp Next, GPT4All-Snoozy incor- porated the Dolly\\u2019s trating data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4AII-Snoozy. As shown in Figure 1, GPT4AIl-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9439041018486023,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            870.1834716796875,\n",
      "            1017.2853393554688\n",
      "          ],\n",
      "          [\n",
      "            870.1834716796875,\n",
      "            1374.783935546875\n",
      "          ],\n",
      "          [\n",
      "            1387.443359375,\n",
      "            1374.783935546875\n",
      "          ],\n",
      "          [\n",
      "            1387.443359375,\n",
      "            1017.2853393554688\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cecbb16941932a87be2fe18464a7a384\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"05adba3138b3fdfcd3880d0d0748b344\",\n",
      "    \"text\": \"Concurrently with the development of GPT4AlI, sev- eral organizations such as LMSys, Stability Al, BAIR, and Databricks built and deployed open source language models, We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more Tesources were developing source language models, we decided to pivot our effort away from training increas: ingly capable models and towards providing easy access to the plethora of models being produced by the open source community. Practically, this meant spending our time compressing open source models for use on com- modity hardware, providing stable and simple high level model APIs, and supporting a GUI for no code model experimentation\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9415037631988525,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.24658203125,\n",
      "            1383.7464599609375\n",
      "          ],\n",
      "          [\n",
      "            867.24658203125,\n",
      "            1799.5350341796875\n",
      "          ],\n",
      "          [\n",
      "            1384.6209716796875,\n",
      "            1799.5350341796875\n",
      "          ],\n",
      "          [\n",
      "            1384.6209716796875,\n",
      "            1383.7464599609375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"cecbb16941932a87be2fe18464a7a384\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b768aa7cc1a0900624659ea7ed455036\",\n",
      "    \"text\": \"33 The Current State of GPT4AlL\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8186452388763428,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            864.1806640625,\n",
      "            1828.4063720703125\n",
      "          ],\n",
      "          [\n",
      "            864.1806640625,\n",
      "            1853.010986328125\n",
      "          ],\n",
      "          [\n",
      "            1225.5865478515625,\n",
      "            1853.010986328125\n",
      "          ],\n",
      "          [\n",
      "            1225.5865478515625,\n",
      "            1828.4063720703125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"05839fb75b53d54acc8632e720c7139e\",\n",
      "    \"text\": \"Today, GPT4AII is focused on improving the accessi bility of open source language models. The repository\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9055867195129395,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            861.33203125,\n",
      "            1870.272216796875\n",
      "          ],\n",
      "          [\n",
      "            861.33203125,\n",
      "            1922.2794189453125\n",
      "          ],\n",
      "          [\n",
      "            1385.8746337890625,\n",
      "            1922.2794189453125\n",
      "          ],\n",
      "          [\n",
      "            1385.8746337890625,\n",
      "            1870.272216796875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"b768aa7cc1a0900624659ea7ed455036\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"583893028def4f6b9b760a521a2d550d\",\n",
      "    \"text\": \"@) (b) (\\u00a9) (d)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8431752920150757,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            247.096923828125,\n",
      "            265.791259765625\n",
      "          ],\n",
      "          [\n",
      "            247.096923828125,\n",
      "            547.1163940429688\n",
      "          ],\n",
      "          [\n",
      "            1355.7847900390625,\n",
      "            547.1163940429688\n",
      "          ],\n",
      "          [\n",
      "            1355.7847900390625,\n",
      "            265.791259765625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"f0884a56bfed4a6941eceb540d5d46a1\",\n",
      "    \"text\": \"Figure 1: TSNE visualizations showing the progression of the GPT4AII train set. Panel (a) shows the original uncurated data, The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4All data after curation. This panel, as well as panels (c) and (d) are 10 colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appearl. Panel (c) shows the GPT4AII-J dataset. The \\\"starburst\\\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9289826154708862,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.13861083984375,\n",
      "            575.5286865234375\n",
      "          ],\n",
      "          [\n",
      "            301.13861083984375,\n",
      "            794.4069213867188\n",
      "          ],\n",
      "          [\n",
      "            1386.0469970703125,\n",
      "            794.4069213867188\n",
      "          ],\n",
      "          [\n",
      "            1386.0469970703125,\n",
      "            575.5286865234375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Table\",\n",
      "    \"element_id\": \"e23b9c1bfe87745da68648565d5b8085\",\n",
      "    \"text\": \"Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 63.4 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 \\u00a9 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4AIl LLaMa Lora 7B* 73.1 77.6 721 67.8 SIL 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 15 71.3 60.9 442 43.4 65.3 GPT4AIl Falcon 71.6 79.8 74.9 70.1 67.9 Ba 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 ng 74.2 50.9 64 68.8 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023b) 56.7 75.4 at 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT, 73.9 66.1 59.8 43.3 4B4 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 42.6 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 ue) 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 71.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned\\u2019 (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 78 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 48 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 49 Wizard 7B xu et al., 2023) 4 712 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 41.6 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 el 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 48 4 OS text-davinci-003 88.1 83.8 83.4 715.8 83.9 63.9 SLO Ba\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9163863658905029,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            309.4304504394531,\n",
      "            820.48046875\n",
      "          ],\n",
      "          [\n",
      "            309.4304504394531,\n",
      "            1646.1414794921875\n",
      "          ],\n",
      "          [\n",
      "            1373.5946044921875,\n",
      "            1646.1414794921875\n",
      "          ],\n",
      "          [\n",
      "            1373.5946044921875,\n",
      "            820.48046875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"text_as_html\": \"<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>63.4</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 =</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4AIl LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIL</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>15</td><td>71.3</td><td>60.9</td><td>442</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>74.9</td><td>70.1</td><td>67.9</td><td>Ba</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>ng</td><td>74.2</td><td>50.9</td><td>4.4</td><td>68.8</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>60.1</td></tr><tr><td>Dolly 12B* (Conover et al., 2023b)</td><td>56.7</td><td>75.4</td><td>at</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>74</td><td>68.8</td><td>56.6</td><td>43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>ue)</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>71.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>4A</td><td>65.0</td></tr><tr><td>StableLM Tuned\\u2019 (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>S13</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>78</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>TAS</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>4</td><td>712</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>41.6</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7m</td><td>43.3</td><td>44.4</td><td>65,2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0298caeafb9fe2344eef79e4f3a16628\",\n",
      "    \"text\": \"Table 1: Evaluations of all language models in the GPT4AIl ecosystem as of August 1, 2023, Code models are not included. OpenAI\\u2019s text-davinci-003 is included as a point of comparison. The best overall performing model in the GPT4AIl ecosystem, Nous-Hermes?, achieves over 92% of the average performance of text-davinci-003, Models marked with an asterisk were available in the ecosystem as of the release of GPT4All-Snoozy, Note that at release, GPT4AII-Snoozy had the best average performance of any model in the ecosystem. Bolded numbers indicate the best performing model as of August 1, 2023\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9210993051528931,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.2977294921875,\n",
      "            1677.7933349609375\n",
      "          ],\n",
      "          [\n",
      "            306.2977294921875,\n",
      "            1843.080810546875\n",
      "          ],\n",
      "          [\n",
      "            1378.6505126953125,\n",
      "            1843.080810546875\n",
      "          ],\n",
      "          [\n",
      "            1378.6505126953125,\n",
      "            1677.7933349609375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"4805c8dd548712e0ce22163dd42e4065\",\n",
      "    \"text\": \"Github Repo Growth 50000 | \\u2014\\u2014 GPTAAIL \\u2014 UaMA \\u2014 Alpaca 40000 g 30000 a 2 3 r=] & 20000 4 10000 \\u00b0 0 20 40 60 80 100 \\u00ab120s 140 Days Since Launch\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8708685040473938,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            364.3477478027344,\n",
      "            285.80804443359375\n",
      "          ],\n",
      "          [\n",
      "            364.3477478027344,\n",
      "            736.1420288085938\n",
      "          ],\n",
      "          [\n",
      "            1171.984375,\n",
      "            736.1420288085938\n",
      "          ],\n",
      "          [\n",
      "            1171.984375,\n",
      "            285.80804443359375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"8c66a757b9d403d609040dfdaf49b511\",\n",
      "    \"text\": \"Figure 2: Comparison of the github start growth of GPT4All, Meta\\u2019s LLaMA, and Stanford\\u2019s Alpaca. We conjecture that GPT4AIl achieved and maintains faster ecosystem growth due to the focus on access, which allows more users to meaningfully participate.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9072696566581726,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            315.8026123046875,\n",
      "            772.1033325195312\n",
      "          ],\n",
      "          [\n",
      "            315.8026123046875,\n",
      "            848.3175659179688\n",
      "          ],\n",
      "          [\n",
      "            1388.649658203125,\n",
      "            848.3175659179688\n",
      "          ],\n",
      "          [\n",
      "            1388.649658203125,\n",
      "            772.1033325195312\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4b3227025511abcb3b7192c4cd04d284\",\n",
      "    \"text\": \"provides compressed versions of open source models for use on commodity hardware, stable and simple high level model APIs, and a GUI for no code model ex- perimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9354280233383179,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.3470153808594,\n",
      "            908.0654907226562\n",
      "          ],\n",
      "          [\n",
      "            319.3470153808594,\n",
      "            1071.406982421875\n",
      "          ],\n",
      "          [\n",
      "            839.2305908203125,\n",
      "            1071.406982421875\n",
      "          ],\n",
      "          [\n",
      "            839.2305908203125,\n",
      "            908.0654907226562\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"75b0bc8519ac1101a44552b3e77c1e97\",\n",
      "    \"text\": \"\\u201cjust work\\\" on any machine, whether it comes equipped with Apple Metal silicon, NVIDIA, AMD, or other edge- accelerated hardware, Overall, we envision a world where anyone, anywhere, with any machine, can access and contribute to the cutting edge of AI.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.929227352142334,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            870.3804931640625,\n",
      "            910.4838256835938\n",
      "          ],\n",
      "          [\n",
      "            870.3804931640625,\n",
      "            1043.315673828125\n",
      "          ],\n",
      "          [\n",
      "            1393.6697998046875,\n",
      "            1043.315673828125\n",
      "          ],\n",
      "          [\n",
      "            1393.6697998046875,\n",
      "            910.4838256835938\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cb9c28eeb7af6891825cf3ab518a7503\",\n",
      "    \"text\": \"GPT4All currently provides native support and benchmark data for over 35 models (see Figure 1), and includes several models co-developed with industry part- ners such as Replit and Hugging Face. GPT4AII also provides high level model APIs in languages includ- ing Python, Typescript, Go, C#, and Java, among oth- ers. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4AII user data is collected on an opt in basis.) GPT4AIl has be- come the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others, GPT4AII is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9414840340614319,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            318.37109375,\n",
      "            1081.3922119140625\n",
      "          ],\n",
      "          [\n",
      "            318.37109375,\n",
      "            1611.921875\n",
      "          ],\n",
      "          [\n",
      "            840.0160522460938,\n",
      "            1611.921875\n",
      "          ],\n",
      "          [\n",
      "            840.0160522460938,\n",
      "            1081.3922119140625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d147cfb7cb1aec3c5e3a01cb7d3d0a87\",\n",
      "    \"text\": \"4 The Future of GPT4AIl\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8407053351402283,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            314.88934326171875,\n",
      "            1649.770263671875\n",
      "          ],\n",
      "          [\n",
      "            314.88934326171875,\n",
      "            1679.01220703125\n",
      "          ],\n",
      "          [\n",
      "            644.4810791015625,\n",
      "            1679.01220703125\n",
      "          ],\n",
      "          [\n",
      "            644.4810791015625,\n",
      "            1649.770263671875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ff256e76f8ed1ce483b3f89c75085e81\",\n",
      "    \"text\": \"In the future, we will continue to grow GPT4AI, sup- porting it as the de facto solution for LLM accessibil- ity. Concretely, this means continuing to compress and distribute important open-source language models de- veloped by the community, as well as compressing and distributing increasingly multimodal AI models, Fur- thermore, we will expand the set of hardware devices that GPT4AII models run on, so that GPT4AIl models\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9457899332046509,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            315.0162658691406,\n",
      "            1705.4500732421875\n",
      "          ],\n",
      "          [\n",
      "            315.0162658691406,\n",
      "            1931.087646484375\n",
      "          ],\n",
      "          [\n",
      "            840.438720703125,\n",
      "            1931.087646484375\n",
      "          ],\n",
      "          [\n",
      "            840.438720703125,\n",
      "            1705.4500732421875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"d147cfb7cb1aec3c5e3a01cb7d3d0a87\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"65fe5169b886a5c32bef95f78f214bb9\",\n",
      "    \"text\": \"Limitations\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8675901889801025,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            874.3472900390625,\n",
      "            1083.5989990234375\n",
      "          ],\n",
      "          [\n",
      "            874.3472900390625,\n",
      "            1105.80419921875\n",
      "          ],\n",
      "          [\n",
      "            1011.0413208007812,\n",
      "            1105.80419921875\n",
      "          ],\n",
      "          [\n",
      "            1011.0413208007812,\n",
      "            1083.5989990234375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0cbf657555bd65e6f7c5004cc74191e7\",\n",
      "    \"text\": \"uk\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1007.0,\n",
      "            1099.0\n",
      "          ],\n",
      "          [\n",
      "            1007.0,\n",
      "            1156.0\n",
      "          ],\n",
      "          [\n",
      "            1097.0,\n",
      "            1156.0\n",
      "          ],\n",
      "          [\n",
      "            1097.0,\n",
      "            1099.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"00d778311243601579e4103db56bde43\",\n",
      "    \"text\": \"By enabling large language models, the GPT4AII project also inherits many of the ethical con- cems associated with generative models. Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., in- structions on building bioweapons), While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of in- creasingly secretive research groups, We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9439144134521484,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.4852905273438,\n",
      "            1136.11328125\n",
      "          ],\n",
      "          [\n",
      "            873.4852905273438,\n",
      "            1522.942626953125\n",
      "          ],\n",
      "          [\n",
      "            1393.2860107421875,\n",
      "            1522.942626953125\n",
      "          ],\n",
      "          [\n",
      "            1393.2860107421875,\n",
      "            1136.11328125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"0cbf657555bd65e6f7c5004cc74191e7\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"73d6b56639bf30bfd73bebaef3433a95\",\n",
      "    \"text\": \"Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly includ- ing the GPT4AII open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4AII effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standard- ized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit as: signment, and hope to be able to support some of this research ourselves in the future\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9481733441352844,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            872.8200073242188,\n",
      "            1534.714111328125\n",
      "          ],\n",
      "          [\n",
      "            872.8200073242188,\n",
      "            1902.781005859375\n",
      "          ],\n",
      "          [\n",
      "            1398.0157470703125,\n",
      "            1902.781005859375\n",
      "          ],\n",
      "          [\n",
      "            1398.0157470703125,\n",
      "            1534.714111328125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"0cbf657555bd65e6f7c5004cc74191e7\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "    \"text\": \"References\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8165109157562256,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            323.6334533691406,\n",
      "            256.2832946777344\n",
      "          ],\n",
      "          [\n",
      "            323.6334533691406,\n",
      "            287.6946105957031\n",
      "          ],\n",
      "          [\n",
      "            457.5999450683594,\n",
      "            287.6946105957031\n",
      "          ],\n",
      "          [\n",
      "            457.5999450683594,\n",
      "            256.2832946777344\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c0ebd30986550bc57caf57d1e1f6fa9a\",\n",
      "    \"text\": \"Nomic AT. 2023. Atlas. https://atlas.nomic.ai/.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7809240818023682,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            323.16424560546875,\n",
      "            303.74078369140625\n",
      "          ],\n",
      "          [\n",
      "            323.16424560546875,\n",
      "            332.01934814453125\n",
      "          ],\n",
      "          [\n",
      "            834.1893310546875,\n",
      "            332.01934814453125\n",
      "          ],\n",
      "          [\n",
      "            834.1893310546875,\n",
      "            303.74078369140625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"af4f01973b489375a7fc5d7b6468406a\",\n",
      "    \"text\": \"MosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable Ilms. Accessed: 2023-08-07.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8573060035705566,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            878.0604858398438,\n",
      "            265.4493103027344\n",
      "          ],\n",
      "          [\n",
      "            878.0604858398438,\n",
      "            339.8004150390625\n",
      "          ],\n",
      "          [\n",
      "            1391.1954345703125,\n",
      "            339.8004150390625\n",
      "          ],\n",
      "          [\n",
      "            1391.1954345703125,\n",
      "            265.4493103027344\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f431d4365ea80e864b3a1de4f9d5a291\",\n",
      "    \"text\": \"Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al- shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hes- low, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.884958803653717,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            321.4092102050781,\n",
      "            355.8955383300781\n",
      "          ],\n",
      "          [\n",
      "            321.4092102050781,\n",
      "            536.5584106445312\n",
      "          ],\n",
      "          [\n",
      "            839.4833984375,\n",
      "            536.5584106445312\n",
      "          ],\n",
      "          [\n",
      "            839.4833984375,\n",
      "            355.8955383300781\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"2638c19b4370c622261d655b41008aaf\",\n",
      "    \"text\": \"Nous-Research. 2023a. gpt4-x-vicuna-13b. https: //huggingface.co/NousResearch/ gpt4-x-vicuna-13b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.78810054063797,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            881.4146118164062,\n",
      "            367.8905944824219\n",
      "          ],\n",
      "          [\n",
      "            881.4146118164062,\n",
      "            441.9910583496094\n",
      "          ],\n",
      "          [\n",
      "            1387.7169189453125,\n",
      "            441.9910583496094\n",
      "          ],\n",
      "          [\n",
      "            1387.7169189453125,\n",
      "            367.8905944824219\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"0d4549398e1cde89375601999f26b479\",\n",
      "    \"text\": \"Nous-Research. 2023b. Nous-hermes-13b. https: //huggingface.co/NousResearch/ Nous-Hermes~13b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8133750557899475,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            880.1997680664062,\n",
      "            469.0786437988281\n",
      "          ],\n",
      "          [\n",
      "            880.1997680664062,\n",
      "            542.4091796875\n",
      "          ],\n",
      "          [\n",
      "            1387.319091796875,\n",
      "            542.4091796875\n",
      "          ],\n",
      "          [\n",
      "            1387.319091796875,\n",
      "            469.0786437988281\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"8f5b93381dbeea5eda6fe1e35fac4ae7\",\n",
      "    \"text\": \"Yuvanesh Anand, Zach Nussbaum, Brandon Duder- stadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo, https: //github.com/nomic-ai/gpt4all.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.901122510433197,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            308.58721923828125,\n",
      "            561.3509521484375\n",
      "          ],\n",
      "          [\n",
      "            308.58721923828125,\n",
      "            687.0341186523438\n",
      "          ],\n",
      "          [\n",
      "            852.759521484375,\n",
      "            687.0341186523438\n",
      "          ],\n",
      "          [\n",
      "            852.759521484375,\n",
      "            561.3509521484375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"66d638ae64e7412465a8b50d4c3ddece\",\n",
      "    \"text\": \"Nous-Research. 2023c. | Nous-hermes-Ilama-2-7b. https: //huggingface.co/NousResearch/ Nous-Hermes-llama-2-7b. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8658347725868225,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            878.3175659179688,\n",
      "            569.4051513671875\n",
      "          ],\n",
      "          [\n",
      "            878.3175659179688,\n",
      "            669.9036254882812\n",
      "          ],\n",
      "          [\n",
      "            1388.3759765625,\n",
      "            669.9036254882812\n",
      "          ],\n",
      "          [\n",
      "            1388.3759765625,\n",
      "            569.4051513671875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"e13431c2052771855860888f3d425f30\",\n",
      "    \"text\": \"BBC News. 2023. Chatgpt banned in italy over privacy concerns. BBC News.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8478924036026001,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            319.9949645996094,\n",
      "            710.995361328125\n",
      "          ],\n",
      "          [\n",
      "            319.9949645996094,\n",
      "            760.974853515625\n",
      "          ],\n",
      "          [\n",
      "            840.01904296875,\n",
      "            760.974853515625\n",
      "          ],\n",
      "          [\n",
      "            840.01904296875,\n",
      "            710.995361328125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"d8a3c42a6978070896a808791638a231\",\n",
      "    \"text\": \"Nous-Research. 2023d. Redmond-puffin-13b. https: //huggingface.co/NousResearch/ Redmond-Puf fin-13B. Model on Hugging Face.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8759371638298035,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            871.6441650390625,\n",
      "            695.470947265625\n",
      "          ],\n",
      "          [\n",
      "            871.6441650390625,\n",
      "            769.2915649414062\n",
      "          ],\n",
      "          [\n",
      "            1391.613037109375,\n",
      "            769.2915649414062\n",
      "          ],\n",
      "          [\n",
      "            1391.613037109375,\n",
      "            695.470947265625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b901be1f53d56920fa53834938cdd0ba\",\n",
      "    \"text\": \"Stella Biderman, Hailey Schoelkopf, Quentin An- thony, Herbie Bradley, Kyle O\\u2019Brien, Eric Hal- lahan, Mohammad Aflah Khan, Shivanshu Puro- hit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pythia: A suite for analyzing large language models across training and scaling.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8832610249519348,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            309.3657531738281,\n",
      "            788.0254516601562\n",
      "          ],\n",
      "          [\n",
      "            309.3657531738281,\n",
      "            961.2088623046875\n",
      "          ],\n",
      "          [\n",
      "            864.4655151367188,\n",
      "            961.2088623046875\n",
      "          ],\n",
      "          [\n",
      "            864.4655151367188,\n",
      "            788.0254516601562\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"bdbfbe3d96ceee35d3655f6614493d89\",\n",
      "    \"text\": \"Harrison Chase, 2022. langchain. https://github. com/langchain-ai/langchain.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5967415571212769,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            318.55328369140625,\n",
      "            987.0906982421875\n",
      "          ],\n",
      "          [\n",
      "            318.55328369140625,\n",
      "            1037.481201171875\n",
      "          ],\n",
      "          [\n",
      "            848.450927734375,\n",
      "            1037.481201171875\n",
      "          ],\n",
      "          [\n",
      "            848.450927734375,\n",
      "            987.0906982421875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"4c541e4b02c1d69b80da2d9fafb47e3f\",\n",
      "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing the magic of chatgpt with open mod- els.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8952469229698181,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            309.6745300292969,\n",
      "            1062.8521728515625\n",
      "          ],\n",
      "          [\n",
      "            309.6745300292969,\n",
      "            1186.4356689453125\n",
      "          ],\n",
      "          [\n",
      "            855.876220703125,\n",
      "            1186.4356689453125\n",
      "          ],\n",
      "          [\n",
      "            855.876220703125,\n",
      "            1062.8521728515625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"dac5493f0fd15fa083ce475f3055ac73\",\n",
      "    \"text\": \"OpenAI. 2023. Gpt-4 technical report.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6892601251602173,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            876.51708984375,\n",
      "            794.2494506835938\n",
      "          ],\n",
      "          [\n",
      "            876.51708984375,\n",
      "            817.843994140625\n",
      "          ],\n",
      "          [\n",
      "            1234.154296875,\n",
      "            817.843994140625\n",
      "          ],\n",
      "          [\n",
      "            1234.154296875,\n",
      "            794.2494506835938\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"1e4e8aedd1beb3214e61731808a1d2eb\",\n",
      "    \"text\": \"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Teshala Neeraj, Jos Rozen, Ab- heesht Sharma, Ar}irea Santilli, Thibault Fevry, Ja- son Alan Fries, RxAn Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization,\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9085522294044495,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            872.9061889648438,\n",
      "            843.8441162109375\n",
      "          ],\n",
      "          [\n",
      "            872.9061889648438,\n",
      "            1217.8609619140625\n",
      "          ],\n",
      "          [\n",
      "            1411.3651123046875,\n",
      "            1217.8609619140625\n",
      "          ],\n",
      "          [\n",
      "            1411.3651123046875,\n",
      "            843.8441162109375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b33574f8b2f917f59e52f7dddc86da97\",\n",
      "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing the world\\u2019s first truly open instruction- tuned Im.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8988227248191833,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            313.4408264160156,\n",
      "            1213.277099609375\n",
      "          ],\n",
      "          [\n",
      "            313.4408264160156,\n",
      "            1340.6673583984375\n",
      "          ],\n",
      "          [\n",
      "            853.0631103515625,\n",
      "            1340.6673583984375\n",
      "          ],\n",
      "          [\n",
      "            853.0631103515625,\n",
      "            1213.277099609375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"3e049836689797b30e2925c5daad835f\",\n",
      "    \"text\": \"Stability-AL 2023. Stablelm. https: //github.com/ Stability-AI/StableLM. GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7069557309150696,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            879.7740478515625,\n",
      "            1254.066162109375\n",
      "          ],\n",
      "          [\n",
      "            879.7740478515625,\n",
      "            1301.79541015625\n",
      "          ],\n",
      "          [\n",
      "            1392.0322265625,\n",
      "            1301.79541015625\n",
      "          ],\n",
      "          [\n",
      "            1392.0322265625,\n",
      "            1254.066162109375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"63a6fb09ddc0e4c1bbbe348eb654bf97\",\n",
      "    \"text\": \"Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal- Jace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic re- search. Blog post.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8863738775253296,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            316.2239685058594,\n",
      "            1366.432373046875\n",
      "          ],\n",
      "          [\n",
      "            316.2239685058594,\n",
      "            1467.0150146484375\n",
      "          ],\n",
      "          [\n",
      "            847.9456176757812,\n",
      "            1467.0150146484375\n",
      "          ],\n",
      "          [\n",
      "            847.9456176757812,\n",
      "            1366.432373046875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"57d339434a4f8e5fc54a6359e2596a82\",\n",
      "    \"text\": \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen, 2021. Lora: Low-rank adaptation of large language models,\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8681251406669617,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            313.5329895019531,\n",
      "            1492.6971435546875\n",
      "          ],\n",
      "          [\n",
      "            313.5329895019531,\n",
      "            1594.7303466796875\n",
      "          ],\n",
      "          [\n",
      "            849.5582275390625,\n",
      "            1594.7303466796875\n",
      "          ],\n",
      "          [\n",
      "            849.5582275390625,\n",
      "            1492.6971435546875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"68232fb79c8114a4bcb48a38cdf3fb85\",\n",
      "    \"text\": \"imartinez. 2023. privategpt, https://github.com/ imartinez/privateGPT.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5315878987312317,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            318.3379211425781,\n",
      "            1620.3861083984375\n",
      "          ],\n",
      "          [\n",
      "            318.3379211425781,\n",
      "            1670.581787109375\n",
      "          ],\n",
      "          [\n",
      "            844.279296875,\n",
      "            1670.581787109375\n",
      "          ],\n",
      "          [\n",
      "            844.279296875,\n",
      "            1620.3861083984375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"47cf52e4295349ab2462cd4ed3b6a044\",\n",
      "    \"text\": \"Oscar Leo, 2023. GitHub: The Fastest Growing Repos- itories of AJ] Time.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7494210004806519,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            314.58892822265625,\n",
      "            1694.7196044921875\n",
      "          ],\n",
      "          [\n",
      "            314.58892822265625,\n",
      "            1746.0809326171875\n",
      "          ],\n",
      "          [\n",
      "            841.4545288085938,\n",
      "            1746.0809326171875\n",
      "          ],\n",
      "          [\n",
      "            841.4545288085938,\n",
      "            1694.7196044921875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"9040b9a0fb5d1ffa3f8f3e83543cb2a8\",\n",
      "    \"text\": \"StanGirard. 2023. quivr. https://github.com/ StanGirard/quivr, GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7443869113922119,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            874.9909057617188,\n",
      "            1329.6654052734375\n",
      "          ],\n",
      "          [\n",
      "            874.9909057617188,\n",
      "            1377.678955078125\n",
      "          ],\n",
      "          [\n",
      "            1389.090087890625,\n",
      "            1377.678955078125\n",
      "          ],\n",
      "          [\n",
      "            1389.090087890625,\n",
      "            1329.6654052734375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"107e5b4a0ff2ad9fad93190874542b1c\",\n",
      "    \"text\": \"Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B, Hashimoto. 2023. Stanford alpaca: An instruction-following llama model, https: // github. com/tatsu-lab/stanford_alpaca.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8818901181221008,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            864.5420532226562,\n",
      "            1403.415771484375\n",
      "          ],\n",
      "          [\n",
      "            864.5420532226562,\n",
      "            1530.091064453125\n",
      "          ],\n",
      "          [\n",
      "            1395.8299560546875,\n",
      "            1530.091064453125\n",
      "          ],\n",
      "          [\n",
      "            1395.8299560546875,\n",
      "            1403.415771484375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f0e9f248e66c702acffab103d49d5810\",\n",
      "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e9re, Naman Goyal, Bric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample, 2023, Llama: Open and efficient foundation language models,\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8762737512588501,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            868.0521240234375,\n",
      "            1559.406494140625\n",
      "          ],\n",
      "          [\n",
      "            868.0521240234375,\n",
      "            1737.20068359375\n",
      "          ],\n",
      "          [\n",
      "            1405.8026123046875,\n",
      "            1737.20068359375\n",
      "          ],\n",
      "          [\n",
      "            1405.8026123046875,\n",
      "            1559.406494140625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"306172d5c1bcd8e14280db86ab92417e\",\n",
      "    \"text\": \"Robert McMillan, 2023. A meta platforms leak put powerful ai in the hands of everyone. The Wall Street Journal\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.844599723815918,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            314.8537292480469,\n",
      "            1771.673828125\n",
      "          ],\n",
      "          [\n",
      "            314.8537292480469,\n",
      "            1848.074462890625\n",
      "          ],\n",
      "          [\n",
      "            843.6608276367188,\n",
      "            1848.074462890625\n",
      "          ],\n",
      "          [\n",
      "            843.6608276367188,\n",
      "            1771.673828125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"96193587a3ec137f8f1402f5ba65703e\",\n",
      "    \"text\": \"The Verge. 2023, Meta\\u2019s powerful ai language model has leaked online \\u2014 what happens now? The Verge\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7548225522041321,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            871.3294067382812,\n",
      "            1765.517822265625\n",
      "          ],\n",
      "          [\n",
      "            871.3294067382812,\n",
      "            1816.924072265625\n",
      "          ],\n",
      "          [\n",
      "            1392.5386962890625,\n",
      "            1816.924072265625\n",
      "          ],\n",
      "          [\n",
      "            1392.5386962890625,\n",
      "            1765.517822265625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"40a9a80d43987cc0bd892fa6b7b1cc65\",\n",
      "    \"text\": \"MindsDB, 2023, Mindsdb. https://github.com/ mindsdb/mindsdb, GitHub repository.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6084712147712708,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            315.8533630371094,\n",
      "            1873.15625\n",
      "          ],\n",
      "          [\n",
      "            315.8533630371094,\n",
      "            1924.0263671875\n",
      "          ],\n",
      "          [\n",
      "            839.9713745117188,\n",
      "            1924.0263671875\n",
      "          ],\n",
      "          [\n",
      "            839.9713745117188,\n",
      "            1873.15625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"ae163c12121ea64331f632b14ab253db\",\n",
      "    \"text\": \"James Vincent. 2023. As an ai generated language model; The phrase that shows how ai is polluting the web. The Verge.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8694372177124023,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            870.0297241210938,\n",
      "            1845.6807861328125\n",
      "          ],\n",
      "          [\n",
      "            870.0297241210938,\n",
      "            1921.2481689453125\n",
      "          ],\n",
      "          [\n",
      "            1393.6605224609375,\n",
      "            1921.2481689453125\n",
      "          ],\n",
      "          [\n",
      "            1393.6605224609375,\n",
      "            1845.6807861328125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f3f35258711ff51dfaddeca05a5bcdce\",\n",
      "    \"text\": \"| free\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            147.0,\n",
      "            2063.0\n",
      "          ],\n",
      "          [\n",
      "            147.0,\n",
      "            2112.0\n",
      "          ],\n",
      "          [\n",
      "            1556.0,\n",
      "            2112.0\n",
      "          ],\n",
      "          [\n",
      "            1556.0,\n",
      "            2063.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"5b17fc3226b43e2fdae96d5dd90f8e2c\",\n",
      "    \"text\": \"Ben Wang and Aran Komatsuzaki. 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https: //github.com/kingoflolz/ mesh-transformer-jax. Eric J. Wang. 2023. alpaca-lora. https: //github. com/tloen/alpaca-lora. GitHub repository. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han- nanch Hajishirzi. 2023. Self-instruct: Aligning lan- guage models with self-generated instructions. Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging Ilm-as-a-judge with mt-bench and chatbot arena.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.33423709869384766,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            149.89720153808594,\n",
      "            213.85165405273438\n",
      "          ],\n",
      "          [\n",
      "            149.89720153808594,\n",
      "            1925.63671875\n",
      "          ],\n",
      "          [\n",
      "            1577.909912109375,\n",
      "            1925.63671875\n",
      "          ],\n",
      "          [\n",
      "            1577.909912109375,\n",
      "            213.85165405273438\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2024-09-26T07:31:36\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"scanned_gpt4all.pdf\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "{'Table', 'Title', 'Image', 'NarrativeText', 'FigureCaption', 'Header', 'ListItem'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "element_dict = [el.to_dict() for el in elements]\n",
    "output = json.dumps(element_dict, indent=2)\n",
    "print(output)\n",
    "\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 63.4 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 © 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4AIl LLaMa Lora 7B* 73.1 77.6 721 67.8 SIL 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 15 71.3 60.9 442 43.4 65.3 GPT4AIl Falcon 71.6 79.8 74.9 70.1 67.9 Ba 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 ng 74.2 50.9 64 68.8 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023b) 56.7 75.4 at 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT, 73.9 66.1 59.8 43.3 4B4 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 42.6 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 ue) 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 71.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned’ (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 78 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 48 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 49 Wizard 7B xu et al., 2023) 4 712 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 41.6 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 el 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 48 4 OS text-davinci-003 88.1 83.8 83.4 715.8 83.9 63.9 SLO Ba\n",
      "<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>63.4</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 =</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4AIl LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIL</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>15</td><td>71.3</td><td>60.9</td><td>442</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>74.9</td><td>70.1</td><td>67.9</td><td>Ba</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>ng</td><td>74.2</td><td>50.9</td><td>4.4</td><td>68.8</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>60.1</td></tr><tr><td>Dolly 12B* (Conover et al., 2023b)</td><td>56.7</td><td>75.4</td><td>at</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>74</td><td>68.8</td><td>56.6</td><td>43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>ue)</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>71.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>4A</td><td>65.0</td></tr><tr><td>StableLM Tuned’ (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>S13</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>78</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>TAS</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>4</td><td>712</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>41.6</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7m</td><td>43.3</td><td>44.4</td><td>65,2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>\n"
     ]
    }
   ],
   "source": [
    "tables = [el for el in elements if el.category == \"Table\"]\n",
    "\n",
    "print(tables[0].text)\n",
    "print(tables[0].metadata.text_as_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Table at 0x3098e600>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 63.4 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 © 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4AIl LLaMa Lora 7B* 73.1 77.6 721 67.8 SIL 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 15 71.3 60.9 442 43.4 65.3 GPT4AIl Falcon 71.6 79.8 74.9 70.1 67.9 Ba 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 ng 74.2 50.9 64 68.8 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023b) 56.7 75.4 at 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT, 73.9 66.1 59.8 43.3 4B4 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 42.6 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 ue) 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 71.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned’ (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 78 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 48 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 49 Wizard 7B xu et al., 2023) 4 712 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 41.6 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 el 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 48 4 OS text-davinci-003 88.1 83.8 83.4 715.8 83.9 63.9 SLO Ba'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<unstructured.documents.elements.ElementMetadata at 0x3098c9b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, comes the most interesting part ( utilizing the extracted data in most efficient way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's helpful to have an HTML representation of the table so that you can the information to an LLM while maintaining the table structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html = tables[0].metadata.text_as_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>63.4</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 =</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4AIl LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIL</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>15</td><td>71.3</td><td>60.9</td><td>442</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>74.9</td><td>70.1</td><td>67.9</td><td>Ba</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>ng</td><td>74.2</td><td>50.9</td><td>4.4</td><td>68.8</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>60.1</td></tr><tr><td>Dolly 12B* (Conover et al., 2023b)</td><td>56.7</td><td>75.4</td><td>at</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>74</td><td>68.8</td><td>56.6</td><td>43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>ue)</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>71.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>4A</td><td>65.0</td></tr><tr><td>StableLM Tuned’ (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>S13</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>78</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>TAS</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>4</td><td>712</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>41.6</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7m</td><td>43.3</td><td>44.4</td><td>65,2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <thead>\n",
      "    <tr>\n",
      "      <th>Model</th>\n",
      "      <th>BoolQ</th>\n",
      "      <th>PIQA</th>\n",
      "      <th>HellaSwag</th>\n",
      "      <th>WinoG.</th>\n",
      "      <th>ARC-c</th>\n",
      "      <th>ARC-c</th>\n",
      "      <th>OBQA</th>\n",
      "      <th>Avg</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>GPT4AII-J 6B v1.0*</td>\n",
      "      <td>73.4</td>\n",
      "      <td>74.8</td>\n",
      "      <td>63.4</td>\n",
      "      <td>64.7</td>\n",
      "      <td>54.9</td>\n",
      "      <td>36</td>\n",
      "      <td>40.2</td>\n",
      "      <td>58.2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AII-J v1.1-breezy*</td>\n",
      "      <td>74</td>\n",
      "      <td>75.1</td>\n",
      "      <td>63.2</td>\n",
      "      <td>63.6</td>\n",
      "      <td>55.4</td>\n",
      "      <td>34.9</td>\n",
      "      <td>38.4</td>\n",
      "      <td>SL</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AIIL-J v1.2-jazzy*</td>\n",
      "      <td>74.8</td>\n",
      "      <td>74.9</td>\n",
      "      <td>63.6</td>\n",
      "      <td>638</td>\n",
      "      <td>56.6</td>\n",
      "      <td>35.3</td>\n",
      "      <td>41</td>\n",
      "      <td>58.6</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AII-J v1.3-groovy*</td>\n",
      "      <td>73.6</td>\n",
      "      <td>74.3</td>\n",
      "      <td>63.8</td>\n",
      "      <td>63.5</td>\n",
      "      <td>57.7</td>\n",
      "      <td>35</td>\n",
      "      <td>38.8 =</td>\n",
      "      <td>58.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AII-J Lora 6B*</td>\n",
      "      <td>68.6</td>\n",
      "      <td>75.8</td>\n",
      "      <td>66.2</td>\n",
      "      <td>63.5</td>\n",
      "      <td>56.4</td>\n",
      "      <td>35.7</td>\n",
      "      <td>402</td>\n",
      "      <td>58.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AIl LLaMa Lora 7B*</td>\n",
      "      <td>73.1</td>\n",
      "      <td>77.6</td>\n",
      "      <td>721</td>\n",
      "      <td>67.8</td>\n",
      "      <td>SIL</td>\n",
      "      <td>40.4</td>\n",
      "      <td>40.2</td>\n",
      "      <td>60.3</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4All 13B snoozy*</td>\n",
      "      <td>83.3</td>\n",
      "      <td>79.2</td>\n",
      "      <td>15</td>\n",
      "      <td>71.3</td>\n",
      "      <td>60.9</td>\n",
      "      <td>442</td>\n",
      "      <td>43.4</td>\n",
      "      <td>65.3</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AIl Falcon</td>\n",
      "      <td>71.6</td>\n",
      "      <td>79.8</td>\n",
      "      <td>74.9</td>\n",
      "      <td>70.1</td>\n",
      "      <td>67.9</td>\n",
      "      <td>Ba</td>\n",
      "      <td>42.6</td>\n",
      "      <td>65.2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Nous-Hermes (Nous-Research, 2023b)</td>\n",
      "      <td>79.5</td>\n",
      "      <td>78.9</td>\n",
      "      <td>80</td>\n",
      "      <td>ng</td>\n",
      "      <td>74.2</td>\n",
      "      <td>50.9</td>\n",
      "      <td>4.4</td>\n",
      "      <td>68.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Nous-Hermes2 (Nous-Research, 2023c)</td>\n",
      "      <td>83.9</td>\n",
      "      <td>80.7</td>\n",
      "      <td>80.1</td>\n",
      "      <td>71.3</td>\n",
      "      <td>75.7</td>\n",
      "      <td>52.1</td>\n",
      "      <td>46.2</td>\n",
      "      <td>70.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Nous-Puffin (Nous-Research, 2023d)</td>\n",
      "      <td>815</td>\n",
      "      <td>80.7</td>\n",
      "      <td>80.4</td>\n",
      "      <td>72.5</td>\n",
      "      <td>771.6</td>\n",
      "      <td>50.7</td>\n",
      "      <td>45.6</td>\n",
      "      <td>69.9</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Dolly 6B* (Conover et al., 2023a)</td>\n",
      "      <td>68.8</td>\n",
      "      <td>71.3</td>\n",
      "      <td>67.6</td>\n",
      "      <td>63.9</td>\n",
      "      <td>62.9</td>\n",
      "      <td>38.7</td>\n",
      "      <td>412</td>\n",
      "      <td>60.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Dolly 12B* (Conover et al., 2023b)</td>\n",
      "      <td>56.7</td>\n",
      "      <td>75.4</td>\n",
      "      <td>at</td>\n",
      "      <td>62.2</td>\n",
      "      <td>64.6</td>\n",
      "      <td>38.5</td>\n",
      "      <td>404</td>\n",
      "      <td>584</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td>\n",
      "      <td>94325793</td>\n",
      "      <td/>\n",
      "      <td>74</td>\n",
      "      <td>68.8</td>\n",
      "      <td>56.6</td>\n",
      "      <td>43.9</td>\n",
      "      <td>426</td>\n",
      "      <td>62.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td>\n",
      "      <td>654</td>\n",
      "      <td>76.2</td>\n",
      "      <td>66.2</td>\n",
      "      <td>64.1</td>\n",
      "      <td>62.2</td>\n",
      "      <td>36.6</td>\n",
      "      <td>38.2</td>\n",
      "      <td>58.4</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>LLama 7B* (Touvron et al., 2023)</td>\n",
      "      <td>73.1</td>\n",
      "      <td>714</td>\n",
      "      <td>ue)</td>\n",
      "      <td>66.9</td>\n",
      "      <td>52.5</td>\n",
      "      <td>414</td>\n",
      "      <td>42.4</td>\n",
      "      <td>61.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>LLama 13B* (Touvron et al_, 2023)</td>\n",
      "      <td>68.5</td>\n",
      "      <td>79.1</td>\n",
      "      <td>76.2</td>\n",
      "      <td>70.1</td>\n",
      "      <td>60</td>\n",
      "      <td>44.6</td>\n",
      "      <td>422</td>\n",
      "      <td>63.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Pythia 6.7B* (Biderman et al., 2023)</td>\n",
      "      <td>63.5</td>\n",
      "      <td>76.3</td>\n",
      "      <td>64</td>\n",
      "      <td>61.1</td>\n",
      "      <td>61.3</td>\n",
      "      <td>35.2</td>\n",
      "      <td>37.2</td>\n",
      "      <td>56.9</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Pythia 12B* (Biderman et al., 2023)</td>\n",
      "      <td>67.7</td>\n",
      "      <td>16.6</td>\n",
      "      <td>67.3</td>\n",
      "      <td>63.8</td>\n",
      "      <td>63.9</td>\n",
      "      <td>34.8</td>\n",
      "      <td>38</td>\n",
      "      <td>58.9</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Fastchat TS* (Zheng et al., 2023)</td>\n",
      "      <td>815</td>\n",
      "      <td>64.6</td>\n",
      "      <td>46.3</td>\n",
      "      <td>618</td>\n",
      "      <td>49.3</td>\n",
      "      <td>(33.2.</td>\n",
      "      <td>39.4</td>\n",
      "      <td>53.7</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td>\n",
      "      <td>76.6</td>\n",
      "      <td>71.2</td>\n",
      "      <td>70.7</td>\n",
      "      <td>67.3</td>\n",
      "      <td>53.5</td>\n",
      "      <td>41.2</td>\n",
      "      <td>40.8</td>\n",
      "      <td>61.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td>\n",
      "      <td>815</td>\n",
      "      <td>76.8</td>\n",
      "      <td>73.3</td>\n",
      "      <td>66.7</td>\n",
      "      <td>57.4</td>\n",
      "      <td>42.7</td>\n",
      "      <td>3.6</td>\n",
      "      <td>63.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Stable Vicufia RLHF* (Stability-Al, 2023)</td>\n",
      "      <td>82.3</td>\n",
      "      <td>78.6</td>\n",
      "      <td>74.1</td>\n",
      "      <td>70.9</td>\n",
      "      <td>61</td>\n",
      "      <td>43.5</td>\n",
      "      <td>4A</td>\n",
      "      <td>65.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>StableLM Tuned&#8217; (Stability-Al, 2023)</td>\n",
      "      <td>625</td>\n",
      "      <td>71.2</td>\n",
      "      <td>53.6</td>\n",
      "      <td>54.8</td>\n",
      "      <td>52.4</td>\n",
      "      <td>31</td>\n",
      "      <td>33.4</td>\n",
      "      <td>S13</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>StableLM Base* (Stability-Al, 2023)</td>\n",
      "      <td>60.1</td>\n",
      "      <td>67.4</td>\n",
      "      <td>412</td>\n",
      "      <td>50.1</td>\n",
      "      <td>44.9</td>\n",
      "      <td>27</td>\n",
      "      <td>32</td>\n",
      "      <td>46.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Koala 13B* (Geng et al., 2023)</td>\n",
      "      <td>765</td>\n",
      "      <td>71.9</td>\n",
      "      <td>72.6</td>\n",
      "      <td>68.8</td>\n",
      "      <td>54.3</td>\n",
      "      <td>4l</td>\n",
      "      <td>42.8</td>\n",
      "      <td>62.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Open Assistant Pythia 12B*</td>\n",
      "      <td>67.9</td>\n",
      "      <td>78</td>\n",
      "      <td>68.1</td>\n",
      "      <td>65</td>\n",
      "      <td>64.2</td>\n",
      "      <td>404</td>\n",
      "      <td>43.2</td>\n",
      "      <td>61.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mosaic MPT7B (MosaicML-Team, 2023)</td>\n",
      "      <td>74.8</td>\n",
      "      <td>79.3</td>\n",
      "      <td>76.3</td>\n",
      "      <td>68.6</td>\n",
      "      <td>70</td>\n",
      "      <td>42.2</td>\n",
      "      <td>42.6</td>\n",
      "      <td>64.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td>\n",
      "      <td>743</td>\n",
      "      <td>80.4</td>\n",
      "      <td>77.2.</td>\n",
      "      <td>678</td>\n",
      "      <td>72.2</td>\n",
      "      <td>44.6</td>\n",
      "      <td>43</td>\n",
      "      <td>65.6</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mosaic mpt-chat (MosaicML-Team, 2023)</td>\n",
      "      <td>771</td>\n",
      "      <td>78.2</td>\n",
      "      <td>TAS</td>\n",
      "      <td>67.5</td>\n",
      "      <td>69.4</td>\n",
      "      <td>43.3</td>\n",
      "      <td>44.2</td>\n",
      "      <td>64.9</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Wizard 7B xu et al., 2023)</td>\n",
      "      <td>4</td>\n",
      "      <td>712</td>\n",
      "      <td>69.9</td>\n",
      "      <td>66,5</td>\n",
      "      <td>56.8</td>\n",
      "      <td>40.5</td>\n",
      "      <td>42.6</td>\n",
      "      <td>61,7</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Wizard 7B Uncensored (Xu et al., 2023)</td>\n",
      "      <td>717</td>\n",
      "      <td>74.2</td>\n",
      "      <td>68</td>\n",
      "      <td>65.2</td>\n",
      "      <td>53.5</td>\n",
      "      <td>38,7</td>\n",
      "      <td>41.6</td>\n",
      "      <td>59.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Wizard 13B Uncensored (Xu et al,, 2023)</td>\n",
      "      <td>784</td>\n",
      "      <td>15.5</td>\n",
      "      <td>21</td>\n",
      "      <td>69.5</td>\n",
      "      <td>57.5</td>\n",
      "      <td>40.4</td>\n",
      "      <td>44</td>\n",
      "      <td>62.5</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td>\n",
      "      <td>813</td>\n",
      "      <td>75</td>\n",
      "      <td>75.2</td>\n",
      "      <td>65</td>\n",
      "      <td>58.7</td>\n",
      "      <td>43,9</td>\n",
      "      <td>43.6</td>\n",
      "      <td>63,2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Falcon 7b (Almazrouei et al., 2023)</td>\n",
      "      <td>73.6</td>\n",
      "      <td>80.7</td>\n",
      "      <td>76.3</td>\n",
      "      <td>67,3</td>\n",
      "      <td>7m</td>\n",
      "      <td>43.3</td>\n",
      "      <td>44.4</td>\n",
      "      <td>65,2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Falcon 7b instruct (Almazrouei et al., 2023)</td>\n",
      "      <td>709</td>\n",
      "      <td>78.6</td>\n",
      "      <td>69.8</td>\n",
      "      <td>66.7</td>\n",
      "      <td>67.9</td>\n",
      "      <td>42.7</td>\n",
      "      <td>412</td>\n",
      "      <td>62.5</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view what the HTML in the metadata field looks like\n",
    "\n",
    "from io import StringIO \n",
    "from lxml import etree\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "file_obj = StringIO(table_html)\n",
    "tree = etree.parse(file_obj, parser)\n",
    "print(etree.tostring(tree, pretty_print=True).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>63.4</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 =</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4AIl LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIL</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>15</td><td>71.3</td><td>60.9</td><td>442</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>74.9</td><td>70.1</td><td>67.9</td><td>Ba</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>ng</td><td>74.2</td><td>50.9</td><td>4.4</td><td>68.8</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>60.1</td></tr><tr><td>Dolly 12B* (Conover et al., 2023b)</td><td>56.7</td><td>75.4</td><td>at</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>74</td><td>68.8</td><td>56.6</td><td>43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>ue)</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>71.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>4A</td><td>65.0</td></tr><tr><td>StableLM Tuned’ (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>S13</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>78</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>TAS</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>4</td><td>712</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>41.6</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7m</td><td>43.3</td><td>44.4</td><td>65,2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's display this table\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(table_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, lets plugin in LangChain to summarize these tables using `Llama3` via `Ollama`\n",
    "#### [Ollama Playlist](https://www.youtube.com/playlist?list=PLz-qytj7eIWX-bpcRtvkixvo9fuejVr8y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain-ollama langchain_core langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mChatOllama\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseCache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseCallbackHandler\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtags\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcustom_get_token_ids\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcallback_manager\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrate_limiter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrate_limiters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseRateLimiter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdisable_streaming\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tool_calling'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmirostat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmirostat_eta\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmirostat_tau\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_ctx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_gpu\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_thread\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_predict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrepeat_last_n\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrepeat_penalty\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtfs_z\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtop_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtop_p\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbase_url\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclient_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mChatOllama\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseChatModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Ollama chat model integration.\n",
      "\n",
      "    .. dropdown:: Setup\n",
      "        :open:\n",
      "\n",
      "        Install ``langchain-ollama`` and download any models you want to use from ollama.\n",
      "\n",
      "        .. code-block:: bash\n",
      "\n",
      "            ollama pull mistral:v0.3\n",
      "            pip install -U langchain-ollama\n",
      "\n",
      "    Key init args — completion params:\n",
      "        model: str\n",
      "            Name of Ollama model to use.\n",
      "        temperature: float\n",
      "            Sampling temperature. Ranges from 0.0 to 1.0.\n",
      "        num_predict: Optional[int]\n",
      "            Max number of tokens to generate.\n",
      "\n",
      "    See full list of supported init args and their descriptions in the params section.\n",
      "\n",
      "    Instantiate:\n",
      "        .. code-block:: python\n",
      "\n",
      "            from langchain_ollama import ChatOllama\n",
      "\n",
      "            llm = ChatOllama(\n",
      "                model = \"llama3\",\n",
      "                temperature = 0.8,\n",
      "                num_predict = 256,\n",
      "                # other params ...\n",
      "            )\n",
      "\n",
      "    Invoke:\n",
      "        .. code-block:: python\n",
      "\n",
      "            messages = [\n",
      "                (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
      "                (\"human\", \"I love programming.\"),\n",
      "            ]\n",
      "            llm.invoke(messages)\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            AIMessage(content='J'adore le programmation. (Note: \"programming\" can also refer to the act of writing code, so if you meant that, I could translate it as \"J'adore programmer\". But since you didn\\'t specify, I assumed you were talking about the activity itself, which is what \"le programmation\" usually refers to.)', response_metadata={'model': 'llama3', 'created_at': '2024-07-04T03:37:50.182604Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 3576619666, 'load_duration': 788524916, 'prompt_eval_count': 32, 'prompt_eval_duration': 128125000, 'eval_count': 71, 'eval_duration': 2656556000}, id='run-ba48f958-6402-41a5-b461-5e250a4ebd36-0')\n",
      "\n",
      "    Stream:\n",
      "        .. code-block:: python\n",
      "\n",
      "            messages = [\n",
      "                (\"human\", \"Return the words Hello World!\"),\n",
      "            ]\n",
      "            for chunk in llm.stream(messages):\n",
      "                print(chunk)\n",
      "\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            content='Hello' id='run-327ff5ad-45c8-49fe-965c-0a93982e9be1'\n",
      "            content=' World' id='run-327ff5ad-45c8-49fe-965c-0a93982e9be1'\n",
      "            content='!' id='run-327ff5ad-45c8-49fe-965c-0a93982e9be1'\n",
      "            content='' response_metadata={'model': 'llama3', 'created_at': '2024-07-04T03:39:42.274449Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 411875125, 'load_duration': 1898166, 'prompt_eval_count': 14, 'prompt_eval_duration': 297320000, 'eval_count': 4, 'eval_duration': 111099000} id='run-327ff5ad-45c8-49fe-965c-0a93982e9be1'\n",
      "\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            stream = llm.stream(messages)\n",
      "            full = next(stream)\n",
      "            for chunk in stream:\n",
      "                full += chunk\n",
      "            full\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            AIMessageChunk(content='Je adore le programmation.(Note: \"programmation\" is the formal way to say \"programming\" in French, but informally, people might use the phrase \"le développement logiciel\" or simply \"le code\")', response_metadata={'model': 'llama3', 'created_at': '2024-07-04T03:38:54.933154Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1977300042, 'load_duration': 1345709, 'prompt_eval_duration': 159343000, 'eval_count': 47, 'eval_duration': 1815123000}, id='run-3c81a3ed-3e79-4dd3-a796-04064d804890')\n",
      "\n",
      "    Async:\n",
      "        .. code-block:: python\n",
      "\n",
      "            messages = [\n",
      "                (\"human\", \"Hello how are you!\"),\n",
      "            ]\n",
      "            await llm.ainvoke(messages)\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            AIMessage(content=\"Hi there! I'm just an AI, so I don't have feelings or emotions like humans do. But I'm functioning properly and ready to help with any questions or tasks you may have! How can I assist you today?\", response_metadata={'model': 'llama3', 'created_at': '2024-07-04T03:52:08.165478Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2138492875, 'load_duration': 1364000, 'prompt_eval_count': 10, 'prompt_eval_duration': 297081000, 'eval_count': 47, 'eval_duration': 1838524000}, id='run-29c510ae-49a4-4cdd-8f23-b972bfab1c49-0')\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            messages = [\n",
      "                (\"human\", \"Say hello world!\"),\n",
      "            ]\n",
      "            async for chunk in llm.astream(messages):\n",
      "                print(chunk.content)\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            HEL\n",
      "            LO\n",
      "            WORLD\n",
      "            !\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            messages = [\n",
      "                (\"human\", \"Say hello world!\"),\n",
      "                (\"human\",\"Say goodbye world!\")\n",
      "            ]\n",
      "            await llm.abatch(messages)\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            [AIMessage(content='HELLO, WORLD!', response_metadata={'model': 'llama3', 'created_at': '2024-07-04T03:55:07.315396Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1696745458, 'load_duration': 1505000, 'prompt_eval_count': 8, 'prompt_eval_duration': 111627000, 'eval_count': 6, 'eval_duration': 185181000}, id='run-da6c7562-e25a-4a44-987a-2c83cd8c2686-0'),\n",
      "            AIMessage(content=\"It's been a blast chatting with you! Say goodbye to the world for me, and don't forget to come back and visit us again soon!\", response_metadata={'model': 'llama3', 'created_at': '2024-07-04T03:55:07.018076Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1399391083, 'load_duration': 1187417, 'prompt_eval_count': 20, 'prompt_eval_duration': 230349000, 'eval_count': 31, 'eval_duration': 1166047000}, id='run-96cad530-6f3e-4cf9-86b4-e0f8abba4cdb-0')]\n",
      "\n",
      "    JSON mode:\n",
      "        .. code-block:: python\n",
      "\n",
      "\n",
      "            json_llm = ChatOllama(format=\"json\")\n",
      "            messages = [\n",
      "                (\"human\", \"Return a query for the weather in a random location and time of day with two keys: location and time_of_day. Respond using JSON only.\"),\n",
      "            ]\n",
      "            llm.invoke(messages).content\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            '{\"location\": \"Pune, India\", \"time_of_day\": \"morning\"}'\n",
      "\n",
      "    Tool Calling:\n",
      "        .. warning::\n",
      "            Ollama currently does not support streaming for tools\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            from langchain_ollama import ChatOllama\n",
      "            from pydantic import BaseModel, Field\n",
      "\n",
      "            class Multiply(BaseModel):\n",
      "                a: int = Field(..., description=\"First integer\")\n",
      "                b: int = Field(..., description=\"Second integer\")\n",
      "\n",
      "            ans = await chat.invoke(\"What is 45*67\")\n",
      "            ans.tool_calls\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            [{'name': 'Multiply',\n",
      "            'args': {'a': 45, 'b': 67},\n",
      "            'id': '420c3f3b-df10-4188-945f-eb3abdb40622',\n",
      "            'type': 'tool_call'}]\n",
      "    \"\"\"\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Model name to use.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmirostat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Enable Mirostat sampling for controlling perplexity.\n",
      "    (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmirostat_eta\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Influences how quickly the algorithm responds to feedback\n",
      "    from the generated text. A lower learning rate will result in\n",
      "    slower adjustments, while a higher learning rate will make\n",
      "    the algorithm more responsive. (Default: 0.1)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmirostat_tau\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Controls the balance between coherence and diversity\n",
      "    of the output. A lower value will result in more focused and\n",
      "    coherent text. (Default: 5.0)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_ctx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Sets the size of the context window used to generate the\n",
      "    next token. (Default: 2048) \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_gpu\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"The number of GPUs to use. On macOS it defaults to 1 to\n",
      "    enable metal support, 0 to disable.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_thread\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Sets the number of threads to use during computation.\n",
      "    By default, Ollama will detect this for optimal performance.\n",
      "    It is recommended to set this value to the number of physical\n",
      "    CPU cores your system has (as opposed to the logical number of cores).\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_predict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Maximum number of tokens to predict when generating text.\n",
      "    (Default: 128, -1 = infinite generation, -2 = fill context)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrepeat_last_n\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Sets how far back for the model to look back to prevent\n",
      "    repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrepeat_penalty\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Sets how strongly to penalize repetitions. A higher value (e.g., 1.5)\n",
      "    will penalize repetitions more strongly, while a lower value (e.g., 0.9)\n",
      "    will be more lenient. (Default: 1.1)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"The temperature of the model. Increasing the temperature will\n",
      "    make the model answer more creatively. (Default: 0.8)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Sets the random number seed to use for generation. Setting this\n",
      "    to a specific number will make the model generate the same text for\n",
      "    the same prompt.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Sets the stop tokens to use.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtfs_z\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Tail free sampling is used to reduce the impact of less probable\n",
      "    tokens from the output. A higher value (e.g., 2.0) will reduce the\n",
      "    impact more, while a value of 1.0 disables this setting. (default: 1)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtop_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Reduces the probability of generating nonsense. A higher value (e.g. 100)\n",
      "    will give more diverse answers, while a lower value (e.g. 10)\n",
      "    will be more conservative. (Default: 40)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtop_p\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Works together with top-k. A higher value (e.g., 0.95) will lead\n",
      "    to more diverse text, while a lower value (e.g., 0.5) will\n",
      "    generate more focused and conservative text. (Default: 0.9)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"json\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Specify the format of the output (options: json)\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"How long the model will stay loaded into memory.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbase_url\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Base url the model is hosted under.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclient_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Additional kwargs to pass to the httpx Client. \n",
      "    For a full list of the params, see [this link](https://pydoc.dev/httpx/latest/httpx.Client.html)\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_client\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mClient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrivateAttr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"\n",
      "    The client to use for making requests.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_async_client\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAsyncClient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrivateAttr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"\n",
      "    The async client to use for making requests.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_default_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Get the default parameters for calling Ollama.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"format\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"options\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"mirostat\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmirostat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"mirostat_eta\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmirostat_eta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"mirostat_tau\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmirostat_tau\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"num_ctx\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_ctx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"num_gpu\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"num_thread\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_thread\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"num_predict\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_predict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"repeat_last_n\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat_last_n\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"repeat_penalty\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat_penalty\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"temperature\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"seed\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"stop\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"tfs_z\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfs_z\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"top_k\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"top_p\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"keep_alive\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mmodel_validator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"after\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_set_clients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Set clients to use for ollama.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclient_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient_kwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mclient_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_async_client\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAsyncClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mclient_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_convert_messages_to_ollama_messages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mollama_messages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mrole\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"user\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"assistant\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"system\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tool\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mtool_call_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mtool_calls\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mrole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"user\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mrole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"assistant\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtool_calls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0m_lc_tool_call_to_openai_tool_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtool_call\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;32mfor\u001b[0m \u001b[0mtool_call\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSystemMessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mrole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"system\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mToolMessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mrole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"tool\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtool_call_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtool_call_id\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Received unsupported message type for Ollama.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mfor\u001b[0m \u001b[0mcontent_part\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32mif\u001b[0m \u001b[0mcontent_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"text\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mcontent\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33mf\"\u001b[0m\u001b[1;33m\\n\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcontent_part\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32melif\u001b[0m \u001b[0mcontent_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tool_use\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32melif\u001b[0m \u001b[0mcontent_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"image_url\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mimage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mtemp_image_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontent_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image_url\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_image_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mimage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_image_url\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_image_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mand\u001b[0m \u001b[1;34m\"url\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_image_url\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_image_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mimage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_image_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[1;34m\"Only string image_url or dict with string 'url' \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[1;34m\"inside content parts are supported.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mimage_url_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;31m# Support data:image/jpeg;base64,<image> format\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;31m# and base64 strings\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_url_components\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_url_components\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_url_components\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;34m\"Unsupported message content type. \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;34m\"Must either have type 'text' or type 'image_url' \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;34m\"with a string 'image_url' field.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# Should convert to ollama.Message once role includes tool, and tool_call_id is in Message # noqa: E501\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"role\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrole\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"content\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"images\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mtool_calls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tool_calls\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtool_calls\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tool_call_id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mollama_messages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mollama_messages\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_acreate_chat_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAsyncIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mollama_messages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_messages_to_ollama_messages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_params\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"options\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stop\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;34m\"tools\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32myield\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_async_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mollama_messages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"options\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mkeep_alive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"keep_alive\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtools\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tools\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m  \u001b[1;31m# type:ignore\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_async_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mollama_messages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"options\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mkeep_alive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"keep_alive\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type:ignore\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_create_chat_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mollama_messages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_messages_to_ollama_messages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_params\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"options\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stop\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;34m\"tools\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mollama_messages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"options\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mkeep_alive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"keep_alive\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtools\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tools\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mollama_messages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"options\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mkeep_alive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"keep_alive\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_chat_stream_with_aggregation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallbackManagerForLLMRun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfinal_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_chat_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAIMessageChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mstream_resp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mif\u001b[0m \u001b[1;34m\"message\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mand\u001b[0m \u001b[1;34m\"content\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0musage_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_usage_metadata_from_generation_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mstream_resp\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mtool_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_tool_calls_from_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mgeneration_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mfinal_chunk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mfinal_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mfinal_chunk\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mrun_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mfinal_chunk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No data received from Ollama stream.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_achat_stream_with_aggregation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAsyncCallbackManagerForLLMRun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfinal_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_acreate_chat_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAIMessageChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mstream_resp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mif\u001b[0m \u001b[1;34m\"message\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mand\u001b[0m \u001b[1;34m\"content\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0musage_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_usage_metadata_from_generation_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mstream_resp\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mtool_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_tool_calls_from_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mgeneration_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mfinal_chunk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mfinal_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mfinal_chunk\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32mawait\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mfinal_chunk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No data received from Ollama stream.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_get_ls_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mLangSmithParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Get standard params for tracing.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_invocation_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mls_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLangSmithParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mls_provider\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ollama\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mls_model_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mls_model_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"chat\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mls_temperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"temperature\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mls_stop\u001b[0m \u001b[1;33m:=\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mls_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls_stop\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls_stop\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mls_params\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallbackManagerForLLMRun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfinal_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chat_stream_with_aggregation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mgeneration_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneration_info\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mchat_generation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChatGeneration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfinal_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0musage_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAIMessageChunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musage_metadata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtool_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAIMessageChunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mgeneration_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeneration_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchat_generation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallbackManagerForLLMRun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_chat_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAIMessageChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mstream_resp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mif\u001b[0m \u001b[1;34m\"message\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mand\u001b[0m \u001b[1;34m\"content\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0musage_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_usage_metadata_from_generation_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mstream_resp\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mtool_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_tool_calls_from_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mgeneration_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mrun_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_astream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAsyncCallbackManagerForLLMRun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAsyncIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_acreate_chat_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChatGenerationChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAIMessageChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mstream_resp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mif\u001b[0m \u001b[1;34m\"message\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32mand\u001b[0m \u001b[1;34m\"content\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0musage_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_usage_metadata_from_generation_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                            \u001b[0mstream_resp\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mtool_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_tool_calls_from_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mgeneration_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32mawait\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_agenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrun_manager\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAsyncCallbackManagerForLLMRun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfinal_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_achat_stream_with_aggregation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mgeneration_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneration_info\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mchat_generation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChatGeneration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfinal_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0musage_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAIMessageChunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musage_metadata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtool_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAIMessageChunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mgeneration_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeneration_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchat_generation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_llm_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Return type of chat model.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"chat-ollama\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mbind_tools\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mtools\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseTool\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLanguageModelInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Bind tool-like objects to this chat model.\n",
      "\n",
      "        Assumes model is compatible with OpenAI tool-calling API.\n",
      "\n",
      "        Args:\n",
      "            tools: A list of tool definitions to bind to this chat model.\n",
      "                Supports any tool definition handled by\n",
      "                :meth:`langchain_core.utils.function_calling.convert_to_openai_tool`.\n",
      "            kwargs: Any additional parameters are passed directly to\n",
      "                ``self.bind(**kwargs)``.\n",
      "        \"\"\"\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mformatted_tools\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconvert_to_openai_tool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtool\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatted_tools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\ia\\ver2\\ia\\ia-pdf-youtube-stuffs\\.venv\\lib\\site-packages\\langchain_ollama\\chat_models.py\n",
      "\u001b[1;31mType:\u001b[0m           ModelMetaclass\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "ChatOllama??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run the Ollama server  \n",
    "http://localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.1:8b\",base_url=\"http://host.docker.internal:11434\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "output = chain.invoke([Document(page_content=table_html)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(metadata={}, page_content='<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>63.4</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 =</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4AIl LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIL</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>15</td><td>71.3</td><td>60.9</td><td>442</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>74.9</td><td>70.1</td><td>67.9</td><td>Ba</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>ng</td><td>74.2</td><td>50.9</td><td>4.4</td><td>68.8</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>60.1</td></tr><tr><td>Dolly 12B* (Conover et al., 2023b)</td><td>56.7</td><td>75.4</td><td>at</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>74</td><td>68.8</td><td>56.6</td><td>43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>ue)</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>71.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>4A</td><td>65.0</td></tr><tr><td>StableLM Tuned’ (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>S13</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>78</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>TAS</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>4</td><td>712</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>41.6</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7m</td><td>43.3</td><td>44.4</td><td>65,2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>')],\n",
       " 'output_text': 'The table appears to compare various large language models (LLMs) and their performance on different tasks. The metrics used include:\\n\\n* Perplexity (PPL)\\n* Accuracy\\n* ROUGE score\\n* BLEU score\\n* METEOR score\\n* Embedding-based similarity scores (not specified)\\n\\nHere\\'s a brief summary of the top-performing LLMs based on the table:\\n\\n1. **Mosaic MPT-instruct**: Achieved the best PPL (74.3), accuracy (80.4%), and ROUGE score (77.2) among all models.\\n2. **GPT4-x-Vicuna-13b**: Scored high in accuracy (75.0%), BLEU score (63.2), and METEOR score (58.7).\\n3. **Falcon 7b**: Achieved the best PPL (73.6) and accuracy (80.7%) among all models.\\n4. **Mosaic mpt-chat**: Performed well in accuracy (78.2%), ROUGE score (77.2), and METEOR score (69.4).\\n\\nNote: The table is not explicitly stating which model is the \"best\" overall, but based on the provided metrics, Mosaic MPT-instruct appears to be a top performer across multiple evaluation criteria.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table appears to compare various large language models (LLMs) and their performance on different tasks. The metrics used include:\n",
      "\n",
      "* Perplexity (PPL)\n",
      "* Accuracy\n",
      "* ROUGE score\n",
      "* BLEU score\n",
      "* METEOR score\n",
      "* Embedding-based similarity scores (not specified)\n",
      "\n",
      "Here's a brief summary of the top-performing LLMs based on the table:\n",
      "\n",
      "1. **Mosaic MPT-instruct**: Achieved the best PPL (74.3), accuracy (80.4%), and ROUGE score (77.2) among all models.\n",
      "2. **GPT4-x-Vicuna-13b**: Scored high in accuracy (75.0%), BLEU score (63.2), and METEOR score (58.7).\n",
      "3. **Falcon 7b**: Achieved the best PPL (73.6) and accuracy (80.7%) among all models.\n",
      "4. **Mosaic mpt-chat**: Performed well in accuracy (78.2%), ROUGE score (77.2), and METEOR score (69.4).\n",
      "\n",
      "Note: The table is not explicitly stating which model is the \"best\" overall, but based on the provided metrics, Mosaic MPT-instruct appears to be a top performer across multiple evaluation criteria.\n"
     ]
    }
   ],
   "source": [
    "print(output['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert HTML table to pandas DataFrame\n",
    "dfs = pd.read_html(table_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                Model       BoolQ   PIQA  \\\n",
       " 0                                  GPT4AII-J 6B v1.0*        73.4   74.8   \n",
       " 1                              GPT4AII-J v1.1-breezy*        74.0   75.1   \n",
       " 2                              GPT4AIIL-J v1.2-jazzy*        74.8   74.9   \n",
       " 3                              GPT4AII-J v1.3-groovy*        73.6   74.3   \n",
       " 4                                  GPT4AII-J Lora 6B*        68.6   75.8   \n",
       " 5                              GPT4AIl LLaMa Lora 7B*        73.1   77.6   \n",
       " 6                                 GPT4All 13B snoozy*        83.3   79.2   \n",
       " 7                                      GPT4AIl Falcon        71.6   79.8   \n",
       " 8                  Nous-Hermes (Nous-Research, 2023b)        79.5   78.9   \n",
       " 9                 Nous-Hermes2 (Nous-Research, 2023c)        83.9   80.7   \n",
       " 10                 Nous-Puffin (Nous-Research, 2023d)       815.0   80.7   \n",
       " 11                  Dolly 6B* (Conover et al., 2023a)        68.8   71.3   \n",
       " 12                 Dolly 12B* (Conover et al., 2023b)        56.7   75.4   \n",
       " 13  Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7...  94325793.0    NaN   \n",
       " 14     Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)       654.0   76.2   \n",
       " 15                   LLama 7B* (Touvron et al., 2023)        73.1  714.0   \n",
       " 16                  LLama 13B* (Touvron et al_, 2023)        68.5   79.1   \n",
       " 17               Pythia 6.7B* (Biderman et al., 2023)        63.5   76.3   \n",
       " 18                Pythia 12B* (Biderman et al., 2023)        67.7   16.6   \n",
       " 19                  Fastchat TS* (Zheng et al., 2023)       815.0   64.6   \n",
       " 20          Fastchat Vicufia* 7B (Zheng et al., 2023)        76.6   71.2   \n",
       " 21         Fastchat Vicufia 13B* (Zheng et al., 2023)       815.0   76.8   \n",
       " 22          Stable Vicufia RLHF* (Stability-Al, 2023)        82.3   78.6   \n",
       " 23               StableLM Tuned’ (Stability-Al, 2023)       625.0   71.2   \n",
       " 24                StableLM Base* (Stability-Al, 2023)        60.1   67.4   \n",
       " 25                     Koala 13B* (Geng et al., 2023)       765.0   71.9   \n",
       " 26                         Open Assistant Pythia 12B*        67.9   78.0   \n",
       " 27                 Mosaic MPT7B (MosaicML-Team, 2023)        74.8   79.3   \n",
       " 28          Mosaic mpt-instruct (MosaicML-Team, 2023)       743.0   80.4   \n",
       " 29              Mosaic mpt-chat (MosaicML-Team, 2023)       771.0   78.2   \n",
       " 30                         Wizard 7B xu et al., 2023)         4.0  712.0   \n",
       " 31             Wizard 7B Uncensored (Xu et al., 2023)       717.0   74.2   \n",
       " 32            Wizard 13B Uncensored (Xu et al,, 2023)       784.0   15.5   \n",
       " 33           GPT4-x-Vicuna-13b (Nous-Research, 2023a)       813.0   75.0   \n",
       " 34                Falcon 7b (Almazrouei et al., 2023)        73.6   80.7   \n",
       " 35       Falcon 7b instruct (Almazrouei et al., 2023)       709.0   78.6   \n",
       " \n",
       "    HellaSwag WinoG.  ARC-c ARC-c.1    OBQA   Avg  \n",
       " 0       63.4   64.7   54.9      36    40.2  58.2  \n",
       " 1       63.2   63.6   55.4    34.9    38.4    SL  \n",
       " 2       63.6    638   56.6    35.3      41  58.6  \n",
       " 3       63.8   63.5   57.7      35  38.8 =  58.1  \n",
       " 4       66.2   63.5   56.4    35.7     402  58.1  \n",
       " 5        721   67.8    SIL    40.4    40.2  60.3  \n",
       " 6         15   71.3   60.9     442    43.4  65.3  \n",
       " 7       74.9   70.1   67.9      Ba    42.6  65.2  \n",
       " 8         80     ng   74.2    50.9     4.4  68.8  \n",
       " 9       80.1   71.3   75.7    52.1    46.2  70.0  \n",
       " 10      80.4   72.5  771.6    50.7    45.6  69.9  \n",
       " 11      67.6   63.9   62.9    38.7     412  60.1  \n",
       " 12        at   62.2   64.6    38.5     404   584  \n",
       " 13        74   68.8   56.6    43.9     426  62.8  \n",
       " 14      66.2   64.1   62.2    36.6    38.2  58.4  \n",
       " 15       ue)   66.9   52.5     414    42.4  61.0  \n",
       " 16      76.2   70.1     60    44.6     422  63.0  \n",
       " 17        64   61.1   61.3    35.2    37.2  56.9  \n",
       " 18      67.3   63.8   63.9    34.8      38  58.9  \n",
       " 19      46.3    618   49.3  (33.2.    39.4  53.7  \n",
       " 20      70.7   67.3   53.5    41.2    40.8  61.0  \n",
       " 21      73.3   66.7   57.4    42.7     3.6  63.1  \n",
       " 22      74.1   70.9     61    43.5      4A  65.0  \n",
       " 23      53.6   54.8   52.4      31    33.4   S13  \n",
       " 24       412   50.1   44.9      27      32  46.1  \n",
       " 25      72.6   68.8   54.3      4l    42.8  62.0  \n",
       " 26      68.1     65   64.2     404    43.2  61.0  \n",
       " 27      76.3   68.6     70    42.2    42.6  64.8  \n",
       " 28     77.2.    678   72.2    44.6      43  65.6  \n",
       " 29       TAS   67.5   69.4    43.3    44.2  64.9  \n",
       " 30      69.9    665   56.8    40.5    42.6   617  \n",
       " 31        68   65.2   53.5     387    41.6  59.8  \n",
       " 32        21   69.5   57.5    40.4      44  62.5  \n",
       " 33      75.2     65   58.7     439    43.6   632  \n",
       " 34      76.3    673     7m    43.3    44.4   652  \n",
       " 35      69.8   66.7   67.9    42.7     412  62.5  ]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Model       BoolQ   PIQA  \\\n",
      "0                                  GPT4AII-J 6B v1.0*        73.4   74.8   \n",
      "1                              GPT4AII-J v1.1-breezy*        74.0   75.1   \n",
      "2                              GPT4AIIL-J v1.2-jazzy*        74.8   74.9   \n",
      "3                              GPT4AII-J v1.3-groovy*        73.6   74.3   \n",
      "4                                  GPT4AII-J Lora 6B*        68.6   75.8   \n",
      "5                              GPT4AIl LLaMa Lora 7B*        73.1   77.6   \n",
      "6                                 GPT4All 13B snoozy*        83.3   79.2   \n",
      "7                                      GPT4AIl Falcon        71.6   79.8   \n",
      "8                  Nous-Hermes (Nous-Research, 2023b)        79.5   78.9   \n",
      "9                 Nous-Hermes2 (Nous-Research, 2023c)        83.9   80.7   \n",
      "10                 Nous-Puffin (Nous-Research, 2023d)       815.0   80.7   \n",
      "11                  Dolly 6B* (Conover et al., 2023a)        68.8   71.3   \n",
      "12                 Dolly 12B* (Conover et al., 2023b)        56.7   75.4   \n",
      "13  Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7...  94325793.0    NaN   \n",
      "14     Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)       654.0   76.2   \n",
      "15                   LLama 7B* (Touvron et al., 2023)        73.1  714.0   \n",
      "16                  LLama 13B* (Touvron et al_, 2023)        68.5   79.1   \n",
      "17               Pythia 6.7B* (Biderman et al., 2023)        63.5   76.3   \n",
      "18                Pythia 12B* (Biderman et al., 2023)        67.7   16.6   \n",
      "19                  Fastchat TS* (Zheng et al., 2023)       815.0   64.6   \n",
      "20          Fastchat Vicufia* 7B (Zheng et al., 2023)        76.6   71.2   \n",
      "21         Fastchat Vicufia 13B* (Zheng et al., 2023)       815.0   76.8   \n",
      "22          Stable Vicufia RLHF* (Stability-Al, 2023)        82.3   78.6   \n",
      "23               StableLM Tuned’ (Stability-Al, 2023)       625.0   71.2   \n",
      "24                StableLM Base* (Stability-Al, 2023)        60.1   67.4   \n",
      "25                     Koala 13B* (Geng et al., 2023)       765.0   71.9   \n",
      "26                         Open Assistant Pythia 12B*        67.9   78.0   \n",
      "27                 Mosaic MPT7B (MosaicML-Team, 2023)        74.8   79.3   \n",
      "28          Mosaic mpt-instruct (MosaicML-Team, 2023)       743.0   80.4   \n",
      "29              Mosaic mpt-chat (MosaicML-Team, 2023)       771.0   78.2   \n",
      "30                         Wizard 7B xu et al., 2023)         4.0  712.0   \n",
      "31             Wizard 7B Uncensored (Xu et al., 2023)       717.0   74.2   \n",
      "32            Wizard 13B Uncensored (Xu et al,, 2023)       784.0   15.5   \n",
      "33           GPT4-x-Vicuna-13b (Nous-Research, 2023a)       813.0   75.0   \n",
      "34                Falcon 7b (Almazrouei et al., 2023)        73.6   80.7   \n",
      "35       Falcon 7b instruct (Almazrouei et al., 2023)       709.0   78.6   \n",
      "\n",
      "   HellaSwag WinoG.  ARC-c ARC-c.1    OBQA   Avg  \n",
      "0       63.4   64.7   54.9      36    40.2  58.2  \n",
      "1       63.2   63.6   55.4    34.9    38.4    SL  \n",
      "2       63.6    638   56.6    35.3      41  58.6  \n",
      "3       63.8   63.5   57.7      35  38.8 =  58.1  \n",
      "4       66.2   63.5   56.4    35.7     402  58.1  \n",
      "5        721   67.8    SIL    40.4    40.2  60.3  \n",
      "6         15   71.3   60.9     442    43.4  65.3  \n",
      "7       74.9   70.1   67.9      Ba    42.6  65.2  \n",
      "8         80     ng   74.2    50.9     4.4  68.8  \n",
      "9       80.1   71.3   75.7    52.1    46.2  70.0  \n",
      "10      80.4   72.5  771.6    50.7    45.6  69.9  \n",
      "11      67.6   63.9   62.9    38.7     412  60.1  \n",
      "12        at   62.2   64.6    38.5     404   584  \n",
      "13        74   68.8   56.6    43.9     426  62.8  \n",
      "14      66.2   64.1   62.2    36.6    38.2  58.4  \n",
      "15       ue)   66.9   52.5     414    42.4  61.0  \n",
      "16      76.2   70.1     60    44.6     422  63.0  \n",
      "17        64   61.1   61.3    35.2    37.2  56.9  \n",
      "18      67.3   63.8   63.9    34.8      38  58.9  \n",
      "19      46.3    618   49.3  (33.2.    39.4  53.7  \n",
      "20      70.7   67.3   53.5    41.2    40.8  61.0  \n",
      "21      73.3   66.7   57.4    42.7     3.6  63.1  \n",
      "22      74.1   70.9     61    43.5      4A  65.0  \n",
      "23      53.6   54.8   52.4      31    33.4   S13  \n",
      "24       412   50.1   44.9      27      32  46.1  \n",
      "25      72.6   68.8   54.3      4l    42.8  62.0  \n",
      "26      68.1     65   64.2     404    43.2  61.0  \n",
      "27      76.3   68.6     70    42.2    42.6  64.8  \n",
      "28     77.2.    678   72.2    44.6      43  65.6  \n",
      "29       TAS   67.5   69.4    43.3    44.2  64.9  \n",
      "30      69.9    665   56.8    40.5    42.6   617  \n",
      "31        68   65.2   53.5     387    41.6  59.8  \n",
      "32        21   69.5   57.5    40.4      44  62.5  \n",
      "33      75.2     65   58.7     439    43.6   632  \n",
      "34      76.3    673     7m    43.3    44.4   652  \n",
      "35      69.8   66.7   67.9    42.7     412  62.5  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming there's only one table, get the DataFrame\n",
    "df = dfs[0]\n",
    "\n",
    "# Now you have the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>PIQA</th>\n",
       "      <th>HellaSwag</th>\n",
       "      <th>WinoG.</th>\n",
       "      <th>ARC-c</th>\n",
       "      <th>ARC-c.1</th>\n",
       "      <th>OBQA</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT4AII-J 6B v1.0*</td>\n",
       "      <td>73.4</td>\n",
       "      <td>74.8</td>\n",
       "      <td>63.4</td>\n",
       "      <td>64.7</td>\n",
       "      <td>54.9</td>\n",
       "      <td>36</td>\n",
       "      <td>40.2</td>\n",
       "      <td>58.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT4AII-J v1.1-breezy*</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.1</td>\n",
       "      <td>63.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>55.4</td>\n",
       "      <td>34.9</td>\n",
       "      <td>38.4</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT4AIIL-J v1.2-jazzy*</td>\n",
       "      <td>74.8</td>\n",
       "      <td>74.9</td>\n",
       "      <td>63.6</td>\n",
       "      <td>638</td>\n",
       "      <td>56.6</td>\n",
       "      <td>35.3</td>\n",
       "      <td>41</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT4AII-J v1.3-groovy*</td>\n",
       "      <td>73.6</td>\n",
       "      <td>74.3</td>\n",
       "      <td>63.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>57.7</td>\n",
       "      <td>35</td>\n",
       "      <td>38.8 =</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT4AII-J Lora 6B*</td>\n",
       "      <td>68.6</td>\n",
       "      <td>75.8</td>\n",
       "      <td>66.2</td>\n",
       "      <td>63.5</td>\n",
       "      <td>56.4</td>\n",
       "      <td>35.7</td>\n",
       "      <td>402</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  BoolQ  PIQA HellaSwag WinoG. ARC-c ARC-c.1    OBQA  \\\n",
       "0      GPT4AII-J 6B v1.0*   73.4  74.8      63.4   64.7  54.9      36    40.2   \n",
       "1  GPT4AII-J v1.1-breezy*   74.0  75.1      63.2   63.6  55.4    34.9    38.4   \n",
       "2  GPT4AIIL-J v1.2-jazzy*   74.8  74.9      63.6    638  56.6    35.3      41   \n",
       "3  GPT4AII-J v1.3-groovy*   73.6  74.3      63.8   63.5  57.7      35  38.8 =   \n",
       "4      GPT4AII-J Lora 6B*   68.6  75.8      66.2   63.5  56.4    35.7     402   \n",
       "\n",
       "    Avg  \n",
       "0  58.2  \n",
       "1    SL  \n",
       "2  58.6  \n",
       "3  58.1  \n",
       "4  58.1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
